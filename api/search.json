[{"id":"4337dc43129fb733f89eff2c212fe09e","title":"MySQL优化经验总结","content":"\n\n\n\n\n\n\n\n\n\n线上SQL的调优经验\n\nslow_query_log 日志中收集到的慢 SQL ，结合 explain 分析是否命中索引。\n减少索引扫描行数，有针对性的优化慢 SQL。\n建立联合索引，由于联合索引的每个叶子节点包含检索字段的信息，按最左前缀原则匹配后，再按其它条件过滤，减少回表的数据量。\n还可以使用虚拟列和联合索引来提升复杂查询的执行效率。\n监控sql执行情况，发邮件、短信报警，便于快速识别慢查询sql\n打开数据库慢查询日志功能\n简化业务逻辑\n代码重构、优化\n异步处理\nsql优化\n索引优化\n\n\n\n\n\n\n\n\n\n\nSQL优化\n\n分页优化。比如电梯直达，limit 100000,10 先查找起始的主键id，再通过id&gt;#&#123;value&#125;往后取10条\n\n尽量使用覆盖索引，索引的叶节点中已经包含要查询的字段，减少回表查询\n\nSQL优化（索引优化、小表驱动大表、虚拟列、适当增加冗余字段减少连表查询、联合索引、排序优化、慢日志 Explain 分析执行计划）。\n\nwhere子句\n​\t避免对字段进行null值判断、表达式操作等；\n​\twhere表之间的连接，必须写在其他where条件之前；\n​\t可过滤掉最大数量记录的条件必须写在 where 子句的末尾，having最后；\n\n优先考虑在where及order by涉及的列上建立索引；\n\n避免在索引列上使用函数运算、is null和is not null；\n\n避免使用select *;\n\n使用 \nunion all 代替 union\nexists代替in\nnot exists 代替 not in\n连接查询代替子查询；\n\n批量操作\n\n小表驱动大表；\n\n多用limit\n\nin中值太多  分页\n\n增量查询\n\n高效的分页\n\njoin表不宜过多\n\n控制索引数量\n\n选择合理的字段类型\n\n提升group by 的效率\n\n索引优化\n\n\n\n设计优化（避免使用NULL、用简单数据类型如int、减少 text 类型、分库分表）。\n\n硬件优化（使用SSD 减少 I&#x2F;O 时间、足够大的网络带宽、尽量大的内存）\n\n\n","slug":"01_MySQL/SQL优化","date":"2022-05-20T15:15:47.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"ca18af8a7c9f51eca47fbf29c78c60fe","title":"Redis Cluster 原理探讨","content":"\n\n\n\n\n\n\n\n\n  Redis Cluster\n\nhash(key) % 16384 &#x3D; slot 哈希槽 &#x3D; hash(key) &amp; 2^n^\nslot - hash槽分布范围[0-5460] 、 [5461-10922]、[10923-16383]\n# 创建RedisCluster配置的节点目录\n[root@redis]$ mkdir -p rediscluster&#x2F;node800&#123;1,2,3,4,5,6&#125;\n# 复制Redis配置到每个节点目录\n[root@redis]$ cp redis-5.0.2&#x2F;redis.conf rediscluster&#x2F;node8001&#x2F;\n# 修改节点配置\n[root@redis]$ vim rediscluster&#x2F;node8001&#x2F;redis.conf\n# 批量修改\n:%s&#x2F;8001&#x2F;8002&#x2F;g\n\n# 启动集群配置\n[root@redis]$ redis-server rediscluster&#x2F;800*&#x2F;redis.conf\n# 校验启动情况\n[root@reids]$ ps -ef | grep redis\n# 集群命令帮助\n[root@redis]$ redis-cli --cluster help\n# 创建集群关系\n[root@redis]$ redis-cli -a 111111 --cluster create --cluster-replicas 1 192.168.109.200:8001 192.168.109.200:8002 192.168.109.200:8003 192.168.109.200:8004 192.168.109.200:8005 192.168.109.200:8006  \n\n\n# 连接任意一个节点客户端[带-c说明是集群方式 智能客户端]\n[root@redis]$ redis-cli -a 111111 -c -h 192.168.109.200 -p 8001\n# 验证集群信息\n&gt; cluster info \n&gt; cluster nodes\n&gt; cluster slots\n\n\n\n\n\n\n序号\n配置项\n选项\n释义\n\n\n\n1\ncluster-enabled\nyes\n启动集群模式\n\n\n2\nport\n8001\n端口\n\n\n3\ndir\n&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;8001&#x2F;\n指定数据目录，绝对目录\n\n\n4\ncluster-config-file\nnodes-8001.conf\n集群节点信息，hash crc16\n\n\n5\ncluster-node-timeout\n5000\n集群节点超时时间,心跳时间\n\n\n6\nbind\n#127.0.0.1\n测试需要注释掉，生产需指定配置\n\n\n7\nprotected-mode\nno\n关闭保护模式\n\n\n8\nrequirepass\n111111\nredis访问密码\n\n\n9\nmasterauth\n111111\n集群节点间的访问密码，与上述保持一致\n\n\n10\ndamonize\nyes\n后台启动\n\n\n11\nappendonly\nyes\n\n\n\n\n\n\n\n\n\n\n\n\n  Laravel 框架 使用redis cluster需要修改的地方\n# .composer.lock\n# ...\n&quot;require&quot;: &#123;\n    # ...\n    &quot;php&quot;: &quot;^7.1.3&quot;,\n    &quot;predis&#x2F;predis&quot;: &quot;^1.1&quot;,\n    # 如果安装horizon，请注意Redis密码必设且相同\n    # config&#x2F;horizon.php中&#39;use&#39;&#x3D;&gt;&#39;horizon&#39;\n    # ...\n&#125;,\n# ...\n\n\n# .env\n# ...\nCACHE_DRIVER&#x3D;redis\n# ...\n    \n# cache.php\n# ...\n&#39;redis&#39; &#x3D;&gt; [\n    &#39;driver&#39;     &#x3D;&gt; &#39;redis&#39;,\n    &#39;connection&#39; &#x3D;&gt; &#39;default&#39;,\n],\n#...\n\n\n# database.php\n# ...\n&#39;redis&#39; &#x3D;&gt; [\n    &#39;client&#39;  &#x3D;&gt; env(&#39;REDIS_CLIENT&#39;, &#39;predis&#39;),\n    &#39;options&#39; &#x3D;&gt; [\n        &#39;cluster&#39; &#x3D;&gt; env(&#39;REDIS_CLUSTER&#39;, &#39;redis&#39;),\n    ],\n    &#39;clusters&#39; &#x3D;&gt; [\n        &#39;default&#39; &#x3D;&gt; [\n            [\n                &#39;host&#39;     &#x3D;&gt; env(&#39;REDIS_HOST_A&#39;),\n                &#39;password&#39; &#x3D;&gt; env(&#39;REDIS_PASSWORD_A&#39;),\n                &#39;port&#39;     &#x3D;&gt; env(&#39;REDIS_PORT_A&#39;, 6379),\n                &#39;database&#39; &#x3D;&gt; env(&#39;REDIS_DB_A&#39;, 0),\n            ],\n            [\n                &#39;host&#39;\t   &#x3D;&gt; env(&#39;REDIS_HOST_B&#39;),\n                &#39;password&#39; &#x3D;&gt; env(&#39;REDIS_PASSWORD_B&#39;),\n                &#39;port&#39;     &#x3D;&gt; env(&#39;REDIS_PORT_B&#39;, 6379),\n                &#39;database&#39; &#x3D;&gt; env(&#39;REDIS_DB_B&#39;, 0),\n            ],\n            [\n                &#39;host&#39;     &#x3D;&gt; env(&#39;REDIS_HOST_C&#39;),\n                &#39;password&#39; &#x3D;&gt; env(&#39;REDIS_PASSWORD_C&#39;),\n                &#39;port&#39;     &#x3D;&gt; env(&#39;REDIS_PORT_C&#39;, 6379),\n                &#39;database&#39; &#x3D;&gt; env(&#39;REDIS_DB_C&#39;, 0),\n            ],\n            [\n                &#39;host&#39;     &#x3D;&gt; env(&#39;REDIS_HOST_D&#39;),\n                &#39;password&#39; &#x3D;&gt; env(&#39;REDIS_PASSWORD_D&#39;),\n                &#39;port&#39;     &#x3D;&gt; env(&#39;REDIS_PORT_D&#39;, 6379),\n                &#39;database&#39; &#x3D;&gt; env(&#39;REDIS_DB_D&#39;, 0),\n            ],\n            [\n                &#39;host&#39;     &#x3D;&gt; env(&#39;REDIS_HOST_E&#39;),\n                &#39;password&#39; &#x3D;&gt; env(&#39;REDIS_PASSWORD_E&#39;),\n                &#39;port&#39;     &#x3D;&gt; env(&#39;REDIS_PORT_E&#39;, 6379),\n                &#39;database&#39; &#x3D;&gt; env(&#39;REDIS_DB_E&#39;, 0),\n            ],\n            [\n                &#39;host&#39;     &#x3D;&gt; env(&#39;REDIS_HOST_F&#39;),\n                &#39;password&#39; &#x3D;&gt; env(&#39;REDIS_PASSWORD_F&#39;),\n                &#39;port&#39;     &#x3D;&gt; env(&#39;REDIS_PORT_F&#39;, 6379),\n                &#39;database&#39; &#x3D;&gt; env(&#39;REDIS_DB_F&#39;, 0),\n            ],\n        ],\n    ],\n],\n# ...\n\n\n\n\n\n\n\n\n\n\n\n\n\n  Redis Cluster 注意事项\n\n不完全支持批量操作：mset、mget\n事务不能跨节点支持\n不支持多实例\nkey 是最小粒度\n最少 6 个才能保证组成完整高可用的集群\n连接的时候只需要连接 1 台服务器即可。\n如果 1 个主从连接宕机的话，那么集群就宕机了。\n\n\n\n\n\n\n\n\n\n\n  应用场景\n计数器 string incr\n分布式ID生成 incr\n海量数据统计 - bitmap\n会话缓存 key value\n分布式队列&#x2F;阻塞队列 list 双向链表 lpush/rpush rpop/lpop    brpop/blpop阻塞队列\n分布式锁[setnx]\n热键 HotKey  存储 [list] ltrim\t\t用户路由\t\t二级缓存\t\t\n社交类 - 好友推荐、文章 set\n排行榜 sorted_set\n延迟队列 - sorted_set &amp; zadd + zrangbyscore + rem key\n地址服务 [geo]\n布隆过滤器  [0-1]\n","slug":"02_Redis/RedisCluster","date":"2020-07-25T12:55:57.000Z","categories_index":"Redis","tags_index":"redis,高可用,集群","author_index":"Michael"},{"id":"6413658dbb1fc2cffd06814af177e795","title":"PHP代码洁癖心得","content":"\n\n\n\n\n\n\n\n\n\n  if的使用洁癖\n\n给定初始值\nif ($orderStatus &#x3D;&#x3D; 1) &#123;\n    $orderDesc &#x3D; &#39;已支付&#39;;\n# 其他的elseif ...\n&#125; else &#123;\n    $orderDesc &#x3D; &#39;未支付&#39;;\n&#125;\n\n&#x2F;&#x2F; 优化后\n$orderDesc &#x3D; &#39;未支付&#39;;\nif ($orderStatus &#x3D;&#x3D; 1) &#123;\n    $orderDesc &#x3D; &#39;已支付&#39;;\n&#125;\n\n\n\n简单的判断使用&amp;&amp;代替\nif (strlen($newPwd) &lt; 6) &#123;\n    $message &#x3D; &#39;密码长度不足！&#39;;\n&#125;\n\n&#x2F;&#x2F; 优化后\nstrlen($newPwd) &lt; 6 &amp;&amp; $message &#x3D; &#39;密码长度不足！&#39;;\n\n\n\n三元运算符\nif (empty($_POST[&#39;action&#39;])) &#123;\n    $action &#x3D; &#39;default&#39;;\n&#125; else &#123;\n    $action &#x3D; $_POST[&#39;action&#39;];\n&#125;\n\n&#x2F;&#x2F; 优化后\n$action &#x3D; empty($_POST[&#39;action&#39;]) ? &#39;default&#39; : $_POST[&#39;action&#39;];\n\n\n\n简化三元运算符?:或??\n$action &#x3D; empty($_POST[&#39;action&#39;]) ? &#39;default&#39; : $_POST[&#39;action&#39;];\n\n&#x2F;&#x2F; 简写后\n$action &#x3D; $_POST[&#39;action&#39;] ?: &#39;default&#39;; # 可保证$_POST下存在action\n# 或\n$action &#x3D; $_POST[&#39;action&#39;] ?? &#39;default&#39;;\n\n\n\n去掉多此一举的\n&#x2F;**\n * \n * @desc 是否为闰年\n * \n * @params int $year 年份\n *\n * @return bool\n *&#x2F;\nfunction isLeapYear(int $year):bool\n&#123;\n    if (($year % 4 &#x3D;&#x3D; 0 &amp;&amp; 100 !&#x3D;0) || ($year % 400 &#x3D;&#x3D; 0)) &#123;\n        return true;\n    &#125; else &#123;\n        return false;\n    &#125;\n&#125;\n\n&#x2F;&#x2F;优化后\nfunction isLeapYear(int $year):bool\n&#123;\n    return ($year % 4 &#x3D;&#x3D; 0 &amp;&amp; 100 !&#x3D;0) || ($year % 400 &#x3D;&#x3D; 0);\n&#125;\n\n\n\n对同一对象，含有多层逻辑，使用switch代替elseif\nif (&#39;玄幻&#39; &#x3D;&#x3D; $sortname) &#123;\n    $sort &#x3D; 1;\n&#125; else if (&#39;武侠&#39; &#x3D;&#x3D; $sortname) &#123;\n    $sort &#x3D; 2;\n&#125; else if (&#39;言情&#39; &#x3D;&#x3D; $sortname) &#123;\n    $sort &#x3D; 3;\n&#125; else if (&#39;其他&#39; &#x3D;&#x3D; $sortname) &#123;\n    $sort &#x3D; 10;\n&#125;\n\n&#x2F;&#x2F;优化后\nswitch ($sortname) &#123;\n    case &#39;玄幻&#39;:\n        $sort &#x3D; 1;\n        break;\n    case &#39;武侠&#39;:\n        $sort &#x3D; 2;\n        break;\n    case &#39;言情&#39;:\n        $sort &#x3D; 3;\n        break;\n    case &#39;其他&#39;:\n        $sort &#x3D; 10;\n        break;\n&#125;\n\n\n\n表驱动法\n&#x2F;&#x2F; 对上述逻辑修改，也可以声明数组选项，如遇复杂逻辑处理，也可以使用匿名函数\n$sortTable &#x3D; [\n    &#39;玄幻&#39; &#x3D;&gt; 1,\n    &#39;武侠&#39; &#x3D;&gt; 2,\n    &#39;言情&#39; &#x3D;&gt; 3,\n    &#39;其他&#39; &#x3D;&gt; function ($name) &#123;&#125;,\n];\n\n$sortId &#x3D; $sortTable[$sortname]($name) ?? 10;\n\n\n\n\n\n\n\n\n\n\n  循环语句\n\nwhile(true)标识无限死循环，别用for；\n特定情况下，如发邮件、采集内容时，要加延时sleep；\n循环体内，尽可能的避免调用复杂逻辑的函数或更多资源的调用；\nforeach代替while和for循环；\n避免空循环；\n只做一件事，尽可能短，控制在 line ≤ 50；\n循环嵌套限制在3层以内；\n循环条件内不做运算；\n\n\n\n\n\n\n\n\n\n\n  函数体\n\n函数的最佳最大长度是 50 ≤ line ≤ 150；\n函数形参最多不超过 7 个；\n短小函数更容易理解，也方便修改&#x2F;维护；\n只做一件事的函数，更易于复用；\n短小函数测试更方便；\n\n\n\n\n\n\n\n\n\n\n  其他\n\n避免使用幻数magic numbers；\n&lt;meta http-equiv&#x3D;&quot;Content-Type&quot; content&#x3D;&quot;text&#x2F;html;charset&#x3D;UTF-8&quot; &#x2F;&gt;\n\n&#x2F;&#x2F;优化后\ndefine(&#39;APP_CHARSET&#39;, &#39;UTF-8&#39;);\n&lt;meta http-equiv&#x3D;&quot;Content-Type&quot; content&#x3D;&quot;text&#x2F;html;charset&#x3D;&#123;APP_CHARSET&#125;&quot; &#x2F;&gt;\n\n幻数浅析（Magic Number）\n将一些比较难理解的东西，定义的常量（类中），这样代码可读性高\n\n中间结果赋值给变量；\n$str     &#x3D; &#39;this_is_a_test&#39;;\n$humpstr &#x3D; implode(&#39;&#39;, array_map(&#39;ucfirst&#39;, explode(&#39;_&#39;, $str)));\n\n&#x2F;&#x2F; 优化后\n$str     &#x3D; &#39;this_is_a_test&#39;;\n$words   &#x3D; explode(&#39;_&#39;, $str);\n$uWords  &#x3D; array_map(&#39;ucfirst&#39;, $words);\n$humpstr &#x3D; implode(&#39;&#39;, $uWords);\n\n\n\n复杂的逻辑表达式做成布尔函数；\nif (!$hasone &amp;&amp; $ddisfirst &#x3D; 1 &amp;&amp; $litpic &#x3D;&#x3D; &#39;&#39; &amp;&amp; empty($litpicname)) &#123;\n    $litpcname &#x3D; GetImageMapDD($iurl, $cfg_ddimg_width);;\n&#125;\n\n&#x2F;&#x2F; 优化后\n$emptyPic &#x3D; ($litpic &#x3D;&#x3D; &#39;&#39; &amp;&amp; empty($litpicname));\n$validFirstPic &#x3D; (!$hasone &amp;&amp; $ddisfirst);\nif ($validFirstPic &amp;&amp; $emptyPic) &#123;\n    $litpcname &#x3D; GetImageMapDD($iurl, $cfg_ddimg_width);;\n&#125;\n\n\n\n永远不要CV雷同的代码；\n相同的代码放一起让以后修改更轻松\n可以让全局的统计和过滤器等实现方便\n可复用的带参函数是解决雷同代码的好办法\n\n\n","slug":"05_PHP/代码优化","date":"2019-10-06T07:06:38.000Z","categories_index":"PHP","tags_index":"优化","author_index":"Michael"},{"id":"c7c9df441ac26b0eb6f306a3696b3570","title":"Redis常见的问题及方案","content":"为了便于大家查找问题，了解全貌，整理个目录，我们可以快速全局了解关于Redis 缓存，面试官一般喜欢问哪些问题？\n\n接下来，我们逐条来看看每个问题及解决方案\nRedis 有哪些特性？\n\n性能高， 读的速度是100000次&#x2F;s，写的速度是80000次&#x2F;s\n数据持久化，支持RDB 、AOF\n支持事务。通过MULTI和EXEC指令包起来。\n多种数据结构类型\n主从复制\n其他特性：发布&#x2F;订阅、通知、key过期等\n\nRedis 为什么这么快？\n\n完全基于内存，没有磁盘IO上的开销，异步持久化除外\n单线程，避免多个线程切换的性能损耗\n非阻塞的IO多路复用机制\n底层的数据存储结构优化，使用原生的数据结构提升性能。\n\nRedis 底层的基础数据结构有哪些？\n\n字符串。没有采用C语言的传统字符串，而是自己实现的一个简单动态字符串SDS的抽象类型，并保存了长度信息。\n链表（linkedlist）。双向无环链表结构，每个链表的节点由一个listNode结构来表示，每个节点都有前置和后置节点的指针\n字典（hashtable）。保存键值对的抽象数据结构，底层使用hash表，每个字典带有两个hash表，供平时使用和rehash时使用。\n跳跃表（skiplist）。跳跃表是有序集合的底层实现之一。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表 信息(表头、表尾节点、⻓度等)，zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1- 32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。\n整数集合（intset）。用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。\n压缩列表（ziplist）。为节约内存而开发的顺序性数据结构，可以包含多个节点，每个节点可以保存一个字节数组或者整数值。\n\nRedis 支持哪些数据类型？\n五种常用数据类型：String、Hash、Set、List、SortedSet。\n三种特殊的数据类型：Bitmap、HyperLogLog、Geospatial，\n​\t\t其中Bitmap 、HyperLogLog的底层都是 String 数据类型，\n​\t\tGeospatial 底层是 Sorted Set 数据类型。\n\n字符串对象string：int整数、embstr编码的简单动态字符串、raw简单动态字符串\n列表对象list：ziplist、linkedlist\n哈希对象hash：ziplist、hashtable\n集合对象set：intset、hashtable\n有序集合对象zset：ziplist、skiplist\n\nRedis 常用的 5 种数据结构和应用场景？\n\nString：缓存、计数器、分布式锁等\nList：链表、队列、微博关注人时间轴列表等\nHash：用户信息、Hash 表等\nSet：去重、赞、踩、共同好友等\nZset：访问量排行榜、点击量排行榜等\n\n为什么采用单线程？\nCPU不会成为Redis的制约瓶颈，Redis主要受内存、网络限制。例如，在一个普通的 Linux 系统上，使用pipelining 可以每秒传递 100 万个请求，所以如果您的应用程序主要使用 O(N) 或 O(log(N)) 命令，则几乎不会使用太多 CPU，属于IO密集型系统。\nRedis 6.0 之后又改用多线程呢?\nRedis的多线程主要是处理数据的读写、协议解析。执行命令还是采用单线程顺序执行。\n主要是因为redis的性能瓶颈在于网络IO而非CPU，使用多线程进行一些周边预处理，提升了IO的读写效率，从而提高了整体的吞吐量。antirez 在 RedisConf 2019 分享时提到，Redis 6 引入的多线程 IO 对性能提升至少一倍以上。\n过期键Key 的删除策略有哪些？\n有3种过期删除策略。\n惰性删除、定期删除、定时删除\n\n惰性删除。使用key时才进行检查，如果已经过期，则删除。缺点：过期的key如果没有被访问到，一直无法删除，一直占用内存，造成空间浪费。\n定期删除。每隔一段时间做一次检查，删除过期的key，每次只是随机取一些key去检查。\n定时删除。为每个key设置过期时间，同时创建一个定时器。一旦到期，立即执行删除。缺点：如果过期键比较多时，占用CPU较多，对服务的性能有很大影响。\n\n如果Redis的内存空间不足，淘汰机制？\n\nvolatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰\nallkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）\nvolatile-ttl：从已设置过期时间的key中，移出将要过期的key\nvolatile-random：从已设置过期时间的key中，随机选择key淘汰\nallkeys-random：从key中随机选择key进行淘汰\nno-eviction：禁止淘汰数据。当内存达到阈值的时候，新写入操作报错\nvolatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰(LFU(Least Frequently Used)算法，也就是最频繁被访问的数据将来最有可能被访问到)\nallkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。\n\nRedis 突然挂了怎么解决？\n1、从系统可用性角度思考，Redis Cluster引入主备机制，当主节点挂了后，自动切换到备用节点，继续提供服务。\n2、Client端引入本地缓存，通过开关切换，避免Redis突然挂掉，高并发流量把数据库打挂。\nRedis 持久化有哪些方式？\n1、快照RDB。将某个时间点上的数据库状态保存到RDB文件中，RDB文件是一个压缩的二进制文件，保存在磁盘上。当Redis崩溃时，可用于恢复数据。通过SAVE或BGSAVE来生成RDB文件。\n\nSAVE：会阻塞redis进程，直到RDB文件创建完毕，在进程阻塞期间，redis不能处理任何命令请求。\nBGSAVE：会fork出一个子进程，然后由子进程去负责生成RDB文件，父进程还可以继续处理命令请求，不会阻塞进程。\n\n2、只追加文件AOF。\n​\t以日志的形式记录每个写操作（非读操作）。当不同节点同步数据时，读取日志文件的内容将写指令从前到后执行一次，即可完成数据恢复。\nRedis 常用场景\n\n1、缓存，有句话说的好，「性能不够，缓存来凑」\n2、分布式锁，利用Redis 的 setnx\n3、分布式session\n4、计数器，通过incr命令\n5、排行榜，Redis 的 有序集合\n6、其他\n\nRedis 缓存要注意的七大经典问题？\n列举了亿级系统，高访问量情况下Redis缓存可能会遇到哪些问题？以及对应的解决方案。\n\n1、缓存集中失效\n2、缓存穿透\n3、缓存雪崩\n4、缓存热点\n5、缓存大Key\n6、缓存数据的一致性\n7、数据并发竞争预热\n\nRedis 集群方案有哪几种？\n\n主从复制模式\nSentinel（哨兵）模式\nRedis Cluster模式\n\nRedis 主从数据同步（主从复制）的过程？\n\n1、slave启动后，向master发送sync命令\n2、master收到sync之后，执行bgsave保存快照，生成RDB全量文件\n3、master把slave的写命令记录到缓存\n4、bgsave执行完毕之后，发送RDB文件到slave，slave执行\n5、master发送缓冲区的写命令给slave，slave接收命令并执行，完成复制初始化。\n6、此后，master每次执行一个写命令都会同步发送给slave，保持master与slave之间数据的一致性\n\n主从复制的优缺点？\n1、优点：\n\nmaster能自动将数据同步到slave，可以进行读写分离，分担master的读压力\nmaster、slave之间的同步是以非阻塞的方式进行的，同步期间，客户端仍然可以提交查询或更新请求\n\n缺点：\n\n不具备自动容错与恢复功能，master 节点宕机后，需要手动指定新的 master\nmaster宕机，如果宕机前数据没有同步完，则切换IP后会存在数据不一致的问题\n难以支持在线扩容，Redis的容量受限于单机配置\n\nSentinel（哨兵）模式的优缺点？\n哨兵模式基于主从复制模式，增加了哨兵来监控与自动处理故障。\n1、优点：\n\n哨兵模式基于主从复制模式，所以主从复制模式有的优点，哨兵模式也有\nmaster 挂掉可以自动进行切换，系统可用性更高\n\n2、缺点：\n\nRedis的容量受限于单机配置\n需要额外的资源来启动sentinel进程\n\nRedis Cluster 模式的优缺点？\n实现了Redis的分布式存储，即每台节点存储不同的内容，来解决在线扩容的问题。\n1、优点：\n\n无中心架构，数据按照slot分布在多个节点\n集群中的每个节点都是平等的，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。\n可线性扩展到1000多个节点，节点可动态添加或删除\n能够实现自动故障转移，节点之间通过gossip协议交换状态信息，用投票机制完成slave到master的角色转换\n\n缺点：\n\n数据通过异步复制，不保证数据的强一致性\nslave充当 “冷备”，不对外提供读、写服务，只作为故障转移使用。\n批量操作限制，目前只支持具有相同slot值的key执行批量操作，对mset、mget、sunion等操作支持不友好\nkey事务操作支持有限，只支持多key在同一节点的事务操作，多key分布在不同节点时无法使用事务功能\n不支持多数据库空间，一台redis可以支持16个db，集群模式下只能使用一个，即db 0。Redis Cluster模式不建议使用pipeline和multi-keys操作，减少max redirect产生的场景。\n\nRedis 如何做扩容？\n为了避免数据迁移失效，通常使用一致性哈希实现动态扩容缩容，有效减少需要迁移的Key数量。\n但是Cluster 模式，采用固定Slot槽位方式（16384个），对每个key计算CRC16值，然后对16384取模，然后根据slot值找到目标机器，扩容时，我们只需要迁移一部分的slot到新节点即可。\nRedis 的集群原理?\n一个redis集群由多个节点node组成，而多个node之间通过cluster meet命令来进行连接，组成一个集群。\n数据存储通过分片的形式，整个集群分成了16384个slot，每个节点负责一部分槽位。整个槽位的信息会同步到所有节点中。\nkey与slot的映射关系：\n\n健值对 key，进行 CRC16 计算，计算出一个 16 bit 的值\n将 16 bit 的值对 16384 取模，得到 0 ～ 16383 的数表示 key 对应的哈希槽\n\nRedis 如何做到高可用？\n哨兵机制。\n​\t具有自动故障转移、集群监控、消息通知等功能。\n​\t哨兵可以同时监视所有的主、从服务器，当某个master下线时，自动提升对应的slave为master，然后由新master对外提供服务。\n什么是 Redis 事务？\nRedis事务是一组命令的集合，将多个命令打包，然后把这些命令按顺序添加到队列中，并且按顺序执行这些命令。\nRedis事务中没有像Mysql关系型数据库事务隔离级别的概念，不能保证原子性操作，也没有像Mysql那样执行事务失败会进行回滚操作\nRedis 事务执行流程？\n通过MULTI、EXEC、WATCH等命令来实现事务机制，事务执行过程将一系列多个命令按照顺序一次性执行，在执行期间，事务不会被中断，也不会去执行客户端的其他请求，直到所有命令执行完毕。\n具体过程：\n\n服务端收到客户端请求，事务以MULTI开始\n如果正处于事务状态时，则会把后续命令放入队列同时返回给客户端QUEUED，反之则直接执行这 个命令\n当收到客户端的EXEC命令时，才会将队列里的命令取出、顺序执行，执行完将当前状态从事务状态改为非事务状态\n如果收到 DISCARD 命令，放弃执行队列中的命令，可以理解为Mysql的回滚操作，并且将当前的状态从事务状态改为非事务状态\n\n\n\n\n\n\n\n\n\n\nWATCH 监视某个key，该命令只能在MULTI命令之前执行。如果监视的key被其他客户端修改，EXEC将会放弃执行队列中的所有命令。UNWATCH 取消监视之前通过WATCH 命令监视的key。通过执行EXEC 、DISCARD 两个命令之前监视的key也会被取消监视。\nRedis 与 Guava 、Caffeine 有什么区别？\n缓存分为本地缓存和分布式缓存。\n1、Caffeine、Guava，属于本地缓存，特点：\n\n直接访问内存，速度快，受内存限制，无法进行大数据存储。\n无网络通讯开销，性能更高。\n只支持本地应用进程访问，同步更新所有节点的本地缓存数据成本较高。\n应用进程重启，数据会丢失。\n\n所以，本地缓存适合存储一些不易改变或者低频改变的高热点数据。\n2、Redis属于分布式缓存，特点：\n\n集群模式，支持大数据量存储\n数据集中存储，保证数据的一致性\n数据跨网络传输，性能低于本地缓存。但同一个机房，两台服务器之间请求跑一个来回也就需要500微秒，比起其优势，这点损耗完全可以忽略，这也是分布式缓存受欢迎的原因。\n支持副本机制，有效的保证了高可用性。\n\n如何实现一个分布式锁？\n\n1、数据库表，性能比较差\n2、使用Lua脚本 (包含 SETNX + EXPIRE 两条指令)\n3、SET的扩展命令（SET key value [EX][PX] [NX|XX]）\n4、Redlock 框架\n5、Zookeeper Curator框架提供了现成的分布式锁\n\n","slug":"02_Redis/Redis","date":"2022-08-20T08:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"6394dcbc9517d7089b969dfbe59af1da","title":"Redis全部","content":"基础1.说说什么是Redis?\nRedis图标\nRedis是一种基于键值对（key-value）的NoSQL数据库。\n比一般键值对数据库强大的地方，Redis中的value支持string（字符串）、hash（哈希）、 list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、 HyperLogLog、GEO（地理信息定位）等多种数据结构，因此 Redis可以满足很多的应用场景。\n而且因为Redis会将所有数据都存放在内存中，所以它的读写性能非常出色。\n不仅如此，Redis还可以将内存的数据利用快照和日志的形式保存到硬盘上，这样在发生类似断电或者机器故障的时候，内存中的数据不会“丢失”。\n除了上述功能以外，Redis还提供了键过期、发布订阅、事务、流水线、Lua脚本等附加功能。\n总之，Redis是一款强大的性能利器。\n2.Redis可以用来干什么？\nRedis\n\n缓存\n这是Redis应用最广泛地方，基本所有的Web应用都会使用Redis作为缓存，来降低数据源压力，提高响应速度。\n\n计数器 Redis天然支持计数功能，而且计数性能非常好，可以用来记录浏览量、点赞量等等。\n\n排行榜 Redis提供了列表和有序集合数据结构，合理地使用这些数据结构可以很方便地构建各种排行榜系统。\n\n社交网络 赞&#x2F;踩、粉丝、共同好友&#x2F;喜好、推送、下拉刷新。\n\n消息队列 Redis提供了发布订阅功能和阻塞队列的功能，可以满足一般消息队列功能。\n\n分布式锁 分布式环境下，利用Redis实现分布式锁，也是Redis常见的应用。\n\n\nRedis的应用一般会结合项目去问，以一个电商项目的用户服务为例：\n\nToken存储：用户登录成功之后，使用Redis存储Token\n登录失败次数计数：使用Redis计数，登录失败超过一定次数，锁定账号\n地址缓存：对省市区数据的缓存\n分布式锁：分布式环境下登录、注册等操作加分布式锁\n……\n\n3.Redis 有哪些数据结构？Redis有五种基本数据结构。\nstring\n字符串最基础的数据结构。字符串类型的值实际可以是字符串（简单的字符串、复杂的字符串（例如JSON、XML））、数字 （整数、浮点数），甚至是二进制（图片、音频、视频），但是值最大不能超过512MB。\n字符串主要有以下几个典型使用场景：\n\n缓存功能\n计数\n共享Session\n限速\n\nhash\n哈希类型是指键值本身又是一个键值对结构。\n哈希主要有以下典型应用场景：\n\n缓存用户信息\n缓存对象\n\nlist\n列表（list）类型是用来存储多个有序的字符串。列表是一种比较灵活的数据结构，它可以充当栈和队列的角色\n列表主要有以下几种使用场景：\n\n消息队列\n文章列表\n\nset\n集合（set）类型也是用来保存多个的字符串元素，但和列表类型不一 样的是，集合中不允许有重复元素，并且集合中的元素是无序的。\n集合主要有如下使用场景：\n\n标签（tag）\n共同关注\n\nsorted set\n有序集合中的元素可以排序。但是它和列表使用索引下标作为排序依据不同的是，它给每个元素设置一个权重（score）作为排序的依据。\n有序集合主要应用场景：\n\n用户点赞统计\n用户排序\n\n4.Redis为什么快呢？Redis的速度⾮常的快，单机的Redis就可以⽀撑每秒十几万的并发，相对于MySQL来说，性能是MySQL的⼏⼗倍。速度快的原因主要有⼏点：\n\n完全基于内存操作\n使⽤单线程，避免了线程切换和竞态产生的消耗\n基于⾮阻塞的IO多路复⽤机制\nC语⾔实现，优化过的数据结构，基于⼏种基础的数据结构，redis做了⼤量的优化，性能极⾼\n\n5.能说一下I&#x2F;O多路复用吗？引用知乎上一个高赞的回答来解释什么是I&#x2F;O多路复用。假设你是一个老师，让30个学生解答一道题目，然后检查学生做的是否正确，你有下面几个选择：\n\n第一种选择：按顺序逐个检查，先检查A，然后是B，之后是C、D。。。这中间如果有一个学生卡住，全班都会被耽误。这种模式就好比，你用循环挨个处理socket，根本不具有并发能力。\n第二种选择：你创建30个分身，每个分身检查一个学生的答案是否正确。这种类似于为每一个用户创建一个进程或者- 线程处理连接。\n第三种选择，你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。\n\n第一种就是阻塞IO模型，第三种就是I&#x2F;O复用模型。\n多路复用模型\nLinux系统有三种方式实现IO多路复用：select、poll和epoll。\n例如epoll方式是将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。\n这样，整个过程只在进行select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。\n6. Redis为什么早期选择单线程？官方解释：https://redis.io/topics/faq\n官方FAQ表示，因为Redis是基于内存的操作，CPU成为Redis的瓶颈的情况很少见，Redis的瓶颈最有可能是内存的大小或者网络限制。\n如果想要最大程度利用CPU，可以在一台机器上启动多个Redis实例。\nPS：网上有这样的回答，吐槽官方的解释有些敷衍，其实就是历史原因，开发者嫌多线程麻烦，后来这个CPU的利用问题就被抛给了使用者。\n同时FAQ里还提到了， Redis 4.0 之后开始变成多线程，除了主线程外，它也有后台线程在处理一些较为缓慢的操作，例如清理脏数据、无用连接的释放、大 Key 的删除等等。\n7.Redis6.0使用多线程是怎么回事?Redis不是说用单线程的吗？怎么6.0成了多线程的？\nRedis6.0的多线程是用多线程来处理数据的读写和协议解析，但是Redis执行命令还是单线程的。\n这样做的⽬的是因为Redis的性能瓶颈在于⽹络IO⽽⾮CPU，使⽤多线程能提升IO读写的效率，从⽽整体提⾼Redis的性能。\n持久化8.Redis持久化⽅式有哪些？有什么区别？Redis持久化⽅案分为RDB和AOF两种。\nRDB\nRDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发。\nRDB⽂件是⼀个压缩的⼆进制⽂件，通过它可以还原某个时刻数据库的状态。由于RDB⽂件是保存在硬盘上的，所以即使Redis崩溃或者退出，只要RDB⽂件存在，就可以⽤它来恢复还原数据库的状态。\n手动触发分别对应save和bgsave命令:\n\nsave命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。\nbgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。\n\n以下场景会自动触发RDB持久化：\n\n使用save相关配置，如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。\n如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点\n执行debug reload命令重新加载Redis时，也会自动触发save操作\n默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。\n\nAOF\nAOF（append only file）持久化：以独立日志的方式记录每次写命令， 重启时再重新执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。\nAOF的工作流程操作：命令写入 （append）、文件同步（sync）、文件重写（rewrite）、重启加载 （load）流程如下：\n1）所有的写入命令会追加到aof_buf（缓冲区）中。\n2）AOF缓冲区根据对应的策略向硬盘做同步操作。\n3）随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩 的目的。\n4）当Redis服务器重启时，可以加载AOF文件进行数据恢复。\n9.RDB 和 AOF 各自有什么优缺点？RDB | 优点\n\n只有一个紧凑的二进制文件 dump.rdb，非常适合备份、全量复制的场景。\n容灾性好，可以把RDB文件拷贝道远程机器或者文件系统张，用于容灾恢复。\n恢复速度快，RDB恢复数据的速度远远快于AOF的方式\n\nRDB | 缺点\n\n实时性低，RDB 是间隔一段时间进行持久化，没法做到实时持久化&#x2F;秒级持久化。如果在这一间隔事件发生故障，数据会丢失。\n存在兼容问题，Redis演进过程存在多个格式的RDB版本，存在老版本Redis无法兼容新版本RDB的问题。\n\nAOF | 优点\n\n实时性好，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次命令操作就记录到 aof 文件中一次。\n通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。\n\nAOF | 缺点\n\nAOF 文件比 RDB 文件大，且 恢复速度慢。\n数据集大 的时候，比 RDB 启动效率低。\n\n10.RDB和AOF如何选择？\n一般来说， 如果想达到足以媲美数据库的 数据安全性，应该 同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载入 AOF 文件来恢复原始的数据，因为在通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数据集要完整。\n如果 可以接受数分钟以内的数据丢失，那么可以 只使用 RDB 持久化。\n有很多用户都只使用 AOF 持久化，但并不推荐这种方式，因为定时生成 RDB 快照（snapshot）非常便于进行数据备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快，除此之外，使用 RDB 还可以避免 AOF 程序的 bug。\n如果只需要数据在服务器运行的时候存在，也可以不使用任何持久化方式。\n\n11.Redis的数据恢复？当Redis发生了故障，可以从RDB或者AOF中恢复数据。\n恢复的过程也很简单，把RDB或者AOF文件拷贝到Redis的数据目录下，如果使用AOF恢复，配置文件开启AOF，然后启动redis-server即可。\nRedis 启动时加载数据的流程：\n\nAOF持久化开启且存在AOF文件时，优先加载AOF文件。\nAOF关闭或者AOF文件不存在时，加载RDB文件。\n加载AOF&#x2F;RDB文件成功后，Redis启动成功。\nAOF&#x2F;RDB文件存在错误时，Redis启动失败并打印错误信息。\n\n12.Redis 4.0 的混合持久化了解吗？重启 Redis 时，我们很少使用 RDB 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 RDB 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。\nRedis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是 自持久化开始到持久化结束 的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小：\n于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。\n高可用Redis保证高可用主要有三种方式：主从、哨兵、集群。\n13.主从复制了解吗？Redis主从复制简图\n主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为 **主节点(master)**，后者称为 **从节点(slave)**。且数据的复制是 单向 的，只能由主节点到从节点。Redis 主从复制支持 主从同步 和 从从同步 两种，后者是 Redis 后续版本新增的功能，以减轻主节点的同步负担。\n\n\n\n\n\n\n\n\n\n主从复制主要的作用?\n\n数据冗余： 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。\n故障恢复： 当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复 *(实际上是一种服务的冗余)*。\n负载均衡： 在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 （即写 Redis 数据时应用连接主节点，读 Redis 数据时应用连接从节点），分担服务器负载。尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。\n高可用基石： 除了上述作用以外，主从复制还是哨兵和集群能够实施的 基础，因此说主从复制是 Redis 高可用的基础。\n\n14.Redis主从有几种常见的拓扑结构？Redis的复制拓扑结构可以支持单层或多层复制关系，根据拓扑复杂性可以分为以下三种：一主一从、一主多从、树状主从结构。\n1.一主一从结构\n一主一从结构是最简单的复制拓扑结构，用于主节点出现宕机时从节点提供故障转移支持。2.一主多从结构\n一主多从结构（又称为星形拓扑结构）使得应用端可以利用多个从节点实现读写分离（见图6-5）。对于读占比较大的场景，可以把读命令发送到从节点来分担主节点压力。3.树状主从结构\n树状主从结构（又称为树状拓扑结构）使得从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下层复制。通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量。\n15.Redis的主从复制原理了解吗？Redis主从复制的工作流程大概可以分为如下几步：\n\n保存主节点（master）信息 这一步只是保存主节点信息，保存主节点的ip和port。\n主从建立连接 从节点（slave）发现新的主节点后，会尝试和主节点建立网络连接。\n发送ping命令 连接建立成功后从节点发送ping请求进行首次通信，主要是检测主从之间网络套接字是否可用、主节点当前是否可接受处理命令。\n权限验证 如果主节点要求密码验证，从节点必须正确的密码才能通过验证。\n同步数据集 主从复制连接正常通信后，主节点会把持有的数据全部发送给从节点。\n命令持续复制 接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性。\n\n16.说说主从数据同步的方式？Redis在2.8及以上版本使用psync命令完成主从数据同步，同步过程分为：全量复制和部分复制。\n主从数据同步方式\n全量复制一般用于初次复制场景，Redis早期支持的复制功能只有全量复制，它会把主节点全部数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销。\n全量复制的完整运行流程如下：\n\n发送psync命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行ID，所以发送psync-1。\n主节点根据psync-1解析出当前为全量复制，回复+FULLRESYNC响应。\n从节点接收主节点的响应数据保存运行ID和偏移量offset\n主节点执行bgsave保存RDB文件到本地\n主节点发送RDB文件给从节点，从节点把接收的RDB文件保存在本地并直接作为从节点的数据文件\n对于从节点开始接收RDB快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写命令数据保存在复制客户端缓冲区内，当从节点加载完RDB文件后，主节点再把缓冲区内的数据发送给从节点，保证主从之间数据一致性。\n从节点接收完主节点传送来的全部数据后会清空自身旧数据\n从节点清空数据后开始加载RDB文件\n从节点成功加载完RDB后，如果当前节点开启了AOF持久化功能， 它会立刻做bgrewriteaof操作，为了保证全量复制后AOF持久化文件立刻可用。\n\n部分复制部分复制主要是Redis针对全量复制的过高开销做出的一种优化措施， 使用psync{runId}{offset}命令实现。当从节点（slave）正在复制主节点 （master）时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向 主节点要求补发丢失的命令数据，如果主节点的复制积压缓冲区内存在这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。\n\n当主从节点之间网络出现中断时，如果超过repl-timeout时间，主节点会认为从节点故障并中断复制连接\n主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存1MB。\n当主从节点网络恢复后，从节点会再次连上主节点\n当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当作psync参数发送给主节点，要求进行部分复制操作。\n主节点接到psync命令后首先核对参数runId是否与自身一致，如果一 致，说明之前复制的是当前主节点；之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送+CONTINUE响应，表示可以进行部分复制。\n主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。\n\n17.主从复制存在哪些问题呢？主从复制虽好，但也存在一些问题：\n\n一旦主节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令其他从节点去复制新的主节点，整个过程都需要人工干预。\n主节点的写能力受到单机的限制。\n主节点的存储能力受到单机的限制。\n\n第一个问题是Redis的高可用问题，第二、三个问题属于Redis的分布式问题。\n18.Redis Sentinel（哨兵）了解吗？主从复制存在一个问题，没法完成自动故障转移。所以我们需要一个方案来完成自动故障转移，它就是Redis Sentinel（哨兵）。\nRedis Sentinel\nRedis Sentinel ，它由两部分组成，哨兵节点和数据节点：\n\n哨兵节点： 哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的 Redis 节点，不存储数据，对数据节点进行监控。\n数据节点： 主节点和从节点都是数据节点；\n\n在复制的基础上，哨兵实现了 自动化的故障恢复 功能，下面是官方对于哨兵功能的描述：\n\n监控（Monitoring）： 哨兵会不断地检查主节点和从节点是否运作正常。\n自动故障转移（Automatic failover）： 当 主节点 不能正常工作时，哨兵会开始 自动故障转移操作，它会将失效主节点的其中一个 从节点升级为新的主节点，并让其他从节点改为复制新的主节点。\n配置提供者（Configuration provider）： 客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址。\n通知（Notification）： 哨兵可以将故障转移的结果发送给客户端。\n\n其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移。而配置提供者和通知功能，则需要在与客户端的交互中才能体现。\n19.Redis Sentinel（哨兵）实现原理知道吗？哨兵模式是通过哨兵节点完成对数据节点的监控、下线、故障转移。\n\n定时监控Redis Sentinel通过三个定时监控任务完成对各个节点发现和监控：\n\n\n每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构\n每隔2秒，每个Sentinel节点会向Redis数据节点的__sentinel__：hello 频道上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息\n每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达\n\n\n主观下线和客观下线主观下线就是哨兵节点认为某个节点有问题，客观下线就是超过一定数量的哨兵节点认为主节点有问题。\n\n\n\n主观下线 每个Sentinel节点会每隔1秒对主节点、从节点、其他Sentinel节点发送ping命令做心跳检测，当这些节点超过 down-after-milliseconds没有进行有效回复，Sentinel节点就会对该节点做失败判定，这个行为叫做主观下线。\n客观下线 当Sentinel主观下线的节点是主节点时，该Sentinel节点会通过sentinel is- master-down-by-addr命令向其他Sentinel节点询问对主节点的判断，当超过 个数，Sentinel节点认为主节点确实有问题，这时该Sentinel节点会做出客观下线的决定\n\n\n领导者Sentinel节点选举Sentinel节点之间会做一个领导者选举的工作，选出一个Sentinel节点作为领导者进行故障转移的工作。Redis使用了Raft算法实现领导者选举。\n\n故障转移\n领导者选举出的Sentinel节点负责故障转移，过程如下：\n\n\n在从节点列表中选出一个节点作为新的主节点，这一步是相对复杂一些的一步\nSentinel领导者节点会对第一步选出来的从节点执行slaveof no one命令让其成为主节点\nSentinel领导者节点会向剩余的从节点发送命令，让它们成为新主节点的从节点\nSentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点\n\n\n\n20.领导者Sentinel节点选举了解吗？Redis使用了Raft算法实 现领导者选举，大致流程如下：\n\n每个在线的Sentinel节点都有资格成为领导者，当它确认主节点主观 下线时候，会向其他Sentinel节点发送sentinel is-master-down-by-addr命令， 要求将自己设置为领导者。\n收到命令的Sentinel节点，如果没有同意过其他Sentinel节点的sentinel is-master-down-by-addr命令，将同意该请求，否则拒绝。\n如果该Sentinel节点发现自己的票数已经大于等于max（quorum， num（sentinels）&#x2F;2+1），那么它将成为领导者。\n如果此过程没有选举出领导者，将进入下一次选举。\n\n21.新的主节点是怎样被挑选出来的？选出新的主节点，大概分为这么几步：\n\n过滤：“不健康”（主观下线、断线）、5秒内没有回复过Sentinel节 点ping响应、与主节点失联超过down-after-milliseconds*10秒。\n选择slave-priority（从节点优先级）最高的从节点列表，如果存在则返回，不存在则继续。\n选择复制偏移量最大的从节点（复制的最完整），如果存在则返 回，不存在则继续。\n选择runid最小的从节点。\n\n22.Redis 集群了解吗？前面说到了主从存在高可用和分布式的问题，哨兵解决了高可用的问题，而集群就是终极方案，一举解决高可用和分布式问题。\n\n数据分区： 数据分区 (或称数据分片) 是集群最核心的功能。集群将数据分散到多个节点，一方面 突破了 Redis 单机内存大小的限制，存储容量大大增加；另一方面 每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。\n高可用： 集群支持主从复制和主节点的 自动故障转移 （与哨兵类似），当任一节点发生故障时，集群仍然可以对外提供服务。\n\n23.集群中数据如何分区？分布式的存储中，要把数据集按照分区规则映射到多个节点，常见的数据分区规则三种：\n方案一：节点取余分区节点取余分区，非常好理解，使用特定的数据，比如Redis的键，或者用户ID之类，对响应的hash值取余：hash（key）%N，来确定数据映射到哪一个节点上。\n不过该方案最大的问题是，当节点数量变化时，如扩容或收缩节点，数据节点映射关 系需要重新计算，会导致数据的重新迁移。\n节点取余分区\n方案二：一致性哈希分区将整个 Hash 值空间组织成一个虚拟的圆环，然后将缓存节点的 IP 地址或者主机名做 Hash 取值后，放置在这个圆环上。当我们需要确定某一个 Key 需 要存取到哪个节点上的时候，先对这个 Key 做同样的 Hash 取值，确定在环上的位置，然后按照顺时针方向在环上“行走”，遇到的第一个缓存节点就是要访问的节点。\n比如说下面 这张图里面，Key 1 和 Key 2 会落入到 Node 1 中，Key 3、Key 4 会落入到 Node 2 中，Key 5 落入到 Node 3 中，Key 6 落入到 Node 4 中。\n这种方式相比节点取余最大的好处在于加入和删除节点只影响哈希环中 相邻的节点，对其他节点无影响。\n但它还是存在问题：\n\n缓存节点在圆环上分布不平均，会造成部分缓存节点的压力较大\n当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成力。\n\n方案三：虚拟槽分区这个方案 一致性哈希分区的基础上，引入了 虚拟节点 的概念。Redis 集群使用的便是该方案，其中的虚拟节点称为 槽（slot）。槽是介于数据和实际节点之间的虚拟概念，每个实际节点包含一定数量的槽，每个槽包含哈希值在一定范围内的数据。\n在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点 之间的关系，增加或删除节点对系统的影响很小。仍以上图为例，系统中有 4 个实际节点，假设为其分配 16 个槽(0-15)；\n\n槽 0-3 位于 node1；4-7 位于 node2；以此类推….\n\n如果此时删除 node2，只需要将槽 4-7 重新分配即可，例如槽 4-5 分配给 node1，槽 6 分配给 node3，槽 7 分配给 node4，数据在其他节点的分布仍然较为均衡。\n24.能说说Redis集群的原理吗？Redis集群通过数据分区来实现数据的分布式存储，通过自动故障转移实现高可用。\n集群创建数据分区是在集群创建的时候完成的。\n设置节点Redis集群一般由多个节点组成，节点数量至少为6个才能保证组成完整高可用的集群。每个节点需要开启配置cluster-enabled yes，让Redis运行在集群模式下。节点握手节点握手是指一批运行在集群模式下的节点通过Gossip协议彼此通信， 达到感知对方的过程。节点握手是集群彼此通信的第一步，由客户端发起命 令：cluster meet{ip}{port}。完成节点握手之后，一个个的Redis节点就组成了一个多节点的集群。\n分配槽（slot）Redis集群把所有的数据映射到16384个槽中。每个节点对应若干个槽，只有当节点分配了槽，才能响应和这些槽关联的键命令。通过 cluster addslots命令为节点分配槽。\n分配槽\n故障转移Redis集群的故障转移和哨兵的故障转移类似，但是Redis集群中所有的节点都要承担状态维护的任务。\n故障发现Redis集群内节点通过ping&#x2F;pong消息实现节点通信，集群中每个节点都会定期向其他节点发送ping消息，接收节点回复pong 消息作为响应。如果在cluster-node-timeout时间内通信一直失败，则发送节 点会认为接收节点存在故障，把接收节点标记为主观下线（pfail）状态。当某个节点判断另一个节点主观下线后，相应的节点状态会跟随消息在集群内传播。通过Gossip消息传播，集群内节点不断收集到故障节点的下线报告。当 半数以上持有槽的主节点都标记某个节点是主观下线时。触发客观下线流程。\n故障恢复\n故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它 的从节点中选出一个替换它，从而保证集群的高可用。\n故障恢复流程\n\n资格检查 每个从节点都要检查最后与主节点断线时间，判断是否有资格替换故障 的主节点。\n准备选举时间 当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该 时间后才能执行后续流程。\n发起选举 当从节点定时任务检测到达故障选举时间（failover_auth_time）到达后，发起选举流程。\n选举投票 持有槽的主节点处理故障选举消息。投票过程其实是一个领导者选举的过程，如集群内有N个持有槽的主节 点代表有N张选票。由于在每个配置纪元内持有槽的主节点只能投票给一个 从节点，因此只能有一个从节点获得N&#x2F;2+1的选票，保证能够找出唯一的从节点。\n替换主节点 当从节点收集到足够的选票之后，触发替换主节点操作。\n\n\n\n\n\n\n\n\n\n\n部署Redis集群至少需要几个物理节点？\n在投票选举的环节，故障主节点也算在投票数内，假设集群内节点规模是3主3从，其中有2 个主节点部署在一台机器上，当这台机器宕机时，由于从节点无法收集到 3&#x2F;2+1个主节点选票将导致故障转移失败。这个问题也适用于故障发现环节。因此部署集群时所有主节点最少需要部署在3台物理机上才能避免单点问题。\n25.说说集群的伸缩？Redis集群提供了灵活的节点扩容和收缩方案，可以在不影响集群对外服务的情况下，为集群添加节点进行扩容也可以下线部分节点进行缩容。其实，集群扩容和缩容的关键点，就在于槽和节点的对应关系，扩容和缩容就是将一部分槽和数据迁移给新节点。\n例如下面一个集群，每个节点对应若干个槽，每个槽对应一定的数据，如果希望加入1个节点希望实现集群扩容时，需要通过相关命令把一部分槽和内容迁移给新节点。缩容也是类似，先把槽和数据迁移到其它节点，再把对应的节点下线。\n缓存设计26.什么是缓存击穿、缓存穿透、缓存雪崩？PS:这是多年黄历的老八股了，一定要理解清楚。\n缓存击穿一个并发访问量比较大的key在某个时间过期，导致所有的请求直接打在DB上。\n解决⽅案：\n\n加锁更新，⽐如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写⼊缓存，再返回给⽤户，这样后⾯的请求就可以从缓存中拿到数据了。\n将过期时间组合写在value中，通过异步的⽅式不断的刷新过期时间，防⽌此类现象。\n\n缓存穿透缓存穿透指的查询缓存和数据库中都不存在的数据，这样每次请求直接打到数据库，就好像缓存不存在一样。\n缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。\n缓存穿透可能会使后端存储负载加大，如果发现大量存储层空命中，可能就是出现了缓存穿透问题。\n缓存穿透可能有两种原因：\n\n自身业务代码问题\n恶意攻击，爬虫造成空命中\n\n它主要有两种解决办法：\n\n缓存空值&#x2F;默认值\n\n一种方式是在数据库不命中之后，把一个空对象或者默认值保存到缓存，之后再访问这个数据，就会从缓存中获取，这样就保护了数据库。\n缓存空值&#x2F;默认值\n缓存空值有两大问题：\n\n空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间（如果是攻击，问题更严重），比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。\n缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致。这时候可以利用消息队列或者其它异步方式清理缓存中的空对象。\n\n\n布隆过滤器除了缓存空对象，我们还可以在存储和缓存之前，加一个布隆过滤器，做一层过滤。\n\n布隆过滤器里会保存数据是否存在，如果判断数据不不能再，就不会访问存储。两种解决方案的对比：\n缓存雪崩某⼀时刻发⽣⼤规模的缓存失效的情况，例如缓存服务宕机、大量key在同一时间过期，这样的后果就是⼤量的请求进来直接打到DB上，可能导致整个系统的崩溃，称为雪崩。\n缓存雪崩是三大缓存问题里最严重的一种，我们来看看怎么预防和处理。\n\n提高缓存可用性\n\n\n集群部署：通过集群来提升缓存的可用性，可以利用Redis本身的Redis Cluster或者第三方集群方案如Codis等。\n多级缓存：设置多级缓存，第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同。\n\n\n过期时间\n\n\n均匀过期：为了避免大量的缓存在同一时间过期，可以把不同的 key 过期时间随机生成，避免过期时间太过集中。\n热点数据永不过期。\n\n\n熔断降级\n\n\n服务熔断：当缓存服务器宕机或超时响应时，为了防止整个系统出现雪崩，暂时停止业务服务访问缓存系统。\n服务降级：当出现大量缓存失效，而且处在高并发高负荷的情况下，在业务系统内部暂时舍弃对一些非核心的接口和数据的请求，而直接返回一个提前准备好的 fallback（退路）错误处理信息。\n\n27.能说说布隆过滤器吗？布隆过滤器，它是一个连续的数据结构，每个存储位存储都是一个bit，即0或者1, 来标识数据是否存在。\n存储数据的时时候，使用K个不同的哈希函数将这个变量映射为bit列表的的K个点，把它们置为1。\n我们判断缓存key是否存在，同样，K个哈希函数，映射到bit列表上的K个点，判断是不是1：\n\n如果全不是1，那么key不存在；\n如果都是1，也只是表示key可能存在。\n\n布隆过滤器也有一些缺点：\n\n它在判断元素是否在集合中时是有一定错误几率，因为哈希算法有一定的碰撞的概率。\n不支持删除元素。\n\n28.如何保证缓存和数据库数据的⼀致性？根据CAP理论，在保证可用性和分区容错性的前提下，无法保证一致性，所以缓存和数据库的绝对一致是不可能实现的，只能尽可能保存缓存和数据库的最终一致性。\n选择合适的缓存更新策略1. 删除缓存而不是更新缓存\n当一个线程对缓存的key进行写操作的时候，如果其它线程进来读数据库的时候，读到的就是脏数据，产生了数据不一致问题。\n相比较而言，删除缓存的速度比更新缓存的速度快很多，所用时间相对也少很多，读脏数据的概率也小很多。\n\n先更数据，后删缓存先更数据库还是先删缓存？这是一个问题。\n\n更新数据，耗时可能在删除缓存的百倍以上。在缓存中不存在对应的key，数据库又没有完成更新的时候，如果有线程进来读取数据，并写入到缓存，那么在更新成功之后，这个key就是一个脏数据。\n毫无疑问，先删缓存，再更数据库，缓存中key不存在的时间的时间更长，有更大的概率会产生脏数据。\n目前最流行的缓存读写策略cache-aside-pattern就是采用先更数据库，再删缓存的方式。\n缓存不一致处理如果不是并发特别高，对缓存依赖性很强，其实一定程序的不一致是可以接受的。\n但是如果对一致性要求比较高，那就得想办法保证缓存和数据库中数据一致。\n缓存和数据库数据不一致常见的两种原因：\n\n缓存key删除失败\n并发导致写入了脏数据\n\n缓存一致性\n消息队列保证key被删除可以引入消息队列，把要删除的key或者删除失败的key丢尽消息队列，利用消息队列的重试机制，重试删除对应的key。\n这种方案看起来不错，缺点是对业务代码有一定的侵入性。\n数据库订阅+消息队列保证key被删除可以用一个服务（比如阿里的 canal）去监听数据库的binlog，获取需要操作的数据。\n然后用一个公共的服务获取订阅程序传来的信息，进行缓存删除操作。这种方式降低了对业务的侵入，但其实整个系统的复杂度是提升的，适合基建完善的大厂。\n延时双删防止脏数据还有一种情况，是在缓存不存在的时候，写入了脏数据，这种情况在先删缓存，再更数据库的缓存更新策略下发生的比较多，解决方案是延时双删。\n简单说，就是在第一次删除缓存之后，过了一段时间之后，再次删除缓存。\n延时双删\n这种方式的延时时间设置需要仔细考量和测试。\n设置缓存过期时间兜底\n这是一个朴素但是有用的办法，给缓存设置一个合理的过期时间，即使发生了缓存数据不一致的问题，它也不会永远不一致下去，缓存过期的时候，自然又会恢复一致。\n29.如何保证本地缓存和分布式缓存的一致？PS:这道题面试很少问，但实际工作中很常见。\n在日常的开发中，我们常常采用两级缓存：本地缓存+分布式缓存。\n所谓本地缓存，就是对应服务器的内存缓存，比如Caffeine，分布式缓存基本就是采用Redis。\n那么问题来了，本地缓存和分布式缓存怎么保持数据一致？Redis缓存，数据库发生更新，直接删除缓存的key即可，因为对于应用系统而言，它是一种中心化的缓存。\n但是本地缓存，它是非中心化的，散落在分布式服务的各个节点上，没法通过客户端的请求删除本地缓存的key，所以得想办法通知集群所有节点，删除对应的本地缓存key。\n可以采用消息队列的方式：\n\n采用Redis本身的Pub&#x2F;Sub机制，分布式集群的所有节点订阅删除本地缓存频道，删除Redis缓存的节点，同事发布删除本地缓存消息，订阅者们订阅到消息后，删除对应的本地key。但是Redis的发布订阅不是可靠的，不能保证一定删除成功。\n引入专业的消息队列，比如RocketMQ，保证消息的可靠性，但是增加了系统的复杂度。\n设置适当的过期时间兜底，本地缓存可以设置相对短一些的过期时间。\n\n30.怎么处理热key？\n\n\n\n\n\n\n\n\n什么是热Key？所谓的热key，就是访问频率比较的key。\n比如，热门新闻事件或商品，这类key通常有大流量的访问，对存储这类信息的 Redis来说，是不小的压力。\n假如Redis集群部署，热key可能会造成整体流量的不均衡，个别节点出现OPS过大的情况，极端情况下热点key甚至会超过 Redis本身能够承受的OPS。\n\n\n\n\n\n\n\n\n\n怎么处理热key？\n对热key的处理，最关键的是对热点key的监控，可以从这些端来监控热点key:\n\n客户端 客户端其实是距离key“最近”的地方，因为Redis命令就是从客户端发出的，例如在客户端设置全局字典（key和调用次数），每次调用Redis命令时，使用这个字典进行记录。\n代理端 像Twemproxy、Codis这些基于代理的Redis分布式架构，所有客户端的请求都是通过代理端完成的，可以在代理端进行收集统计。\nRedis服务端 使用monitor命令统计热点key是很多开发和运维人员首先想到，monitor命令可以监控到Redis执行的所有命令。\n\n只要监控到了热key，对热key的处理就简单了：\n\n把热key打散到不同的服务器，降低压⼒\n加⼊⼆级缓存，提前加载热key数据到内存中，如果redis宕机，⾛内存查询\n\n31.缓存预热怎么做呢？所谓缓存预热，就是提前把数据库里的数据刷到缓存里，通常有这些方法：\n1、直接写个缓存刷新页面或者接口，上线时手动操作\n2、数据量不大，可以在项目启动的时候自动进行加载\n3、定时任务刷新缓存.\n32.热点key重建？问题？解决？开发的时候一般使用“缓存+过期时间”的策略，既可以加速数据读写，又保证数据的定期更新，这种模式基本能够满足绝大部分需求。\n但是有两个问题如果同时出现，可能就会出现比较大的问题：\n\n当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。\n重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的 SQL、多次IO、多个依赖等。在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。\n\n\n\n\n\n\n\n\n\n\n怎么处理呢？\n要解决这个问题也不是很复杂，解决问题的要点在于：\n\n减少重建缓存的次数。\n数据尽可能一致。\n较少的潜在危险。\n\n所以一般采用如下方式：\n\n互斥锁（mutex key） 这种方法只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。\n永远不过期 “永远不过期”包含两层意思：\n\n\n从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。\n从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。\n\n33.无底洞问题吗？如何解决？\n\n\n\n\n\n\n\n\n什么是无底洞问题？\n2010年，Facebook的Memcache节点已经达到了3000个，承载着TB级别的缓存数据。但开发和运维人员发现了一个问题，为了满足业务要求添加了大量新Memcache节点，但是发现性能不但没有好转反而下降了，当时将这 种现象称为缓存的“无底洞”现象。\n那么为什么会产生这种现象呢?\n通常来说添加节点使得Memcache集群 性能应该更强了，但事实并非如此。键值数据库由于通常采用哈希函数将 key映射到各个节点上，造成key的分布与业务无关，但是由于数据量和访问量的持续增长，造成需要添加大量节点做水平扩容，导致键值分布到更多的 节点上，所以无论是Memcache还是Redis的分布式，批量操作通常需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，分布式批量操作会涉及多次网络时间。\n\n\n\n\n\n\n\n\n\n无底洞问题如何优化呢？\n先分析一下无底洞问题：\n\n客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着节点的增多，耗时会不断增大。\n网络连接数变多，对节点的性能也有一定影响。\n\n常见的优化思路如下：\n\n命令本身的优化，例如优化操作语句等。\n减少网络通信次数。\n降低接入成本，例如客户端使用长连&#x2F;连接池、NIO等。\n\nRedis运维34.Redis报内存不足怎么处理？Redis 内存不足有这么几种处理方式：\n\n修改配置文件 redis.conf 的 maxmemory 参数，增加 Redis 可用内存\n也可以通过命令set maxmemory动态设置内存上限\n修改内存淘汰策略，及时释放内存空间\n使用 Redis 集群模式，进行横向扩容。\n\n35.Redis的过期数据回收策略有哪些？Redis主要有2种过期数据回收策略：\n惰性删除\n惰性删除指的是当我们查询key的时候才对key进⾏检测，如果已经达到过期时间，则删除。显然，他有⼀个缺点就是如果这些过期的key没有被访问，那么他就⼀直⽆法被删除，⽽且⼀直占⽤内存。\n定期删除\n定期删除指的是Redis每隔⼀段时间对数据库做⼀次检查，删除⾥⾯的过期key。由于不可能对所有key去做轮询来删除，所以Redis会每次随机取⼀些key去做检查和删除。\n36.Redis有哪些内存溢出控制&#x2F;内存淘汰策略？Redis所用内存达到maxmemory上限时会触发相应的溢出控制策略，Redis支持六种策略：\n\nnoeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返 回客户端错误信息，此 时Redis只响应读操作。\nvolatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直 到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略。\nallkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性， 直到腾出足够空间为止。\nallkeys-random：随机删除所有键，直到腾出足够空间为止。\nvolatile-random：随机删除过期键，直到腾出足够空间为止。\nvolatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果 没有，回退到noeviction策略。\n\n37.Redis阻塞？怎么解决？Redis发生阻塞，可以从以下几个方面排查：\n\nAPI或数据结构使用不合理\n通常Redis执行命令速度非常快，但是不合理地使用命令，可能会导致执行速度很慢，导致阻塞，对于高并发的场景，应该尽量避免在大对象上执行算法复杂 度超过O（n）的命令。\n对慢查询的处理分为两步：\n\n\n发现慢查询：slowlog get{n}命令可以获取最近 的n条慢查询命令；\n发现慢查询后，可以从两个方向去优化慢查询：1）修改为低算法复杂度的命令，如hgetall改为hmget等，禁用keys、sort等命 令 2）调整大对象：缩减大对象数据或把大对象拆分为多个小对象，防止一次命令操作过多的数据。\n\n\nCPU饱和的问题\n单线程的Redis处理命令时只能使用一个CPU。而CPU饱和是指Redis单核CPU使用率跑到接近100%。\n针对这种情况，处理步骤一般如下：\n\n\n判断当前Redis并发量是否已经达到极限，可以使用统计命令redis-cli-h{ip}-p{port}–stat获取当前 Redis使用情况\n如果Redis的请求几万+，那么大概就是Redis的OPS已经到了极限，应该做集群化水品扩展来分摊OPS压力\n如果只有几百几千，那么就得排查命令和内存的使用\n\n\n持久化相关的阻塞\n对于开启了持久化功能的Redis节点，需要排查是否是持久化导致的阻塞。\n\n\nfork阻塞 fork操作发生在RDB和AOF重写时，Redis主线程调用fork操作产生共享 内存的子进程，由子进程完成持久化文件重写工作。如果fork操作本身耗时过长，必然会导致主线程的阻塞。\nAOF刷盘阻塞 当我们开启AOF持久化功能时，文件刷盘的方式一般采用每秒一次，后台线程每秒对AOF文件做fsync操作。当硬盘压力过大时，fsync操作需要等 待，直到写入完成。如果主线程发现距离上一次的fsync成功超过2秒，为了 数据安全性它会阻塞直到后台线程执行fsync操作完成。\nHugePage写操作阻塞 对于开启Transparent HugePages的 操作系统，每次写命令引起的复制内存页单位由4K变为2MB，放大了512 倍，会拖慢写操作的执行时间，导致大量写操作慢查询。\n\n\n\n38.大key问题了解吗？Redis使用过程中，有时候会出现大key的情况， 比如：\n\n单个简单的key存储的value很大，size超过10KB\nhash， set，zset，list 中存储过多的元素（以万为单位）\n\n\n\n\n\n\n\n\n\n\n大key会造成什么问题呢？\n\n客户端耗时增加，甚至超时\n对大key进行IO操作时，会严重占用带宽和CPU\n造成Redis集群中数据倾斜\n主动删除、被动删等，可能会导致阻塞\n\n\n\n\n\n\n\n\n\n\n如何找到大key?\n\nbigkeys命令：使用bigkeys命令以遍历的方式分析Redis实例中的所有Key，并返回整体统计信息与每个数据类型中Top1的大Key\nredis-rdb-tools：redis-rdb-tools是由Python写的用来分析Redis的rdb快照文件用的工具，它可以把rdb快照文件生成json文件或者生成报表用来分析Redis的使用详情。\n\n\n\n\n\n\n\n\n\n\n如何处理大key?\n大key处理\n\n删除大key\n\n\n当Redis版本大于4.0时，可使用UNLINK命令安全地删除大Key，该命令能够以非阻塞的方式，逐步地清理传入的Key。\n当Redis版本小于4.0时，避免使用阻塞式命令KEYS，而是建议通过SCAN命令执行增量迭代扫描key，然后判断进行删除。\n\n\n压缩和拆分key\n\n\n当vaule是string时，比较难拆分，则使用序列化、压缩算法将key的大小控制在合理范围内，但是序列化和反序列化都会带来更多时间上的消耗。\n当value是string，压缩之后仍然是大key，则需要进行拆分，一个大key分为不同的部分，记录每个部分的key，使用multiget等操作实现事务读取。\n当value是list&#x2F;set等集合类型时，根据预估的数据规模来进行分片，不同的元素计算后分到不同的片。\n\n\n\n39.Redis常见性能问题和解决方案？\nMaster 最好不要做任何持久化工作，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做持久化。\n如果数据比较关键，某个 Slave 开启 AOF 备份数据，策略为每秒同步一次。\n为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。\n尽量避免在压力较大的主库上增加从库。\nMaster 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。\n为了 Master 的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关为：Master&lt;–Slave1&lt;–Slave2&lt;–Slave3…，这样的结构也方便解决单点故障问题，实现 Slave 对 Master 的替换，也即，如果 Master 挂了，可以立马启用 Slave1 做 Master，其他不变。\n\nRedis应用40.使用Redis 如何实现异步队列？我们知道redis支持很多种结构的数据，那么如何使用redis作为异步队列使用呢？一般有以下几种方式：\n\n使用list作为队列，lpush生产消息，rpop消费消息\n\n这种方式，消费者死循环rpop从队列中消费消息。但是这样，即使队列里没有消息，也会进行rpop，会导致Redis CPU的消耗。可以通过让消费者休眠的方式的方式来处理，但是这样又会又消息的延迟问题。\n-使用list作为队列，lpush生产消息，brpop消费消息\nbrpop是rpop的阻塞版本，list为空的时候，它会一直阻塞，直到list中有值或者超时。\n这种方式只能实现一对一的消息队列。\n\n使用Redis的pub&#x2F;sub来进行消息的发布&#x2F;订阅\n\n发布&#x2F;订阅模式可以1：N的消息发布&#x2F;订阅。发布者将消息发布到指定的频道频道（channel），订阅相应频道的客户端都能收到消息。\n但是这种方式不是可靠的，它不保证订阅者一定能收到消息，也不进行消息的存储。\n所以，一般的异步队列的实现还是交给专业的消息队列。\n41.Redis 如何实现延时队列?\n使用zset，利用排序实现\n\n可以使用 zset这个结构，用设置好的时间戳作为score进行排序，使用 zadd score1 value1 ….命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务，通过循环执行队列任务即可。\n42.Redis 支持事务吗？Redis提供了简单的事务，但它对事务ACID的支持并不完备。\nmulti命令代表事务开始，exec命令代表事务结束，它们之间的命令是原子顺序执行的：\n127.0.0.1:6379&gt; multi \nOK\n127.0.0.1:6379&gt; sadd user:a:follow user:b \nQUEUED \n127.0.0.1:6379&gt; sadd user:b:fans user:a \nQUEUED\n127.0.0.1:6379&gt; sismember user:a:follow user:b \n(integer) 0\n127.0.0.1:6379&gt; exec 1) (integer) 1\n2) (integer) 1\n\nRedis事务的原理，是所有的指令在 exec 之前不执行，而是缓存在 服务器的一个事务队列中，服务器一旦收到 exec 指令，才开执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。\n因为Redis执行命令是单线程的，所以这组命令顺序执行，而且不会被其它线程打断。\nRedis事务的注意点有哪些？\n需要注意的点有：\n\nRedis 事务是不支持回滚的，不像 MySQL 的事务一样，要么都执行要么都不执行；\nRedis 服务端在执行事务的过程中，不会被其他客户端发送来的命令请求打断。直到事务命令全部执行完毕才会执行其他客户端的命令。\n\nRedis 事务为什么不支持回滚？\nRedis 的事务不支持回滚。\n如果执行的命令有语法错误，Redis 会执行失败，这些问题可以从程序层面捕获并解决。但是如果出现其他问题，则依然会继续执行余下的命令。\n这样做的原因是因为回滚需要增加很多工作，而不支持回滚则可以保持简单、快速的特性。\n43.Redis和Lua脚本的使用了解吗？Redis的事务功能比较简单，平时的开发中，可以利用Lua脚本来增强Redis的命令。\nLua脚本能给开发人员带来这些好处：\n\nLua脚本在Redis中是原子执行的，执行过程中间不会插入其他命令。\nLua脚本可以帮助开发和运维人员创造出自己定制的命令，并可以将这 些命令常驻在Redis内存中，实现复用的效果。\nLua脚本可以将多条命令一次性打包，有效地减少网络开销。\n\n比如这一段很（烂）经（大）典（街）的秒杀系统利用lua扣减Redis库存的脚本：\n-- 库存未预热\nif (redis.call(&#39;exists&#39;, KEYS[2]) &#x3D;&#x3D; 1) then\n     return -9;\n end;\n -- 秒杀商品库存存在\n if (redis.call(&#39;exists&#39;, KEYS[1]) &#x3D;&#x3D; 1) then\n     local stock &#x3D; tonumber(redis.call(&#39;get&#39;, KEYS[1]));\n     local num &#x3D; tonumber(ARGV[1]);\n     -- 剩余库存少于请求数量\n     if (stock &lt; num) then\n         return -3\n     end;\n     -- 扣减库存\n     if (stock &gt;&#x3D; num) then\n         redis.call(&#39;incrby&#39;, KEYS[1], 0 - num);\n         -- 扣减成功\n         return 1\n     end;\n     return -2;\n end;\n -- 秒杀商品库存不存在\n return -1;\n\n44.Redis的管道了解吗？Redis 提供三种将客户端多条命令打包发送给服务端执行的方式：\nPipelining(管道) 、 Transactions(事务) 和 Lua Scripts(Lua 脚本) 。\nPipelining（管道）\nRedis 管道是三者之中最简单的，当客户端需要执行多条 redis 命令时，可以通过管道一次性将要执行的多条命令发送给服务端，其作用是为了降低 RTT(Round Trip Time) 对性能的影响，比如我们使用 nc 命令将两条指令发送给 redis 服务端。\nRedis 服务端接收到管道发送过来的多条命令后，会一直执命令，并将命令的执行结果进行缓存，直到最后一条命令执行完成，再所有命令的执行结果一次性返回给客户端 。\nPipelining的优势\n在性能方面， Pipelining 有下面两个优势：\n\n节省了RTT：将多条命令打包一次性发送给服务端，减少了客户端与服务端之间的网络调用次数\n减少了上下文切换：当客户端&#x2F;服务端需要从网络中读写数据时，都会产生一次系统调用，系统调用是非常耗时的操作，其中设计到程序由用户态切换到内核态，再从内核态切换回用户态的过程。当我们执行 10 条 redis 命令的时候，就会发生 10 次用户态到内核态的上下文切换，但如果我们使用 Pipeining 将多条命令打包成一条一次性发送给服务端，就只会产生一次上下文切换。\n\n45.Redis实现分布式锁了解吗？Redis是分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。\n\nV1：setnx命令\n\n占坑一般是使用 setnx(set if not exists) 指令，只允许被一个客户端占坑。先来先占， 用完了，再调用 del 指令释放茅坑。\n&gt; setnx lock:fighter true\nOK\n... do something critical ...\n&gt; del lock:fighter\n(integer) 1\n\n但是有个问题，如果逻辑执行到中间出现异常了，可能会导致 del 指令没有被调用，这样就会陷入死锁，锁永远得不到释放。\n\nV2:锁超时释放\n\n所以在拿到锁之后，再给锁加上一个过期时间，比如 5s，这样即使中间出现异常也可以保证 5 秒之后锁会自动释放。\n&gt; setnx lock:fighter true\nOK\n&gt; expire lock:fighter 5\n... do something critical ...\n&gt; del lock:fighter\n(integer) 1\n\n但是以上逻辑还有问题。如果在 setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被人为杀掉的，就会导致 expire 得不到执行，也会造成死锁。\n这种问题的根源就在于 setnx 和 expire 是两条指令而不是原子指令。如果这两条指令可以一起执行就不会出现问题。\n\nV3:set指令\n\n这个问题在Redis 2.8 版本中得到了解决，这个版本加入了 set 指令的扩展参数，使得 setnx 和expire 指令可以一起执行。\nset lock:fighter3 true ex 5 nx OK ... do something critical ... &gt; del lock:codehole\n\n上面这个指令就是 setnx 和 expire 组合在一起的原子指令，这个就算是比较完善的分布式锁了。\n当然实际的开发，没人会去自己写分布式锁的命令，因为有专业的轮子——Redisson。\n底层结构这一部分就比较深了，如果不是简历上写了精通Redis，应该不会怎么问。\n46.说说Redis底层数据结构？Redis有**动态字符串(sds)**、**链表(list)**、**字典(ht)**、**跳跃表(skiplist)**、**整数集合(intset)*、*压缩列表(ziplist) 等底层数据结构。\nRedis并没有使用这些数据结构来直接实现键值对数据库，而是基于这些数据结构创建了一个对象系统，来表示所有的key-value。\n我们常用的数据类型和编码对应的映射关系：\n简单看一下底层数据结构，如果对数据结构掌握不错的话，理解这些结构应该不是特别难：\n\n字符串：redis没有直接使⽤C语⾔传统的字符串表示，⽽是⾃⼰实现的叫做简单动态字符串SDS的抽象类型。\nC语⾔的字符串不记录⾃身的⻓度信息，⽽SDS则保存了⻓度信息，这样将获取字符串⻓度的时间由O(N)降低到了O(1)，同时可以避免缓冲区溢出和减少修改字符串⻓度时所需的内存重分配次数。\n\n\nSDS\n\n链表linkedlist：redis链表是⼀个双向⽆环链表结构，很多发布订阅、慢查询、监视器功能都是使⽤到了链表来实现，每个链表的节点由⼀个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，同时表头节点的前置和后置节点都指向NULL。\n\n链表linkedlist\n\n字典dict：⽤于保存键值对的抽象数据结构。Redis使⽤hash表作为底层实现，一个哈希表里可以有多个哈希表节点，而每个哈希表节点就保存了字典里中的一个键值对。每个字典带有两个hash表，供平时使⽤和rehash时使⽤，hash表使⽤链地址法来解决键冲突，被分配到同⼀个索引位置的多个键值对会形成⼀个单向链表，在对hash表进⾏扩容或者缩容的时候，为了服务的可⽤性，rehash的过程不是⼀次性完成的，⽽是渐进式的。\n跳跃表skiplist：跳跃表是有序集合的底层实现之⼀，Redis中在实现有序集合键和集群节点的内部结构中都是⽤到了跳跃表。Redis跳跃表由zskiplist和zskiplistNode组成，zskiplist⽤于保存跳跃表信息（表头、表尾节点、⻓度等），zskiplistNode⽤于表示表跳跃节点，每个跳跃表节点的层⾼都是1-32的随机数，在同⼀个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯⼀的，节点按照分值⼤⼩排序，如果分值相同，则按照成员对象的⼤⼩排序。\n整数集合intset：⽤于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。\n压缩列表ziplist：压缩列表是为节约内存⽽开发的顺序性数据结构，它可以包含任意多个节点，每个节点可以保存⼀个字节数组或者整数值。\n\n压缩列表组成\n47.Redis 的 SDS 和 C 中字符串相比有什么优势？C 语言使用了一个长度为 N+1 的字符数组来表示长度为 N 的字符串，并且字符数组最后一个元素总是 \\0，这种简单的字符串表示方式 不符合 Redis 对字符串在安全性、效率以及功能方面的要求。\nC语言的字符串\n\n\n\n\n\n\n\n\n\nC语言的字符串可能有什么问题？\n这样简单的数据结构可能会造成以下一些问题：\n\n获取字符串长度复杂度高 ：因为 C 不保存数组的长度，每次都需要遍历一遍整个数组，时间复杂度为O(n)；\n不能杜绝 缓冲区溢出&#x2F;内存泄漏 的问题 : C字符串不记录自身长度带来的另外一个问题是容易造成缓存区溢出（buffer overflow），例如在字符串拼接的时候，新的\nC 字符串 只能保存文本数据 → 因为 C 语言中的字符串必须符合某种编码（比如 ASCII），例如中间出现的 &#39;\\0&#39; 可能会被判定为提前结束的字符串而识别不了；\n\n\n\n\n\n\n\n\n\n\nRedis如何解决？优势？\nRedis sds\n简单来说一下 Redis 如何解决的：\n\n多增加 len 表示当前字符串的长度：这样就可以直接获取长度了，复杂度 O(1)；\n自动扩展空间：当 SDS 需要对字符串进行修改时，首先借助于 len 和 alloc 检查空间是否满足修改所需的要求，如果空间不够的话，SDS 会自动扩展空间，避免了像 C 字符串操作中的溢出情况；\n有效降低内存分配次数：C 字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分配，SDS 使用了 空间预分配 和 惰性空间释放 机制，简单理解就是每次在扩展时是成倍的多分配的，在缩容是也是先留着并不正式归还给 OS；\n二进制安全：C 语言字符串只能保存 ascii 码，对于图片、音频等信息无法保存，SDS 是二进制安全的，写入什么读取就是什么，不做任何过滤和限制；\n\n48.字典是如何实现的？Rehash 了解吗？字典是 Redis 服务器中出现最为频繁的复合型数据结构。除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个 全局字典，还有带过期时间的 key 也是一个字典。*(存储在 RedisDb 数据结构中)*\n\n\n\n\n\n\n\n\n\n字典结构是什么样的呢？\nRedis 中的字典相当于 Java 中的 HashMap，内部实现也差不多类似，采用哈希与运算计算下标位置；通过 **”数组 + 链表” *的*链地址法 来解决哈希冲突，同时这样的结构也吸收了两种不同数据结构的优点。\n\n\n\n\n\n\n\n\n\n字典是怎么扩容的？\n字典结构内部包含 两个 hashtable，通常情况下只有一个哈希表 ht[0] 有值，在扩容的时候，把ht[0]里的值rehash到ht[1]，然后进行 渐进式rehash ——所谓渐进式rehash，指的是这个rehash的动作并不是一次性、集中式地完成的，而是分多次、渐进式地完成的。\n待搬迁结束后，h[1]就取代h[0]存储字典的元素。\n49.跳跃表是如何实现的？原理？PS:跳跃表是比较常问的一种结构。\n跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。\n\n\n\n\n\n\n\n\n\n为什么使用跳跃表?\n首先，因为 zset 要支持随机的插入和删除，所以它 不宜使用数组来实现，关于排序问题，我们也很容易就想到 红黑树&#x2F; 平衡树 这样的树形结构，为什么 Redis 不使用这样一些结构呢？\n\n性能考虑： 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部；\n实现考虑： 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；\n\n基于以上的一些考虑，Redis 基于 William Pugh 的论文做出一些改进后采用了 跳跃表 这样的结构。\n本质是解决查找问题。\n\n\n\n\n\n\n\n\n\n跳跃表是怎么实现的？\n跳跃表的节点里有这些元素：\n\n层跳跃表节点的level数组可以包含多个元素，每个元素都包含一个指向其它节点的指针，程序可以通过这些层来加快访问其它节点的速度，一般来说，层的数量月多，访问其它节点的速度就越快。\n每次创建一个新的跳跃表节点的时候，程序都根据幂次定律，随机生成一个介于1和32之间的值作为level数组的大小，这个大小就是层的“高度”\n\n前进指针每个层都有一个指向表尾的前进指针（level[i].forward属性），用于从表头向表尾方向访问节点。\n我们看一下跳跃表从表头到表尾，遍历所有节点的路径：\n\n跨度层的跨度用于记录两个节点之间的距离。跨度是用来计算排位（rank）的：在查找某个节点的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。\n例如查找，分值为3.0、成员对象为o3的节点时，沿途经历的层：查找的过程只经过了一个层，并且层的跨度为3，所以目标节点在跳跃表中的排位为3。\n\n分值和成员节点的分值（score属性）是一个double类型的浮点数，跳跃表中所有的节点都按分值从小到大来排序。\n节点的成员对象（obj属性）是一个指针，它指向一个字符串对象，而字符串对象则保存这一个SDS值。\n\n\n50.压缩列表了解吗？压缩列表是 Redis 为了节约内存 而使用的一种数据结构，是由一系列特殊编码的连续内存快组成的顺序型数据结构。\n一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。\n压缩列表由这么几部分组成：\n\nzlbyttes:记录整个压缩列表占用的内存字节数\nzltail:记录压缩列表表尾节点距离压缩列表的起始地址有多少字节\nzllen:记录压缩列表包含的节点数量\nentryX:列表节点\nzlend:用于标记压缩列表的末端\n\n压缩列表示例\n51.快速列表 quicklist 了解吗？Redis 早期版本存储 list 列表数据结构使用的是压缩列表 ziplist 和普通的双向链表 linkedlist，也就是说当元素少时使用 ziplist，当元素多时用 linkedlist。\n但考虑到链表的附加空间相对较高，prev 和 next 指针就要占去 16 个字节（64 位操作系统占用 8 个字节），另外每个节点的内存都是单独分配，会家具内存的碎片化，影响内存管理效率。\n后来 Redis 新版本（3.2）对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist，quicklist是综合考虑了时间效率与空间效率引入的新型数据结构。\nquicklist由list和ziplist结合而成，它是一个由ziplist充当节点的双向链表。\n其他问题52.假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？使用 keys 指令可以扫出指定模式的 key 列表。但是要注意 keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。\n","slug":"02_Redis/Redis面试","date":"2022-03-20T07:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"6f20946e9914d93a8ca5443da94ef158","title":"网络安全问题","content":"网络安全\n​\t被动攻击\n​\t主动攻击\nDNS劫持\nCSRF攻击\nDoS、DDoS、DRDoS攻击\nXSS攻击\n","slug":"03_HTTP/网络安全","date":"2021-11-10T07:05:07.000Z","categories_index":"攻击","tags_index":"网络安全","author_index":"Michael"},{"id":"0e09c90cb345d77bfe5e6301428a903c","title":"MySQL索引数据结构原理","content":"二叉树 - 链表结构  - 相当于全表扫描\n大于自己的值，放在右边，比自己小的放在左边\n红黑树 - 二叉平衡树 - 数据量大时，树的高度不可控\nB-Tree树  \n​\t\t\t非叶子节点也会存储数据 没有维护双向指针\n​\t\t\t树的高度 由非叶子节点 的叶叉树来决定的\n​\t\t\t16^n^  &#x3D; 2Kw\nB+Tree - 多叉平衡树    B-Tree树的变种  树的高度可控\n​\t\t\t非叶子节点，作为一个冗余，不存储数据\n​\t\t\t1170 * 1170 * 16 &#x3D; 2Kw\n叶节点大小 16KB - 16384字节\nHash  - hash运算  hashmap 桶  -    一次 I&#x2F;O  \n​\thash冲突 \n​\t仅支持 &#x3D; 等值，不支持范围查询\n主键 必须有，否则MySQL会自行选择一列作为 聚簇索引，如果没有，MySQL 会做个 隐藏的 聚簇索引\n且为整型 \n数值存储空间要小\n数值比较效率要比字符串比较高\n数值自增排序，避免页分裂\nASCII值  \n二级索引 - 非聚簇索引 \n回表&amp;跳表\n联合索引(复合索引)\n​\t\t最左前缀原则\n​\t\t排好序\n​\t\t跳过最左字段，属于是无序的结构\nMVCC 多版本  并发控制 \nprocesson.com&#x2F;mindmap&#x2F;5dbeda6ee4b0ece75948831d\nbuffer pool 缓存机制\n​\t\t\tLRU算法\n​\t\t\t脏页\n  \n分布式消息中间件\tRabbitMQ 、 RocketMQ 、 Kafka\n分布式存储中间件\tRedis 、 MongoDB 、 FastDFS、 ElasticSearch、 ELK\n分布式架构(微服务框架) \tZookeeper 、 Dubbo 、ShardingSphere 、 Netty\ncs.usfca.edu\nhttps://cs.usfca.edu/~galles/visualization/Algorithms.html\n","slug":"01_MySQL/索引/红黑树","date":"2021-07-23T01:45:07.000Z","categories_index":"MySQL","tags_index":"索引","author_index":"Michael"},{"id":"5916b45061cc077d565610c60916fcda","title":"MySQL数据类型","content":"int \t\t\t\t整数 \nchar \t\t\t定长字符\n varchar \t变长字符 \ndatetime\t日期时间型\n text \t\t\t文本型 \nvarchar 与char的区别 \nchar是固定长度的字符类型，分配多少空间，就占用多长空间。 \nvarchar是可变长度的字符类型，内容有多大就占用多大的空间，能有效节省空间。 \n由于varchar类型是可变的，所以在数据长度改变的时，服务器要进行额外的操作，所以效率比char类型低。\n","slug":"01_MySQL/数据类型","date":"2021-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"3d8a1767104d30a018d732bb977e29c6","title":"SQL查询语句的流程","content":"当Mysql执行一条查询的SQl的时候大概发生了以下的步骤：\n\n客户端发送查询语句给服务器。\n服务器首先进行用户名和密码的验证以及权限的校验。\n然后会检查缓存中是否存在该查询，若存在，返回缓存中存在的结果。若是不存在就进行下一步。注意：Mysql 8就把缓存这块给砍掉了。\n接着进行语法和词法的分析，对SQl的解析、语法检测和预处理，再由优化器生成对应的执行计划。\nMysql的执行器根据优化器生成的执行计划执行，调用存储引擎的接口进行查询。服务器将查询的结果返回客户端。\n\nMysql中语句的执行都是都是分层执行，每一层执行的任务都不同，直到最后拿到结果返回，主要分为Service层和引擎层。\n在Service层中包含：连接器、分析器、优化器、执行器。引擎层以插件的形式可以兼容各种不同的存储引擎，主要包含的有InnoDB和MyISAM两种存储引擎。具体的执行流程图如下所示：\n\n","slug":"01_MySQL/查询语句的流程","date":"2021-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"a268ecb8e7f5610e6bc0d93965482953","title":"MySQL - 锁","content":"[TOC]\n锁机制\n\n\n\n\n\n\n\n\n计算机协调 多个进程或线程 并发访问某一资源的机制。\n锁的类型及其特点开销、加锁、颗粒度、冲突、并发等角度分析\n表级锁(table-level locking) 开销大，加锁快，不会出现死锁，颗粒度大，锁冲突概率高，并发度小；\n页面锁(page-level locking) 开销、加锁效率、颗粒度介于表锁和行锁之间，会出现死锁，并发度一般；\n行级锁(row-level locking)  开销大，加速慢，会出现死锁，颗粒度小，锁冲突概率小，并发度高；\n锁的类型应用场景表锁 - 适合 以查询为主，只有少量按索引条件更新数据的应用，如web应用；\n行锁 - 适合 大量按索引条件并发 更新少量不同数据，同时又有并发查询的应用，如在线事务处理系统；\n锁的支持度及情况MyISAM 只支持 表锁\nInnoDB 默认支持 行锁，也支持表锁\n-- 查询表锁争用情况\nshow status like &#39;table%&#39;; # Table_locks_waited 大则表锁争用情况严重\n\n锁的维度划分共享锁(S) - 读锁\n排他锁(X) - 写锁\n意向共享锁(IS) \n意向排他锁(IX)\n间隙锁\n死锁死锁的产生原因\n系统资源不足\n进程运行 推进的顺序&#x2F;速度 不同\n资源分配不当\n\n死锁的必要条件\n互斥\t\t\t\t\t一个资源每次只能被一个进程使用\n请求与保持    一个进程因请求资源而阻塞时，对已获得的资源保持不放\n不可剥夺        进程已获得的资源，在未使用完之前，不能强行剥夺\n循环等待        若干进程之间形成一种头尾相接的循环等待资源关系\n\n避免死锁\n合理的设计索引，区分度高的列放到组合索引前面，使业务 SQL 尽可能通过索引定位更少的行，减少锁竞争。\n\n调整业务逻辑 SQL 执行顺序， 避免 update&#x2F;delete 长时间持有锁的 SQL 在事务前面。\n\n避免大事务，将大事务拆成多个小事务\n\n以固定的顺序访问表和行。\n比如两个更新数据的事务，\n事务 A 更新数据的顺序为 1，2;\n事务 B 更新数据的顺序为 2，1。\n这样更可能会造成死锁。\n\n在并发比较高的系统中，不要显式加锁，特别是是在事务里显式加锁。\n如 select … for update 语句，\n如果是在事务里（运行了 start transaction 或设置了autocommit 等于0）,\n那么就会锁定所查找到的记录。\n\n尽量用主键&#x2F;索引去查找记录\n\n优化 SQL 和表设计，减少同时占用太多资源的情况。\n比如说，避免多个表join，将复杂 SQL 分解为多个简单的 SQL。\n\n\n死锁的解除与预防打破必要条件之一即可解锁，预防必要条件即可预防死锁。\n\n按同一顺序访问对象\n避免事务中的用户交互\n保持事务简短并在一个批处理中\n使用低隔离级别\n使用绑定连接\n\n总结\n\n\n维度|锁类型\n表级锁\n页面锁\n行级锁\n\n\n\n内存开销\n大\n中\n大\n\n\n加锁效率\n快\n中\n慢\n\n\n颗粒度\n大\n中\n小\n\n\n锁冲突概率\n高\n中\n低\n\n\n是否会死锁\n否\n是\n是\n\n\n并发度\n小\n一般\n高\n\n\n应用特点\n查询&amp;少量索引条件的更新\n-\n并发查询&amp;大量索引条件的不同数据更新\n\n\n应用场景\nWeb\n-\n在线事务处理系统\n\n\n存储引擎\nMyISAM、InnoDB\n-\nInnoDB\n\n\n锁争用参数\nshow status like &#39;table%&#39; Table_locks_waited\n-\nshow status like &#39;InnoDB_row_lock%&#39;;InnoDB_row_lock_waitsInnoDB_row_lock_time_avg\n\n\n","slug":"01_MySQL/锁机制","date":"2021-03-20T07:05:07.000Z","categories_index":"MySQL Lock","tags_index":"MySQL,锁","author_index":"Michael"},{"id":"2a240a0b6536e25078add1806f7b654e","title":"MySQL面试题","content":"\n\n","slug":"01_MySQL/面试题","date":"2021-03-20T07:05:07.000Z","categories_index":"SQL,面试题","tags_index":"MySQL","author_index":"Michael"},{"id":"3682ab669363b7cc91c7e1f90f676fac","title":"Redis缓存","content":"数据结构：memcache仅支持简单的key-value形式，Redis支持的数据更多（string字符串，set集合，list列表，hash散列，zset有序集合）；\n多线程：memcache支持多线程，Redis支持单线程\n持久化：Redis支持持久化，memcache不支持持久化\n分布式：Redis做主从结构，memcache服务器需要通过hash一致化来支撑主从结构\n实际运用中可以redis，memcache结合，memcache可作为session存储的方式，session都是KV类型键值对。\n\nRedis中，并不是所有的数据都一直存储在内存中的，这是和Memcache相比一个最大的区别。\n\nRedis在很多方面具备数据库的特征，或者说就是一个数据库系统，而Memcache只是简单的K&#x2F;V缓存。\n\n他们的扩展都需要做集群；实现方式：master-slave、Hash。\n\n在100k以上的数据中，Memcache性能要高于Redis。\n\n如果要说内存使用效率，使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcache。当然，这和你的应用场景和数据特性有关。\n\n如果你对数据持久化和数据同步有所要求，那么推荐你选择Redis，因为这两个特性Memcache都不具备。即使你只是希望在升级或者重启系统后缓存数据不会丢失，选择Redis也是明智的。\n\nRedis和Memcache在写入性能上面差别不大，读取性能上面尤其是批量读取性能上面Memcache更强\n\nRedis 提供了多种不同级别的持久化方式：\n\n\nRDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。\nAOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。\nRedis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。\n你甚至可以关闭持久化功能，让数据只在服务器运行时存在。\n\n\n\n\n\n\n\n\n\n归纳\n\n\n\n\nRedis\nMemcache\n\n\n\n数据结构\nstring、set集合、list列表、hash散列、zset有序集合\nkey-value\n\n\n多线程\nNO\nYES\n\n\n持久化\nRDB快照、AOF日志\nNO\n\n\n分布式\n主从结构\nhash一致化\n\n\n读写\n读11w&#x2F;s，写8w&#x2F;s\n读更优\n\n\n特性\n具备数据库特征，NoSQL\nK&#x2F;V缓存\n\n\n性能\n100KB以内的数据，更优\n100KB以上的数据，更优\n\n\n集群\nMaster-slave hash\nMaster-slave hash\n\n\n数据存储\n并非所有的数据都一直存储在内存中\n所有的都存在内存中\n\n\n内存使用率\n如果是hash结构的key-value，组合式的压缩，会高\n高\n\n\n","slug":"02_Redis/比较区别_Redis和Memcache","date":"2021-03-20T07:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"b8997c28f0beb7e2efaf414b6b406c0f","title":"Redis高并发","content":"\n\n\n\n\n\n\n\n\n背景\nRedis是不会存在并发问题的，因为他是单进程的，再多的命令都是一个接一个地执行的。\n\n\n\n\n\n\n\n\n\n场景\n\nGET &amp; SET \n\n利用Jedis等客户端对Redis进行并发访问\n\n远程访问Redis的时候，因为网络等原因造成高并发访问、延迟返回\n\n\n我们使用的时候，可能会出现并发问题，比如获得和设定这一对。\nRedis的为什么 有高并发问题？Redis的的出身决定。\nRedis是一种单线程机制的nosql数据库，基于key-value，数据可持久化落盘。\n由于单线程所以Redis本身并没有锁的概念，多个客户端连接并不存在竞争关系，\n但是利用Jedis等客户端对Redis进行并发访问时会出现问题。\n\n\n\n\n\n\n\n\n\n原因\n发生【连接超时】、【数据转换错误】、【阻塞】、【客户端关闭连接】等问题，\n这些问题均是由于【客户端连接混乱】造成。\n单线程的天性决定，高并发对同一个键的操作会排队处理，\n如果并发量很大，可能造成后来的请求超时。\n在远程访问Redis的时候，因为网络等原因造成高并发访问延迟返回的问题。\n\n\n\n\n\n\n\n\n\n解决办法\n\n客户端角度，将连接进行池化，同时对读写Redis操作采用内部锁 sync hronized；\n服务器角度，利用setnx变向实现锁机制；\n\n","slug":"02_Redis/防止高并发","date":"2021-03-20T07:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"dd3ad8310bb65f7ae1074f767c58a90d","title":"PHP依赖注入","content":"依赖注入\nIOC（inversion of control） 控制反转模式；控制反转是将组件间的依赖关系从程序内部提到外部来管理；\nDI（dependency injection）依赖注入模式；\n依赖注入是指将组件的依赖通过外部以 参数或其他形式 注入；\n","slug":"05_PHP/依赖注入","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"1a2ade4f8c304fc2bc170e0b21a2a998","title":"常见的设计模式","content":"\n\n\n设计模式\n概念\n代码\n\n\n\n工厂模式\n用来实现创建对象和对象的使用分离，将对象的创建交给专门的工厂类负责简单工厂模式工厂模式抽象工厂模式\n简单工厂模式，根据不同的入参new实例化不同的类对象\n\n\n单例模式\n保证一个类仅有一个实例，并提供一个访问它的全局访问点。\n\n\n\n适配器模式\n将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。\n\n\n\n观察者模式\n定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新，简单来说该模式相当于源 - 监听（Source-Listener）模式（即监听器）、发布 - 订阅（Publish-Subscribe）模式\n\n\n\n策略模式\n用相同的方法实现不同的功能\n\n\n\n注册树模式\n\n\n\n\n","slug":"05_PHP/常见设计模式","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"设计模式","author_index":"Michael"},{"id":"310cdbee74459a58b10a045d6d41a3f0","title":"PHP版本区别","content":"\n\n\n版本\n特性\n\n\n\n4\n支持 autoload、PDO 和 MySQLi、类型约束，纯过程式语言，没太多复杂的\n\n\n5.2\n支持JSON，完全实现了面向对象\n\n\n5.3\n匿名函数，魔术方法，命名空间，后期静态变量绑定，hereDoc、nowDoc、const、三元运算、Phar\n\n\n5.4\n(无需修改ini配置)短标签，数组简写，Traits工具类，内置Web服务器\n\n\n5.5\nyield迭代器、生成器(foreach)，foreach支持list()\n\n\n5.6\n增强常量、命名空间，可变函数参数，**幂运算，大文件上传，php:&#x2F;&#x2F;input可重用\n\n\n7.0\n新版ZendEngine引擎，匿名类，返回类型声明，变量类型、错误异常、zval使用栈内存等许多新特性\n\n\n7.1\n可空(NullLable)类型、list简写[]、指定key，const常量可指定权限，多异常捕获处理\n\n\n7.2\n新的对象类型，逆变和协变，通过名称加载扩展，允许重写抽象方法，使用argon2算法生成密码散列，新增ext&#x2F;PDO字符串扩展类型\n\n\n7.3\n取数组第一个&#x2F;最后一个键\n\n\n7.4\n数组延展操作符(…$a)、箭头函数(&#x3D;&gt;)，空合并运算赋值\n\n\n8.0\n注解、JIT、命名参数、联合类型、构造器属性提升，match表达式、nullsafe运算符、改进了类型系统、错误处理、语法一致性\n\n\n8.1\n枚举、只读属性、first-class可调用语法、纤程、交集类型和性能改进等\n\n\n","slug":"05_PHP/比较区别_PHP版本","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"9aaf2af7e7121b62182052d72c57944c","title":"接口与抽象类","content":"\n\n\n区别\n接口类\n抽象类\n\n\n\n条件\n必须实现接口类中所有的公共方法\n必须定义父类中所有的抽象方法\n\n\n关键字\ninterface\nabstract\n\n\n方式\n实现implements\n继承extends\n\n\n特性\n实现多个接口\n只能继承一个抽象类\n\n\n修饰符\npublic 公有的\n保持一致或更为宽泛\n\n\n","slug":"05_PHP/比较区别_interface与abstract","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"57ca8344e7f1164684be994c1abac187","title":"生命周期","content":"生命周期\n完整的生命周期为\n​\t【模块初始化】\n​\t【请求初始化】\n​\t【请求处理】\n​\t【请求关闭】\n​\t【模块关闭】\n五大阶段。\nCLI 模式下，每个脚本都会完整的执行上面的五大阶段；\nFast-CGI模式而言，只在启动时会执行【模块初始化】，之后的请求都走了\n【请求初始化】、【处理请求】、【请求关闭】三大阶段，\nFast-CGI关闭时执行【模块关闭】阶段；\n各个扩展的加载也是在模块初始化阶段完成的。\n","slug":"05_PHP/生命周期","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"3f834afbb52751d37ab132951dc0a901","title":"OOP - 面向对象","content":"面向对象 OOP\n面向对象是程序的一种设计方式，\n它利于提高程序的重用性，\n使程序结构更加清晰。\n主要特征：\n​\t\t封装\n​\t\t继承\n​\t\t多态\n五大基本原则： \n​\t\t单一职责原则；\n​\t\t开放封闭原则；\n​\t\t替换原则；\n​\t\t依赖原则； \n​\t\t接口分离原则。\n","slug":"05_PHP/面向对象OOP","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"OOP","author_index":"Michael"},{"id":"65a3b05d7141d3108344f4a914101725","title":"Go基础","content":"Go","slug":"06_GoLang/Go","date":"2021-03-20T07:05:07.000Z","categories_index":"Go","tags_index":"Go","author_index":"Michael"},{"id":"257801c13db5cb3a113e2333b528cb5f","title":"MarkDown基础","content":"MarkDown","slug":"Editor/MarkDown","date":"2021-03-20T07:05:07.000Z","categories_index":"markdown","tags_index":"markdown","author_index":"Michael"},{"id":"10b5113d0b035e5e97b3af0e0cb363af","title":"PhpStorm基础","content":"PhpStorm","slug":"Editor/PhpStorm","date":"2021-03-20T07:05:07.000Z","categories_index":"PhpStorm","tags_index":"PhpStorm","author_index":"Michael"},{"id":"3fe1ee3f3830128bf539e5f4ed9fbbe9","title":"Linux","content":"Linux系统中的644权限是什么意思？\n\n\n\n权限\n简称\n全称\n值\n表达式\n\n\n\n读取权限\nr\nRead\n4\n2^2^\n\n\n写入权限\nw\nWrite\n2\n2^1^\n\n\n执行权限\nx\nExecute\n1\n2^0^\n\n\n无权限\n–\n—\n0\n0\n\n\n rw- r– r– \n​\t\t\t第一位 6 &#x3D; 4 + 2 + 0 所以是 rw-  即：所有(拥有)者\t\t拥有读写权限；\n​\t\t\t第二位 4 &#x3D; 4 + 0 + 0 所以是 r–    即：(同组)用户组\t\t拥有读权限；\n​\t\t\t第三位 4 &#x3D; 4 + 0 + 0 所以是 r–    即：公共(其他)用户\t拥有读权限；\n​\t\t\n","slug":"Linux/Linux权限","date":"2021-03-20T07:05:07.000Z","categories_index":"Linux","tags_index":"Linux","author_index":"Michael"},{"id":"8874693909ad7fda8ef04b046cdcb113","title":"MacOS基础","content":"MacOSmacOS 使用pecl安装PHP扩展\n安装kafka扩展前，确保MacOS已经安装了librdkafka，如果没有，可以使用 brew 安装 librdkafka：\nbrew install librdkafka\n\n因为mongodb在默认版本下，对PHP的版本要求是7.2，所以可以指定版本安装\npecl i redis rdkafka mongodb-1.11.1\n\n\n\npecl安装PHP扩展的版本地址\n拷贝文件内容的命令pbcopy\npbcopy &lt; ~&#x2F;.ssh&#x2F;id_rsa.pub\n\n","slug":"MacOS/MacOS","date":"2021-03-20T07:05:07.000Z","categories_index":"MacOS","tags_index":"MacOS","author_index":"Michael"},{"id":"69d68218b5a6b67545a995ee806b6fa9","title":"书单","content":"软技能 代码之外的生存指南\t约翰 Z.森梅兹 著\n代码整洁之道\t马丁 著\n代码整洁之道 程序员的职业素养\t罗伯特·C.马丁 著\n编程珠玑（第2版 修订版）\t乔恩·本特利（Jon Bentley） 著\n编程珠玑（续 修订版）\t\t乔恩·本特利 著\n重构 改善既有代码的设计\t\t马丁·福勒（Martin Fowler) 著\n程序员面试白皮书\t\t逸超, 董飞著\n师兄教你找工作——100场面试 20个offer背后的求职秘密\t\t韩速（@美牙君）著\n趣学算法\t\t\t陈小玉 著\n算法谜题\t\t【美】Anany Levitin 著\nC和C++程序员面试秘笈\t董山海 著\nJava程序员面试秘笈\t常建功著\n编程之法：面试和算法心得 July 著\n.NET程序员面试秘笈\t张云翯著\n软件测试工程师面试秘籍\tG.li, 51Testing软件测试网 著\nAndroid高薪之路—Android程序员面试宝典\t李宁著\n从跨界到专精 T型产品经理的自我修炼\t简浅  著\n","slug":"Other/书单","date":"2021-03-20T07:05:07.000Z","categories_index":"编程","tags_index":"书单","author_index":"Michael"},{"id":"8293f563eb43963f4391de385bc44bf4","title":"索引的最左前缀原则","content":"最左前缀原则就是最左优先，\n在创建多列索引时，要根据业务需求，\nwhere子句中使用最频繁的一列放在最左边。\nmysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，\n比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 \n如果建立(a,b,c,d)顺序的索引，d是用不到索引的，\n如果建立(a,b,d,c)的索引则都可以用到，\na,b,d的顺序可以任意调整。\n&#x3D;和in可以乱序，\n比如a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3 建立(a,b,c)索引可以任意顺序，\nmysql的查询优化器会帮你优化成索引可以识别的形式。\n最左前缀原则可以是联合索引的的最左N个字段，也可以是字符串索引的最左的M个字符。举个例子，假如现在有一个表的原始数据如下所示：\n\n并根据col3 ，col2的顺序建立联合索引，此时联合索引树结构如图下所示：\n\n叶子结点中首先会根据col3的字符进行排序，若是col3相等，在col3相等的值里面再对col2进行排序，假如我们要查询where col3 like &#39;Eri%&#39;，就可以快速的定位查询到Eric。\n若是查询条件为where col3 like ‘%se’，前面的字符不确定，表示任意字符都可以，这样就可以导致全表扫描进行字符的比较，就会使索引失效。\n","slug":"01_MySQL/索引/最左前缀原则","date":"2021-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"dbb49c91b895258e0502c7a585bfdf69","title":"Hyperf 基础","content":"Hyperf","slug":"05_PHP/PHP框架/Hyperf","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"Hyperf","author_index":"Michael"},{"id":"ae596fb01f5b415b040878d7d5fdc1b5","title":"EasySwoole基础","content":"EasySwoole","slug":"05_PHP/PHP框架/EasySwoole","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"EasySwoole","author_index":"Michael"},{"id":"f740911c599f68488a13761b066acd48","title":"Lumen 基础","content":"Lumen依赖注入\n它是”其中一种对象依赖于另一个对象”的技术。\n依赖注入有三种类型：\n1）构造函数注入\n2） setter 注入\n3）接口注入.\n下面是laravel的主要优点：\nLaravel具有blade模板引擎，可创建动态布局并増加编译任务\n 可以很简单的复用代码\n您不需要手动維护和包含路径，因为Laravel具有自动加载功能\n该框架可帮助您使用LOC容器制作新工具\nLaravel提供了一个版本控制系统，可帮助简化迁移管理\n区别：\n1、Laravel是一个全栈Web应用程序框架，而Lumen是一个微框架，用于开发微服务和API开发；\n2、Laravel可以与更多数量的工具集成，而Lumen与其他工具的集成设施数量较少。\n\nlaravel与lumen的区别是什么\nLaravel是用于Web开发的开源PHP框架。它是免费的，由Taylor Otwell创建。它基于MVC(模型视图控制器)架构模式。它主要用于开发Web应用程序。Laravel易于理解，并且健壮的MVC框架可用于PHP中的Web应用程序开发。Lumen是一个微型框架，意味着更小，更简单，更精简和更快，Lumen主要用于构建具有松耦合组件的微服务，这些组件可降低复杂性并轻松增强改进。\nLaravel\nLaravel易于理解，并且健壮的MVC框架可用于PHP中的Web应用程序开发。它是在麻省理工学院获得许可的。它最初于2011年6月发布。它完全用PHP编程语言编写。Laravel通过最新功能为开发提供了丰富的功能集。在网络攻击盛行的网络安全情况下，Laravel的安全功能非常出色。\nLumen\nLumen是由Laravel的创建者泰勒·奥特威尔(Taylor Otwell)创建的一个微型框架。Lumen意味着整个Web应用程序框架的更小，更简单，更精简和更快的版本。Lumen框架的基础级别与大多数相似组件在Laravel级别相同。在配置Web应用程序时，Lumen具有较少的配置和不同的路由参数，并有助于快速开发。\nLaravel与Lumen之间的主要区别：\n\nLaravel是一个全栈Web应用程序框架，可打包或支持许多第三方工具和框架，而Lumen是一个微框架，用于开发微服务和API开发，旨在提供快速和高响应时间。\nLaravel对于服务器和与应用程序一起使用的其他工具需要不同类型的配置，而Lumen微型框架是Laravel版本的一种轻型形式，它提供了专门的功能，例如API开发，Cookie，模板，缓存，日志记录，路由，HTTP会议等\nLaravel具有以下特点：干净的体系结构，开源，不断发展的社区，依赖注入仅适用于PHP的框架，而Lumen是一个微框架，API功能，宁静的支持，雄辩且易于使用。\n与Lumen相比，Laravel可以与更多数量的工具集成，而Lumen与其他工具的集成设施数量较少。\n在SQL查询和从应用程序级别调整数据库的情况下，Laravel的性能将很好，而与Laravel相比，在SQL查询和较少的功能的情况下，Lumen的性能会下降。\nLaravel在雄辩的ORM框架中有不同的规范，而Blade是完全用PHP编写的默认模板引擎，而Lumen没有直接衍生自Laravel的规范。\nLaravel有自己的命令行界面，与框架一起内置，而Lumen是功能丰富的微框架。\nLaravel具有出色的内置对象关系映射框架，而Lumen易于升级。\nLaravel非常适合构建RESTful API(应用程序编程接口)，而Lumen是构建微服务的性能最高的微框架API之一。\nLaravel有一个很好的文档来进行项目启动和初始化，而Lumen没有清晰的文档，但是易于使用。\nLaravel易于将身份验证与应用程序集成在一起，而Lumen没有内置或易于集成的第三方工具。\nLaravel可以轻松处理事件排队，而Lumen没有内置功能。\nLaravel具有强大的模板系统，而Lumen没有这种功能。\nLaravel有一个陡峭的学习曲线来掌握框架，而Lumen的学习曲线更少并且易于实现。\n与Lumen相比，Laravel的性能和速度较差，而Lumen的性能却很好。\nLaravel有一个Symfony框架，可以用来创建Symfony组件，因为Lumen没有这些功能。\n\n","slug":"05_PHP/PHP框架/Lumen","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"Lumen","author_index":"Michael"},{"id":"7cc8ad08f29f88db72501f4301aec128","title":"ThinkPHP基础","content":"ThinkPHP","slug":"05_PHP/PHP框架/ThinkPHP","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"ThinkPHP","author_index":"Michael"},{"id":"ef8d75bd96688af0514a3f41dc972e71","title":"Yaf基础","content":"Yaf","slug":"05_PHP/PHP框架/Yaf","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"Yaf","author_index":"Michael"},{"id":"a5c2969ae041d169a8872b0ff677251d","title":"Yii2基础","content":"Yii2","slug":"05_PHP/PHP框架/Yii2","date":"2021-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"Yii2","author_index":"Michael"},{"id":"d87e3b52c409ec7187f6e118ea506ef4","title":"Kubernetes 基础操作命令","content":"\n\n\n初始版本\n2014年6月7日，7年前\n\n\n\n稳定版本\n1.23.1（2021年12月16日，2个月前）\n\n\n源代码库\nkubernetes\n\n\n编程语言\nGo\n\n\n操作系统\n跨平台\n\n\n类型\n集群管理\n\n\n许可协议\nApache许可证 2.0\n\n\n网站\nkubernetes.io\n\n\nKubernetes（常简称为K8s）是用于自动部署、扩展和管理“容器化（containerized）应用程序”的开源系统。该系统由 Google 设计并捐赠给Cloud Native Computing Foundation（今属Linux基金会）来使用。\n它旨在提供“跨主机集群的自动部署、扩展以及运行应用程序容器的平台”。它支持一系列容器工具，包括Docker等。\nMore info: Kubernetes\nBash Command查看默认命名空间下的podkubectl get pods\n\n或\nkubectl get pod\n\n或\nkubectl get po\n\n\n\n查看所有的命名空间kubectl get po -A\n\n\n\n查看指定命名空间下的所有podkubectl get po -n dev-jingsocial\n\n\n\n进入某一个pod默认的容器kubectl exec user-deployment-66f996944c-9b4qq bash -itn dev-jingsocial\n\n\n\n查看配置里某一个配置项的集合kubectl get po -o jsonpath&#x3D;&#123;.items..metadata.labels.k8s-app&#125; -n dev-jingsocial \n\n\n\n查看某一个label的pod容器名称kubectl get po -o jsonpath&#x3D;&#123;.items..metadata.name&#125; -n dev-jingsocial\n\n\n\n进入某一个动态指定的容器kubectl exec $(kubectl get po -l k8s-app&#x3D;user -o jsonpath&#x3D;&#123;.items..metadata.name&#125; -n dev-jingsocial) bash -itn dev-jingsocial\n\n\n\n拷贝本地文件到容器kubectl cp &#x2F;Users&#x2F;michael&#x2F;.kube&#x2F;config user-deployment-66f996944c-9b4qq:&#x2F;var&#x2F;www&#x2F;.kube&#x2F;config -n dev-jingsocial\n\n\n\n拷贝容器文件到本地kubectl cp user-deployment-66f996944c-9b4qq:&#x2F;var&#x2F;www&#x2F;.kube&#x2F;config &#x2F;Users&#x2F;michael&#x2F;.kube&#x2F;config -n dev-jingsocial\n\n","slug":"Kubernetes/Kubernetes","date":"2021-03-20T02:23:13.000Z","categories_index":"kubernetes,command","tags_index":"kubernetes,kubectl,K8S","author_index":"Michael"},{"id":"a595c434c3f9419b2137be25f49e6e71","title":"分布式","content":"C - 一致性\nA - 可用性\nP - 分区容错性\nBASE\n\n基本可用\n最终一致性\n\n\n","slug":"00_架构/CAP","date":"2020-07-20T03:15:49.000Z","categories_index":"架构","tags_index":"分布式架构","author_index":"Michael"},{"id":"c1f6d722cc4602038235f2e7924e8ff2","title":"MySQL事务","content":"事务概念\n\n\n\n\n\n\n\n\n\n4个原则 ACID\t\n\n\n\n原则\n概念\n\n\n\n\n原子性\n一个事务中的操作要么全部成功，要么全部失败\nAtomicity\n\n\n一致性\n总是从一个一致性的状态转换到另一个一致性的状态\nConsistent\n\n\n隔离性\n一个事务的修改在提交前，其他事务是感知不到的\nIsalotion\n\n\n持久性\n永久保存在数据库中\nDurable\n\n\n​\t原子性、隔离性、持久性都是为了保障一致性而存在的，一致性也是最终的目的。\n\n\n\n\n\n\n\n\n\n隔离级别\n​\t读未提交\tREAD UNCOMMITTED\n​\t读已提交\tREAD COMMITTED\n​\t可重复读\tREPEATABLE READ\n​\t可序列化\tSERIALIZABLE\n没有那种隔离级别是完美的，只能根据自己的项目业务场景去评估选择最适合的隔离级别，大部分的公司一般选择Mysql默认的隔离级别：可重复读。\n隔离级别从：读未提交-读提交-可重复读-串行化，级别越来越高，隔离也就越来越严实，到最后的串行化，当出现读写锁冲突的时候，后面的事务只能等前面的事务完成后才能继续访问。\n\n读未提交：读取到别的事务还没有提交的数据，从而产生了脏读。\n读提交：读取别的事务已经提交的数据，从而产生不可重复读。\n可重复读：事务开启过程中看到的数据和事务刚开始看到的数据是一样的，从而产生幻读，在Mysql的中通过MVCC多版本控制的一致性视图解决了不可重复读问题以及通过间隙锁解决了幻读问题。\n串行化：对于同一行记录，若是读写锁发生冲突，后面访问的事务只能等前面的事务执行完才能继续访问。\n\n举个例子，假如有一个user表，里面有两个字段id和age，里面有一条测试数据：（1,24），现在要执行age+1，同时有两个事务执行：\n\n\n\n事务1\n事务2\n\n\n\n启动事务，接着查询age（a1）\n\n\n\n\n启动事务\n\n\n\n查询age（a2）\n\n\n\n执行age&#x3D;age+1\n\n\n查询age（a3）\n\n\n\n\n提交事务\n\n\n查询age（a4）\n\n\n\n提交事务\n\n\n\n查询age（a5）\n\n\n\n经过上面的执行，在四种隔离级别下a1,a2,a3,a4,a5的值分别是多少？我们来认真的分析一波：\n\n读未提交：a1和a2因为读的是初始值所以为24，隔离级别为读未提交，事务2执行了age&#x3D;age+1，不管事务2是否提交，那么a3、a4和a5的值都是25。\n读提交：a1和a2因为读的是初始值所以为24，隔离级别为读提交所以a3还是24，a4和a5因为事务2已经提交所以得到的值是25。\n可重复读：a1和a2因为读的是初始值所以为24，可重复读的隔离级别下，a3和a4读取的值和事务开始的结果一样，所以还是24，a5前一步因为已经提交事务，所以a5的值是25。\n串行化：a1和a2因为读的是初始值所以为24，串行化隔离级别下，当事务2修改数据的时候，获取了写锁，事务1读取age的值会被锁住，所以在事务1的角度下a3和a4读取的值为24，a5的值为25。\n\n当你能够分析得出这个例子下，在不同隔离级别下分析的出a1-a5的值，说明你对事务的隔离级别已经有比较深入的理解了。\n\n\n\n\n\n\n\n\n\n并发事务的问题\n​\t更新丢失\n​\t脏读\n​\t不可重复读\n​\t幻读\n\n\n\n\n\n\n\n\n\n实现分布式事务\n1、流水任务，最终一致性，前提是接口要支持幂等性\n2、事务消息\n3、二阶段提交\n4、三阶段提交\n5、TCC\n6、Seata 框架\n","slug":"01_MySQL/事务","date":"2020-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"a1edca3a2bbcac434a13f40d2a6e8589","title":"MySQL存储引擎","content":"\n\n\n\n\n\n\n\n\nInnoDB和MyISAM的区别\n（1）InnoDB和MyISAM都是Mysql的存储引擎，现在MyISAM也逐渐被InnoDB给替代，主要因为InnoDB支持事务和行级锁，MyISAM不支持事务和行级锁，MyISAM最小锁单位是表级。因为MyISAM不支持行级锁，所以在并发处理能力上InnoDB会比MyISAM好。\n（2） 数据的存储上：MyISAM的索引也是由B+树构成，但是树的叶子结点存的是行数据的地址，查找时需要找到叶子结点的地址，再根据叶子结点地址查找数据。\n\nInnoDB的主键索引的叶子结点直接就是存储行数据，查找主键索引树就能获得数据：\n\n若是根据非主键索引查找，非主键索引的叶子结点存储的就是，当前索引值以及对应的主键的值，若是联合索引存储的就是联合索引值和对应的主键值。\n\n（3）数据文件构成：MyISAM有三种存储文件分别是扩展名为：.frm（文件存储表定义）、.MYD (MYData数据文件)、.MYI (MYIndex索引文件)。而InnoDB的表只受限于操作系统文件的大小，一般是2GB\n（4）查询区别：对于读多写少的业务场景，MyISAM会更加适合，而对于update和insert比较多的场景InnoDB会比较适合。\n（5）count(*)区别：select count(*) from table，MyISAM引擎会查询已经保存好的行数，这是不加where的条件下，而InnoDB需要全表扫描一遍，InnoDB并没有保存表的具体行数。\n（6）其它的区别：InnoDB支持外键，但是不支持全文索引，而MyISAM不支持外键，支持全文索引，InnoDB的主键的范围比MyISAM的大。\n\n\n\n\n\n\n\n\n\n总结\n\n\n\n\nMyISAM\nInnoDB\n\n\n\n默认\n不支持\n支持\n\n\n事务\n不支持\n支持\n\n\n外键\n不支持\n支持\n\n\n聚集索引\n不支持\n支持\n\n\n索引和数据\n分开存储\n存储在一起\n\n\nMVCC\n不支持\n支持\n\n\n备份\n不支持\n在线热备\n\n\n全文索引\n支持\n不支持\n\n\n主键范围\n小\n大\n\n\n并发能力\n低\n高(通过MVCC来支持)\n\n\n锁粒度\n表锁\n行锁、表锁、页锁\n\n\n查询\n读多写少\n更新和插入较多的场景\n\n\n行数\n保存\n不保存\n\n\n崩溃恢复\n慢，易丢失\n概率低\n\n\n数据文件\n.frm（文件存储表定义）.MYD (MYData数据文件).MYI (MYIndex索引文件)\n.frm.ibd只受限于操作系统文件的大小一般是2GB\n\n\n","slug":"01_MySQL/存储引擎","date":"2020-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"dc0f0a28e862093b53019489e393e51e","title":"性能优化方案","content":"\n数据量比较大，批量操作数据入库\n耗时操作考虑异步处理\n恰当使用缓存\n优化程序逻辑、代码\nSQL优化\n压缩传输内容\n考虑使用文件&#x2F;MQ等其他方式暂存，异步再落地DB\n跟产品讨论需求最恰当，最舒服的实现方式\n\n本文会提到52条SQL语句性能优化策略。\n1、对查询进行优化，应尽量避免全表扫描，首先应考虑在where及order by涉及的列上建立索引。\n2、应尽量避免在where子句中对字段进行null值判断，创建表时NULL是默认值，但大多数时候应该使用NOT NULL，或者使用一个特殊的值，如0，-1作为默认值。\n3、应尽量避免在where子句中使用!&#x3D;或&lt;&gt;操作符，MySQL只有对以下操作符才使用索引：&lt;，&lt;&#x3D;，&#x3D;，&gt;，&gt;&#x3D;，BETWEEN，IN，以及某些时候的LIKE。\n4、应尽量避免在where子句中使用or来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，可以使用UNION合并查询：select id from t where num&#x3D;10 union all select id from t where num&#x3D;20。\n5、in和not in也要慎用，否则会导致全表扫描，对于连续的数值，能用between就不要用in了：Select id from t where num between 1 and 3。\n6、下面的查询也将导致全表扫描：select id from t where name like‘%abc%’或者select id from t where name like‘%abc’若要提高效率，可以考虑全文检索。而select id from t where name like‘abc%’才用到索引。\n7、如果在where子句中使用参数，也会导致全表扫描。\n8、应尽量避免在where子句中对字段进行表达式操作，应尽量避免在where子句中对字段进行函数操作。\n9、很多时候用exists代替in是一个好的选择：select num from a where num in(select num from b)。用下面的语句替换：select num from a where exists(select 1 from b where num&#x3D;a.num)。\n10、索引固然可以提高相应的select的效率，但同时也降低了insert及update的效率，因为insert或update时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。关于索引可以关注公众号Java技术栈搜索阅读更多详细教程。\n11、应尽可能的避免更新clustered索引数据列， 因为clustered索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新clustered索引数据列，那么需要考虑是否应将该索引建为clustered索引。\n12、尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。\n13、尽可能的使用varchar&#x2F;nvarchar代替char&#x2F;nchar，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。\n14、最好不要使用”“返回所有：select from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。具体可以阅读《别再 select * 了》这篇文章。\n15、尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。\n16、使用表的别名(Alias)：当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个Column上。这样一来，就可以减少解析的时间并减少那些由Column歧义引起的语法错误。\n17、使用“临时表”暂存中间结果 ：\n简化SQL语句的重要方法就是采用临时表暂存中间结果，但是临时表的好处远远不止这些，将临时结果暂存在临时表，后面的查询就在tempdb中了，这可以避免程序中多次扫描主表，也大大减少了程序执行中“共享锁”阻塞“更新锁”，减少了阻塞，提高了并发性能。\n18、一些SQL查询语句应加上nolock，读、写是会相互阻塞的，为了提高并发性能，对于一些查询，可以加上nolock，这样读的时候可以允许写，但缺点是可能读到未提交的脏数据。\n使用nolock有3条原则：\n\n查询的结果用于“插、删、改”的不能加nolock；\n查询的表属于频繁发生页分裂的，慎用nolock ；\n使用临时表一样可以保存“数据前影”，起到类似Oracle的undo表空间的功能，能采用临时表提高并发性能的，不要用nolock。\n\n19、常见的简化规则如下：\n不要有超过5个以上的表连接（JOIN），考虑使用临时表或表变量存放中间结果。少用子查询，视图嵌套不要过深，一般视图嵌套不要超过2个为宜。\n20、将需要查询的结果预先计算好放在表中，查询的时候再Select。这在SQL7.0以前是最重要的手段，例如医院的住院费计算。\n21、用OR的字句可以分解成多个查询，并且通过UNION 连接多个查询。他们的速度只同是否使用索引有关，如果查询需要用到联合索引，用UNION all执行的效率更高。多个OR的字句没有用到索引，改写成UNION的形式再试图与索引匹配。一个关键的问题是否用到索引。\n22、在IN后面值的列表中，将出现最频繁的值放在最前面，出现得最少的放在最后面，减少判断的次数。\n23、尽量将数据的处理工作放在服务器上，减少网络的开销，如使用存储过程。\n存储过程是编译好、优化过、并且被组织到一个执行规划里、且存储在数据库中的SQL语句，是控制流语言的集合，速度当然快。反复执行的动态SQL，可以使用临时存储过程，该过程（临时表）被放在Tempdb中。\n24、当服务器的内存够多时，配制线程数量 &#x3D; 最大连接数+5，这样能发挥最大的效率；否则使用 配制线程数量&lt;最大连接数启用SQL SERVER的线程池来解决，如果还是数量 &#x3D; 最大连接数+5，严重的损害服务器的性能。\n25、查询的关联同写的顺序 ：\nselect a.personMemberID, * from chineseresume a,personmember b where personMemberID &#x3D; b.referenceid and a.personMemberID &#x3D; ‘JCNPRH39681’ （A &#x3D; B ,B &#x3D; ‘号码’） \nselect a.personMemberID, * from chineseresume a,personmember b where a.personMemberID &#x3D; b.referenceid and a.personMemberID &#x3D; ‘JCNPRH39681’ and b.referenceid &#x3D; ‘JCNPRH39681’ （A &#x3D; B ,B &#x3D; ‘号码’， A &#x3D; ‘号码’） \nselect a.personMemberID, * from chineseresume a,personmember b where b.referenceid &#x3D; ‘JCNPRH39681’ and a.personMemberID &#x3D; ‘JCNPRH39681’ （B &#x3D; ‘号码’， A &#x3D; ‘号码’）\n26、尽量使用exists代替select count(1)来判断是否存在记录，count函数只有在统计表中所有行数时使用，而且count(1)比count(*)更有效率。\n27、尽量使用“&gt;&#x3D;”，不要使用“&gt;”。\n28、索引的使用规范：\n\n索引的创建要与应用结合考虑，建议大的OLTP表不要超过6个索引；\n尽可能的使用索引字段作为查询条件，尤其是聚簇索引，必要时可以通过index index_name来强制指定索引；\n避免对大表查询时进行table scan，必要时考虑新建索引；\n在使用索引字段作为条件时，如果该索引是联合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用；\n要注意索引的维护，周期性重建索引，重新编译存储过程。\n\n　　\n29、下列SQL条件语句中的列都建有恰当的索引，但执行速度却非常慢： \nSELECT * FROM record WHERE substrINg(card_no,1,4)&#x3D;’5378’ (13秒) \nSELECT * FROM record WHERE amount&#x2F;30&lt; 1000 （11秒） \nSELECT * FROM record WHERE convert(char(10),date,112)&#x3D;’19991201’ （10秒） \n分析： \nWHERE子句中对列的任何操作结果都是在SQL运行时逐列计算得到的，因此它不得不进行表搜索，而没有使用该列上面的索引。\n如果这些结果在查询编译时就能得到，那么就可以被SQL优化器优化，使用索引，避免表搜索，因此将SQL重写成下面这样： \nSELECT * FROM record WHERE card_no like ‘5378%’ （&lt; 1秒） \nSELECT * FROM record WHERE amount&lt; 1000*30 （&lt; 1秒） \nSELECT * FROM record WHERE date&#x3D; ‘1999&#x2F;12&#x2F;01’ （&lt; 1秒）\n30、当有一批处理的插入或更新时，用批量插入或批量更新，绝不会一条条记录的去更新。批量插入的方法请关注公众号Java技术栈然后搜索阅读。\n31、在所有的存储过程中，能够用SQL语句的，我绝不会用循环去实现。\n例如：列出上个月的每一天，我会用connect by去递归查询一下，绝不会去用循环从上个月第一天到最后一天。\n32、选择最有效率的表名顺序（只在基于规则的优化器中有效）： \nOracle的解析器按照从右到左的顺序处理FROM子句中的表名，FROM子句中写在最后的表（基础表 driving table）将被最先处理，在FROM子句中包含多个表的情况下，你必须选择记录条数最少的表作为基础表。\n如果有3个以上的表连接查询，那就需要选择交叉表（intersection table）作为基础表，交叉表是指那个被其他表所引用的表。\n33、提高GROUP BY语句的效率，可以通过将不需要的记录在GROUP BY之前过滤掉。下面两个查询返回相同结果，但第二个明显就快了许多。 \n低效：\nSELECT JOB , AVG(SAL) \nFROM EMP \nGROUP BY JOB \nHAVING JOB &#x3D;’PRESIDENT’ \nOR JOB &#x3D;’MANAGER’ \n高效: \nSELECT JOB , AVG(SAL) \nFROM EMP \nWHERE JOB &#x3D;’PRESIDENT’ \nOR JOB &#x3D;’MANAGER’ \nGROUP BY JOB\n34、SQL语句用大写，因为Oracle总是先解析SQL语句，把小写的字母转换成大写的再执行。\n35、别名的使用，别名是大型数据库的应用技巧，就是表名、列名在查询中以一个字母为别名，查询速度要比建连接表快1.5倍。\n36、避免死锁，在你的存储过程和触发器中访问同一个表时总是以相同的顺序；事务应经可能地缩短，在一个事务中应尽可能减少涉及到的数据量；永远不要在事务中等待用户输入。\n37、避免使用临时表，除非却有需要，否则应尽量避免使用临时表，相反，可以使用表变量代替；大多数时候(99%)，表变量驻扎在内存中，因此速度比临时表更快，临时表驻扎在TempDb数据库中，因此临时表上的操作需要跨数据库通信，速度自然慢。\n38、最好不要使用触发器：\n\n触发一个触发器，执行一个触发器事件本身就是一个耗费资源的过程；\n如果能够使用约束实现的，尽量不要使用触发器；\n不要为不同的触发事件(Insert，Update和Delete)使用相同的触发器；\n不要在触发器中使用事务型代码。\n\n39、索引创建规则： \n\n表的主键、外键必须有索引； \n数据量超过300的表应该有索引； \n经常与其他表进行连接的表，在连接字段上应该建立索引； \n经常出现在Where子句中的字段，特别是大表的字段，应该建立索引； \n索引应该建在选择性高的字段上； \n索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引； \n复合索引的建立需要进行仔细分析，尽量考虑用单字段索引代替； \n正确选择复合索引中的主列字段，一般是选择性较好的字段； \n复合索引的几个字段是否经常同时以AND方式出现在Where子句中？单字段查询是否极少甚至没有？如果是，则可以建立复合索引；否则考虑单字段索引； \n如果复合索引中包含的字段经常单独出现在Where子句中，则分解为多个单字段索引； \n如果复合索引所包含的字段超过3个，那么仔细考虑其必要性，考虑减少复合的字段； \n如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引； \n频繁进行数据操作的表，不要建立太多的索引； \n删除无用的索引，避免对执行计划造成负面影响； \n表上建立的每个索引都会增加存储开销，索引对于插入、删除、更新操作也会增加处理上的开销。另外，过多的复合索引，在有单字段索引的情况下，一般都是没有存在价值的；相反，还会降低数据增加删除时的性能，特别是对频繁更新的表来说，负面影响更大。 \n尽量不要对数据库中某个含有大量重复的值的字段建立索引。MySQL开发 36 条军规，推荐看下。\n\n40、MySQL查询优化总结：\n使用慢查询日志去发现慢查询，使用执行计划去判断查询是否正常运行，总是去测试你的查询看看是否他们运行在最佳状态下。关注公众号Java技术栈回复面试，可以获取 MySQL 及更多面试题。\n久而久之性能总会变化，避免在整个表上使用count(*)，它可能锁住整张表，使查询保持一致以便后续相似的查询可以使用查询缓存，在适当的情形下使用GROUP BY而不是DISTINCT，在WHERE、GROUP BY和ORDER BY子句中使用有索引的列，保持索引简单，不在多个索引中包含同一个列。\n有时候MySQL会使用错误的索引，对于这种情况使用USE INDEX，检查使用SQL_MODE&#x3D;STRICT的问题，对于记录数小于5的索引字段，在UNION的时候使用LIMIT不是是用OR。 \n为了避免在更新前SELECT，使用INSERT ON DUPLICATE KEY或者INSERT IGNORE，不要用UPDATE去实现，不要使用MAX，使用索引字段和ORDER BY子句，LIMIT M，N实际上可以减缓查询在某些情况下，有节制地使用，在WHERE子句中使用UNION代替子查询，在重新启动的MySQL，记得来温暖你的数据库，以确保数据在内存和查询速度快，考虑持久连接，而不是多个连接，以减少开销。\n基准查询，包括使用服务器上的负载，有时一个简单的查询可以影响其他查询，当负载增加在服务器上，使用SHOW PROCESSLIST查看慢的和有问题的查询，在开发环境中产生的镜像数据中测试的所有可疑的查询。\n41、MySQL备份过程：\n\n从二级复制服务器上进行备份；\n在进行备份期间停止复制，以避免在数据依赖和外键约束上出现不一致；\n彻底停止MySQL，从数据库文件进行备份；\n如果使用MySQL dump进行备份，请同时备份二进制日志文件 – 确保复制没有中断；\n不要信任LVM快照，这很可能产生数据不一致，将来会给你带来麻烦；\n为了更容易进行单表恢复，以表为单位导出数据——如果数据是与其他表隔离的。 \n当使用mysqldump时请使用–opt；\n在备份之前检查和优化表；\n为了更快的进行导入，在导入时临时禁用外键约束。；\n为了更快的进行导入，在导入时临时禁用唯一性检测；\n在每一次备份后计算数据库，表以及索引的尺寸，以便更够监控数据尺寸的增长；\n通过自动调度脚本监控复制实例的错误和延迟；\n定期执行备份。\n\n42、查询缓冲并不自动处理空格，因此，在写SQL语句时，应尽量减少空格的使用，尤其是在SQL首和尾的空格（因为查询缓冲并不自动截取首尾空格）。\n43、member用mid做标准进行分表方便查询么？一般的业务需求中基本上都是以username为查询依据，正常应当是username做hash取模来分表。\n而分表的话MySQL的partition功能就是干这个的，对代码是透明的；在代码层面去实现貌似是不合理的。\n44、我们应该为数据库里的每张表都设置一个ID做为其主键，而且最好的是一个INT型的（推荐使用UNSIGNED），并设置上自动增加的AUTO_INCREMENT标志。\n45、在所有的存储过程和触发器的开始处设置SET NOCOUNT ON，在结束时设置SET NOCOUNT OFF。无需在执行存储过程和触发器的每个语句后向客户端发送DONE_IN_PROC消息。\n46、MySQL查询可以启用高速查询缓存。这是提高数据库性能的有效MySQL优化方法之一。当同一个查询被执行多次时，从缓存中提取数据和直接从数据库中返回数据快很多。\n47、EXPLAIN SELECT查询用来跟踪查看效果：\n使用EXPLAIN关键字可以让你知道MySQL是如何处理你的SQL语句的。这可以帮你分析你的查询语句或是表结构的性能瓶颈。EXPLAIN的查询结果还会告诉你你的索引主键被如何利用的，你的数据表是如何被搜索和排序的。\n48、当只要一行数据时使用LIMIT 1 ：\n当你查询表的有些时候，你已经知道结果只会有一条结果，但因为你可能需要去fetch游标，或是你也许会去检查返回的记录数。\n在这种情况下，加上LIMIT 1可以增加性能。这样一来，MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据。\n49、选择表合适存储引擎： \n\nmyisam：应用时以读和插入操作为主，只有少量的更新和删除，并且对事务的完整性，并发性要求不是很高的。 \n\nInnoDB：事务处理，以及并发条件下要求数据的一致性。除了插入和查询外，包括很多的更新和删除。（InnoDB有效地降低删除和更新导致的锁定）。\n对于支持事务的InnoDB类型的表来说，影响速度的主要原因是AUTOCOMMIT默认设置是打开的，而且程序没有显式调用BEGIN 开始事务，导致每插入一条都自动提交，严重影响了速度。可以在执行SQL前调用begin，多条SQL形成一个事物（即使autocommit打开也可以），将大大提高性能。\n\n\n50、优化表的数据类型，选择合适的数据类型： \n原则：更小通常更好，简单就好，所有字段都得有默认值，尽量避免null。 \n例如：数据库表设计时候更小的占磁盘空间尽可能使用更小的整数类型。(mediumint就比int更合适) \n比如时间字段：datetime和timestamp，datetime占用8个字节，而timestamp占用4个字节，只用了一半，而timestamp表示的范围是1970—2037适合做更新时间 \nMySQL可以很好的支持大数据量的存取，但是一般说来，数据库中的表越小，在它上面执行的查询也就会越快。 \n因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。\n例如：在定义邮政编码这个字段时，如果将其设置为CHAR(255)，显然给数据库增加了不必要的空间。甚至使用VARCHAR这种类型也是多余的，因为CHAR(6)就可以很好的完成任务了。\n同样的，如果可以的话，我们应该使用MEDIUMINT而不是BIGIN来定义整型字段，应该尽量把字段设置为NOT NULL，这样在将来执行查询的时候，数据库不用去比较NULL值。 \n对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在MySQL中，ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多。这样，我们又可以提高数据库的性能。\n51、字符串数据类型：char，varchar，text选择区别。\n52、任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询时要尽可能将操作移至等号右边。\n","slug":"01_MySQL/性能优化策略","date":"2020-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"6209a41d0c1bdc89b8242b6c5a89a469","title":"MySQL三范式","content":"\n\n\n\n\n\n\n\n\n数据库三范式\n第一范式：1NF是对属性的原子性约束，要求属性具有原子性，不可再分解；\n第二范式：2NF是对记录的唯一性约束，要求记录有唯一标识，即实体的唯一性；\n第三范式：3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。\n\n\n\n\n\n\n\n\n\n范式化\n优点：可以尽量的减少数据冗余，使得更新快，体积小\n缺点：对于查询需要多个表进行关联，减少写的效率增加读的效率，更难进行索引优化\n\n\n\n\n\n\n\n\n\n反范式化\n优点：可以减少表的关联，可以更好的进行索引优化\n缺点：数据冗余以及数据异常，数据的修改需要更多的成本\n\n\n\n\n\n\n\n\n\n归纳\n\n\n\n方式\n第一范式\n第二范式\n第三范式\n\n\n\n约束\n原子性\n唯一性\n冗余性\n\n\n优点\n更新快\n体积小\n减少数据冗余\n\n\n缺点\n对于查询需要多个表进行关联\n减少写的效率增加读的效率\n更难进行索引优化\n\n\n(反)优点\n可以减少表的关联\n可以更好的进行索引优化\n-\n\n\n(反)缺点\n数据冗余以及数据异常\n数据的修改需要更多的成本\n-\n\n\n","slug":"01_MySQL/范式","date":"2020-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"1d3d34015824551bc1c5fbed5c50786a","title":"冒泡排序","content":"在要排序的一组数中，对当前还未排好的序列，\n从前往后对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。\n即，每当两相邻的数比较后发现它们的排序与排序要求相反时，就将它们互换。\n$arr &#x3D; [1, 43, 54, 62, 21, 66, 32, 78, 36, 76, 39];\n\nfunction bubble_sort($arr)\n&#123;\n  $len &#x3D; count($arr);\n  &#x2F;&#x2F;该层循环控制 需要冒泡的轮数\n  for($i &#x3D; 0; $i &lt; $len - 1; $i++) &#123;\n    &#x2F;&#x2F;该层循环用来控制每轮 冒出一个数 需要比较的次数\n    for($k &#x3D; 0; $k &lt; $len- $i - 1; $k++) &#123;\n      &#x2F;&#x2F; 下一个键\n      $nk &#x3D; $k + 1;\n      &#x2F;&#x2F; 如果当前值比下一个值大\n      if($arr[$k] &gt; $arr[$nk]) &#123;\n        &#x2F;&#x2F; 把下一个值先存起来\n        $tmp      &#x3D; $arr[$nk];\n        &#x2F;&#x2F; 把当前值给下一个键，覆盖\n        $arr[$nk] &#x3D; $arr[$k];\n        &#x2F;&#x2F; 再把存起来的值，给当前键\n        $arr[$k]  &#x3D; $tmp;\n      &#125;\n    &#125;\n  &#125;\n  \n  return $arr;\n&#125;\n\n","slug":"07_LeetCode/冒泡排序","date":"2020-03-20T07:05:07.000Z","categories_index":"LeetCode","tags_index":"冒泡排序","author_index":"Michael"},{"id":"9c04d15496da1d73edddda137155e866","title":"快速排序","content":"选择一个基准元素，通常选择第一个元素或者最后一个元素。\n通过一趟扫描，将待排序列分成两部分，\n一部分比基准元素小，一部分大于等于基准元素。\n此时基准元素在其排好序后的正确位置，\n然后再用同样的方法递归地排序划分的两部分。\n$arr &#x3D; [1, 43, 54, 62, 21, 66, 32, 78, 36, 76, 39];\n\nfunction quick_sort($arr)\n&#123;\n  $len &#x3D; count($arr);\n  &#x2F;&#x2F; 先判断是否需要继续进行\n  if($len &lt;&#x3D; 1) &#123;\n    \n    return $arr;\n  &#125;\n  \n  &#x2F;&#x2F; 选择第一个元素作为基准\n  $baseNum &#x3D; $arr[0];\n  &#x2F;&#x2F; 遍历除了标尺外的所有元素，按照大小关系放入两个数组内\n  &#x2F;&#x2F; 初始化比基准值小和大的俩个数组:\n  $leftArray &#x3D; $rightArray &#x3D; [];\n  &#x2F;&#x2F; 开始从第二个值开始比较\n  for ($i &#x3D; 1; $i &lt; $len; $i++) &#123;\n    if ($baseNum &gt; $arr[$i]) &#123;\n      &#x2F;&#x2F; 放入左边数组\n      $leftArray[]  &#x3D; $arr[$i];\n    &#125; else &#123;\n      &#x2F;&#x2F; 放入右边\n      $rightArray[] &#x3D; $arr[$i];\n    &#125;\n  &#125;\n  \n  &#x2F;&#x2F; 再分别对左边和右边的数组进行相同的排序处理方式递归调用这个函数\n  $leftArray  &#x3D; quick_sort($leftArray);\n  $rightArray &#x3D; quick_sort($rightArray);\n  \n  &#x2F;&#x2F; 合并返回结果\n  return array_merge($leftArray, [$baseNum], $rightArray);\n&#125;\n\n","slug":"07_LeetCode/快速排序","date":"2020-03-20T07:05:07.000Z","categories_index":"LeetCode","tags_index":"快速排序","author_index":"Michael"},{"id":"f2ea62009b2a302d5e2076e5efd27611","title":"插入排序","content":"在要排序的一组数中，假设前面的数已经是排好顺序的，\n现在要把第n个数插到前面的有序数中，使得这n个数也是排好顺序的。\n如此反复循环，直到全部排好顺序。\n$arr &#x3D; [1, 43, 54, 62, 21, 66, 32, 78, 36, 76, 39];\n\nfunction insert_sort($arr)\n&#123;\n  &#x2F;&#x2F; 计算数组长度\n  $len &#x3D; count($arr); \n  &#x2F;&#x2F; 循环数组\n  for($i &#x3D; 1; $i &lt; $len; $i++) &#123;\n    &#x2F;&#x2F; 当前值缓存起来\n    $tmp &#x3D; $arr[$i];\n    &#x2F;&#x2F; 内层循环控制，比较并插入\n    for($j &#x3D; $i - 1; $j &gt;&#x3D; 0; $j--) &#123;\n      \n      \n      if($tmp &lt; $arr[$j]) &#123;\n        &#x2F;&#x2F;发现插入的元素要小，交换位置，将后边的元素与前面的元素互换\n      \t$arr[$j + 1] &#x3D; $arr[$j];\n        $arr[$j]\t\t &#x3D; $tmp;\n      &#125; else &#123;\n        &#x2F;&#x2F;如果碰到不需要移动的元素，由于是已经排序好是数组，则前面的就不需要再次比较了。\n        break;\n      &#125;\n    &#125;\n  &#125;\n  \n  &#x2F;&#x2F; 返回结果\n  return $arr;\n&#125;\n\n","slug":"07_LeetCode/插入排序","date":"2020-03-20T07:05:07.000Z","categories_index":"LeetCode","tags_index":"插入排序","author_index":"Michael"},{"id":"d1408add887a68e7d3f5038df24f24f8","title":"约瑟夫环","content":"一群猴子排成一圈，按1,2,…,n依次编号。\n然后从第1只开始数，数到第m只,把它踢出圈，\n从它后面再开始数，再数到第m只，再把它踢出去…，\n如此不停的进行下去，直到最后只剩下一只猴子为止，那只猴子就叫做大王。\n要求编程模拟此过程，输入m、n, 输出最后那个大王的编号。\nfunction mk($n ,$m)\n&#123;\n  $arr &#x3D; range(1, $n);&#x2F;&#x2F; 构造一个数组\n  $i   &#x3D; 1; &#x2F;&#x2F;从第一个开始循环\n  $len &#x3D; count($arr);\n  while($len &gt; 1) &#123; &#x2F;&#x2F; 如果总数大于1\n    $pk &#x3D; $i - 1;\n    ($i % $m !&#x3D; 0) &amp;&amp; array_push($arr, $arr[$pk]); &#x2F;&#x2F; 不被踢出则压入数组尾部\n    unset($arr[$pk]); &#x2F;&#x2F; 压入数组然后删除\n    $i++;&#x2F;&#x2F;继续循环\n  &#125;\n  \n  return $arr[$i - 1]; &#x2F;&#x2F;直至最后剩下一个为大王 \n&#125;\n\necho mk(6,8);   &#x2F;&#x2F; 第3只为大王","slug":"07_LeetCode/约瑟夫环","date":"2020-03-20T07:05:07.000Z","categories_index":"LeetCode","tags_index":"约瑟夫环","author_index":"Michael"},{"id":"25abdf87b37439d6db828d8a717bff02","title":"选择排序","content":"在要排序的一组数中，选出最小的一个数与第一个位置的数交换。\n然后在剩下的数当中再找最小的与第二个位置的数交换，\n如此循环到倒数第二个数和最后一个数比较为止。\n$arr &#x3D; [1, 43, 54, 62, 21, 66, 32, 78, 36, 76, 39];\n\nfunction select_sort($arr)\n&#123;\n  &#x2F;&#x2F; 双重循环完成，外层控制轮数，内层控制比较次数\n  $len &#x3D; count($arr);\n  &#x2F;&#x2F; 循环 数组 的长度，也就是Key\n  for($i &#x3D; 0; $i &lt; $len - 1; $i++) &#123;\n    &#x2F;&#x2F; 先假设最小的值的位置\n    $p &#x3D; $i;\n    &#x2F;&#x2F; 从 $i的下一个键开始循环\n    for($j &#x3D; $i + 1; $j &lt; $len; $j++) &#123;      \n      &#x2F;&#x2F; 找出比 $p 对应值 还要小的 键\n      ($arr[$j] &lt; $arr[$p]) &amp;&amp; $p &#x3D; $j;\n      # &#x2F;&#x2F; $arr[$p] 是当前已知的最小值\n      # if($arr[$p] &gt; $arr[$j]) &#123;\n      #\t\t&#x2F;&#x2F; 比较，发现更小的,记录下最小值的位置；\n      #\t\t&#x2F;&#x2F; 并且在下次比较时采用已知的最小值进行比较。\n      #\t\t$p &#x3D; $j;\n      # &#125;\n    &#125;\n    &#x2F;&#x2F; 已经确定了当前的最小值的位置，保存到$p中。\n    &#x2F;&#x2F; 如果发现最小值的位置与当前假设的位置$i不同，则位置互换即可。\n    &#x2F;&#x2F; 俩个键发生了变化，就开始排序\n    if ($p !&#x3D; $i) &#123;\n      $tmp     &#x3D; $arr[$p];\n      $arr[$p] &#x3D; $arr[$i];\n      $arr[$i] &#x3D; $tmp;\n    &#125;\n  &#125;\n  \n  &#x2F;&#x2F;返回最终结果\n  return $arr;\n&#125;\n\n","slug":"07_LeetCode/选择排序","date":"2020-03-20T07:05:07.000Z","categories_index":"LeetCode","tags_index":"选择排序","author_index":"Michael"},{"id":"a48e6dda0c21e40880cba7e763278b04","title":"Docker","content":"Docker","slug":"Docker/Docker","date":"2020-03-20T07:05:07.000Z","categories_index":"Docker","tags_index":"Docker","author_index":"Michael"},{"id":"0aaa27c48e7b40c2bc96b31fb70803da","title":"TypeScript","content":"TypeScript","slug":"HTML/JavaScript","date":"2020-03-20T07:05:07.000Z","categories_index":"TypeScript","tags_index":"TypeScript","author_index":"Michael"},{"id":"0aaa27c48e7b40c2bc96b31fb70803da","title":"TypeScript","content":"TypeScript","slug":"HTML/TypeScript","date":"2020-03-20T07:05:07.000Z","categories_index":"TypeScript","tags_index":"TypeScript","author_index":"Michael"},{"id":"5f258f833478a2a0e21ce42d19305683","title":"Vue","content":"Vue","slug":"HTML/Vue","date":"2020-03-20T07:05:07.000Z","categories_index":"Vue","tags_index":"Vue","author_index":"Michael"},{"id":"a5b97ab8932b5f038d4330f012aa0a62","title":"jQuery","content":"jQuery","slug":"HTML/jQuery","date":"2020-03-20T07:05:07.000Z","categories_index":"jQuery","tags_index":"jQuery","author_index":"Michael"},{"id":"7972c32d39f314ccb6f804289f8a291c","title":"Git基础","content":"GIT\n\n\n\n\n\n\n\n\n以行的模式查看提交日志：\ngit log –pretty&#x3D;oneline\n\n\n\n\n\n\n\n\n\n撤销某次提交，并保留修改 –soft\ngit reset –soft d3c2257b08ffefd69130d9e2bdd1d0328c7d4085\n\n\n\n\n\n\n\n\n\n将修改暂存到缓存区保存起来：\ngit stash save ‘url_scheme’\n\n\n\n\n\n\n\n\n\n回滚某次提交\ngit revert e08e6b103d72a793cc0c21b06f187884c3943f83\n回滚后，记得提交\ngit push\n\n\n\n\n\n\n\n\n\n回到指定分支\ngit checkout T910_URLSchemeLink\n\n\n\n\n\n\n\n\n\n取出缓存区的修改内容\ngit stash pop\n","slug":"SVN/Git","date":"2020-03-20T07:05:07.000Z","categories_index":"git","tags_index":"git","author_index":"Michael"},{"id":"127d1f6ddaf592cdbfe5766a891f8f96","title":"索引采用的算法","content":"\n\n\n\n\n\n\n\n\n索引为什么采用B+树，而不用B-树，红黑树\n提升查询速度，首先要减少磁盘I&#x2F;O次数，也就是要降低树的高度。\n\n平衡二叉树、红黑树，都属于二叉树。\n时间复杂度为O(n)，当表的数据量上千万时，树的深度很深，mysql读取时消耗大量 IO。\n另外，InnoDB引擎采用页为单位读取，每个节点一页，\n但是二叉树每个节点储存一个关键词，导致空间浪费。\n\nB-树，非叶子节点存储数据，占用较多空间，\n导致每个节点的指针少很多，无形增加了树的深度。\n\nB+树数据都存储在叶子节点，非叶子节点只存储健值+指针，\n索引树更加扁平，三层深度可以支持千万级表存储。\n同时叶子节点之间通过链表关联，范围查找更快。\n\n\n","slug":"01_MySQL/索引/B+树","date":"2020-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"91a0e294ae045d1c9047e0525f52b4fd","title":"SQL语句性能分析工具 - explain","content":"通过explain，如以下例子：\nEXPLAIN SELECT * FROM employees.titles WHERE emp_no&#x3D;&#39;10001&#39; AND title&#x3D;&#39;Senior Engineer&#39; AND from_date&#x3D;&#39;1986-06-26&#39;;\n\n\n\n\nid\nselect_type\ntable\npartitions\ntype\npossible_keys\nkey\nkey_len\nref\nfiltered\nrows\nExtra\n\n\n\n1\nSIMPLE\ntitles\nnull\nconst\nPRIMARY\nPRIMARY\n59\nconst,const,const\n10\n1\n\n\n\n\nid：在⼀个⼤的查询语句中每个SELECT关键字都对应⼀个唯⼀的id ，如\nexplain select * from s1 where id = (select id from s1 where name = &#39;egon1&#39;);\n第一个select的id是1，第二个select的id是2。\n有时候会出现两个select，但是id却都是1，\n这是因为优化器把子查询变成了连接查询 。\n\nselect_type：select关键字对应的那个查询的类型，如\n\n\n\n\n类型\n含义\n\n\n\nSIMPLE\n简单SELECT查询，不包含子查询和UNION\n\n\nPRIMARY\n复杂查询中的最外层查询，表示主要的查询\n\n\nSUBQUERY\nSELECT或WHERE列表中包含了子查询\n\n\nDERIVED\nFROM列表中包含的子查询，即衍生\n\n\nUNION\nUNION关键字之后的查询\n\n\nUNION RESULT\n从UNION后的表获取结果集\n\n\n\ntable：每个查询对应的表名 \n\n&lt;unionM,N&gt;：具有和id值的行的M并集N。\n&lt;derivedN&gt;：用于与该行的派生表结果id的值N。派生表可能来自（例如）FROM子句中的子查询 。\n&lt;subqueryN&gt;：子查询的结果，其id值为N\n\n\npartitions：该列的值表示查询将从中匹配记录的分区\n\ntype：type 字段比较重要, 它提供了判断查询是否高效的重要依据依据.\n通过 type 字段, 我们判断此次查询是 全表扫描 还是 索引扫描 等。如\nconst(主键索引或者唯一二级索引进行等值匹配的情况下)；\nref(普通的⼆级索引列与常量进⾏等值匹配)；\nindex(扫描全表索引的覆盖索引) …\nsystem &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL\n通常来说, 不同的 type 类型的性能关系如下:\nALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; system\nALL 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.而 index 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.\n\npossible_key：查询中可能用到的索引(可以把用不到的删掉，降低优化器的优化时间)\n\nkey：此字段是 MySQL 在当前查询时所真正使用到的索引。\n\nkey_len：该列表示使用索引的长度。\n\nref：该列表示索引命中的列或者常量。\n\nrows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好。\n\nfiltered：查询器预测满足下一次查询条件的百分比 。\n\nextra：表示额外信息，如Using where,Start temporary,End temporary,Using temporary等。\n\n\n\n枚举值\n涵义\n\n\n\nImpossible WHERE\n表示WHERE后面的条件一直都是false\n\n\nUsing filesort\n表示按文件排序，一般是在指定的排序和索引排序不一致的情况才会出现\n\n\nUsing index\n表示是否用了覆盖索引，说白了它表示是否所有获取的列都走了索引\n\n\nUsing temporary\n表示是否使用了临时表，一般多见于order by 和 group by语句\n\n\nUsing where\n表示使用了where条件过滤\n\n\nUsing join buffer\n表示是否使用连接缓冲\n\n\nNo tables used\nQuery语句中使用from dual 或不含任何from子句\n\n\nSelect tables optimized away\n这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行\n\n\n\n\n常用的字符编码占用字节数量如下：\n\n目前我的数据库字符编码格式用的：UTF8占3个字节。\nMySQL常用字段占用字节数：\n\n\n\n字段类型\n占用字节数\n\n\n\nchar(n)\nn\n\n\nvarchar(n)\nn + 2\n\n\ntinyint\n1\n\n\nsmallint\n2\n\n\nint\n4\n\n\nbigint\n8\n\n\ndate\n3\n\n\ntimestamp\n4\n\n\ndatetime\n8\n\n\n使用explain命令，查看MySQL的执行计划。\n\n\n\n项目\n释义\n\n\n\nid\nselect唯一标识\n\n\nselect_type\nselect类型\n\n\ntable\n表名称\n\n\npartitions\n匹配的分区\n\n\ntype\n连接类型\n\n\npossible_keys\n可能的索引选择\n\n\nkey\n实际用到的索引\n\n\nkey_len\n实际索引长度\n\n\nref\n与索引比较的列\n\n\nrows\n预期要检查的行数\n\n\nfiltered\n按表条件过滤的行百分比\n\n\nextra\n附加信息\n\n\n索引优化的过程\n先用慢查询日志定位具体需要优化的sql\n\n使用explain执行计划查看索引使用情况\n\n重点关注：\nkey（查看有没有使用索引）\nkey_len（查看索引使用是否充分）\ntype（查看索引类型）\nextra（查看附加信息：排序、临时表、where条件为false等）\n一般情况下根据这4列就能找到索引问题。\n\n根据上1步找出的索引问题优化sql\n\n再回到第2步\n\n\n","slug":"01_MySQL/Explain","date":"2019-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"ef9e2edc26d3ded046b353bb82c77d51","title":"MySQL - MVCC","content":"MVCC叫做多版本控制，实现MVCC时用到了一致性视图，用于支持读提交和可重复读的实现。\n对于一行数据若是想实现可重复读取或者能够读取数据的另一个事务未提交前的原始值，那么必须对原始数据进行保存或者对更新操作进行保存，这样才能够查询到原始值。\n在Mysql的MVCC中规定每一行数据都有多个不同的版本，一个事务更新操作完后就生成一个新的版本，并不是对全部数据的全量备份，因为全量备份的代价太大了：\n\n如图中所示，假如三个事务更新了同一行数据，那么就会有对应的v1、v2、v3三个数据版本，每一个事务在开始的时候都获得一个唯一的事务id（transaction id），并且是顺序递增的，并且这个事务id最后会赋值给row trx_id，这样就形成了一个唯一的一行数据版本。\n实际上版本1、版本2并非实际物理存在的，而图中的U1和U2实际就是undo log日志（回滚日志），这v1和v2版本是根据当前v3和undo log计算出来的。\nInnoDB引擎就是利用每行数据有多个版本的特性，实现了秒级创建“快照”，并不需要花费大量的是时间。\n","slug":"01_MySQL/MVCC","date":"2019-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"e7f5587de2fa0cb9394ae0921cbff0fa","title":"MySQL主从复制与读写分离","content":"\n\n\n\n\n\n\n\n\n主从同步\n\nmaster主库，有数据更新，将此次更新的事件类型写入到主库的binlog文件中\n主库会创建log dump 线程通知slave有数据更新\nslave从库，向master节点的 log dump线程请求一份指定binlog文件位置的副本，并将请求回来的binlog存到本地的Relay log 中继日志中\nslave 再开启一个SQL 线程读取Relay log事件，并在本地执行redo操作。将发生在主库的事件在本地重新执行一遍，从而保证主从数据同步\n\n\n\n\n\n\n\n\n\n\n\n主从延迟\n指一个写入SQL操作在主库执行完后，将数据完整同步到从库会有一个时间差，称之为主从延迟。\n\n主库生成一条写入SQL的binlog，里面会有一个时间字段，记录写入的时间戳 t1\nbinlog 同步到从库后，一旦开始执行，取当前时间 t2\nt2-t1，就是延迟时间\n\n注意：不同服务器要保持时钟一致。\n\n\n\n\n\n\n\n\n\n主从延迟排查方法\n通过 show slave status 命令输出的Seconds_Behind_Master参数的值来判断\n\n为零：表示主从复制良好\n正值：表示主从已经出现延时，数字越大，表示从库延迟越严重\n\n\n\n\n\n\n\n\n\n\n主从延迟的解决方案\n\n看业务的接受程度。如果不能接受延迟，那么建议强制走主库查询\n可以考虑引入缓存，更新主库后同步写入缓存，保证缓存的及时性\n提升从库的机器配置，提高从库binlog的同步效率\n缩短主、从库的网络距离，减少binlog的网络传输时间\n一主多从，每个从库都启一个线程从主库同步 binlog，导致主库压力过大，可以采用canal 增量订阅&amp;消费组件，缓解主库压力。\n因为数据库必须要等到事务完成之后才会写入binlog，所以减少大事务的执行，尽量控制数量，分批执行。\n5.6版本之前，从库是单线程复制，当遇到执行慢的sql时，就会阻塞后面的同步。5.7 版本后支持多线程复制，可以在从服务上设置slave_parallel_workers为一个大于0的数，然后把slave_parallel_type参数设置为LOGICAL_CLOCK\n为从库增加浮动IP，并通过脚本检测从库的延迟，延迟大于指定阈值时，将浮动IP切换至Master库，追平后再切换回从库。\n\n","slug":"01_MySQL/主从读写","date":"2019-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"475d8cc506c896f960af12777142c003","title":"MySQL主键","content":"主键使用自增ID还是UUID?能说说原因吗？\n自增ID和UUID作为主键的考虑主要有两方面，\n一个是性能\n另一个就是存储的空间大小，\n一般没有特定的业务要求都不推荐使用UUID作为主键。\n因为使用UUID作为主键插入并不能保证插入是有序的，有可能会涉及数据的挪动，也有可能触发数据页的分裂，因为一个数据页的大小就是16KB，这样插入数据的成本就会比较高。\n而自增ID作为主键的话插入数据都是追加操作，不会有数据的移动以及数据页的分裂，性能会比较好。\n另一方面就是存储空间，\n自增主键一般整形只要4个字节，长整形才占8字节的大小空间，\n而使用UUID作为主键存储空间需要16字节的大小，会占用更多的磁盘，\n在二级索引中也会存出一份主键索引，这样多占用消耗的空间就是两倍，性能低，\n所以不推荐使用。\n自增id是连续的，插入过程也是顺序的，总是插入在最后，减少了页分裂，有效减少数据的移动。\n所以尽量不要使用字符串（如：UUID）作为主键。\n","slug":"01_MySQL/主键","date":"2019-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"fb7e30301338d92aa2ed33accfcc50d6","title":"分库分表","content":"\n\n\n\n\n\n\n\n\n分库分表\n​\t并发量决定是否需要分库，\n​\t数据量决定是否需要分表。\n\n\n\n\n\n\n\n\n\n分区分片\n​\t按时间范围归档分区\n​\t按用户ID取模分表，\n​\t按shardingkey来分片；\n\n\n\n\n\n\n\n\n\n数据量太大的场景\nmysql表的数据量一般控制在千万级别，如果再大的话，就要考虑分库分表。\n除了分表外，列举了面对海量数据业务的一些常见优化手段\n\n缓存加速\n读写分离\n垂直拆分\n分库分表\n冷热数据分离\nES助力复杂搜索\nNoSQL\nNewSQL\n\n\n\n\n\n\n\n\n\n\n分表后ID如何保证全局唯一\n分库分表后，多张表共用一套全局id，原来单表主键自增方式满足不了要求。\n我们需要重新设计一套id生成器。\n特点：全局唯一、高性能、高可用、方便接入。\n\nUUID\n数据库自增ID\n数据库的号段模式，每个业务定义起始值、步长，一次拉取多个id号码\n基于Redis，通过incr命令实现ID的原子性自增。\n雪花算法（Snowflake）\n市面的一些开源框架，如：百度（uid-generator），美团（Leaf）， 滴滴（Tinyid）等\n\n\n\n\n\n\n\n\n\n\n分表后可能遇到的问题\n分表后，与单表的最大区别是有分表键sharding_key，用来路由具体的物理表，以电商为例，有买家和卖家两个维度，以buyer_id路由，无法满足卖家的需求，反之同样道理。如何解决？\n\n分买家库和卖家库，将买家库做为写库，保存完整的数据关系。同时将数据异构同步一份到卖家库，卖家库可以只存储seller_id，order_id，buyer_id 等几个简单关系字段即可，以seller_id作为分表键\n多线程扫描，分段查找，然后再聚合结果\n另外也可以存到ES中，支持多维度复杂搜索\n\n","slug":"01_MySQL/分库分表","date":"2019-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"f9a9c6facd4e5bfb5a48d022643ffd1d","title":"控制并发","content":"Mysql内部通过锁机制实现对资源的并发访问控制，保证数据的一致性，锁机制的类型和引擎的种类有关，MyISAM中默认支持的表级锁有两种：共享读锁和独占写锁。表级锁在MyISAM和InnoDB的存储引擎中都支持，但是InnoDB默认支持的是行锁。\nMyISAM锁机制Mysql中可以通过以下sql来显示的在事务中显式的进行加锁和解锁操作：\n&#x2F;&#x2F; 显式的添加表级读锁\nLOCK TABLE 表名 READ\n&#x2F;&#x2F; 显示的添加表级写锁\nLOCK TABLE 表名 WRITE\n&#x2F;&#x2F; 显式的解锁（当一个事务commit的时候也会自动解锁）\nunlock tables;\n\n（1）MyISAM表级写锁：当一个线程获取到表级写锁后，只能由该线程对表进行读写操作，别的线程必须等待该线程释放锁以后才能操作。\n（2）MyISAM表级共享读锁：当一个线程获取到表级读锁后，该线程只能读取数据不能修改数据，其它线程也只能加读锁，不能加写锁。\nInnoDB锁机制InnoDB和MyISAM不同的是，InnoDB支持行锁和事务，InnoDB中除了有表锁和行级锁的概念，还有Gap Lock（间隙锁）、Next-key Lock锁，间隙锁主要用于范围查询的时候，锁住查询的范围，并且间隙锁也是解决幻读的方案。\nInnoDB中的行级锁是对索引加的锁，在不通过索引查询数据的时候，InnoDB就会使用表锁。\n但是通过索引查询的时候是否使用索引，还要看Mysql的执行计划，Mysql的优化器会判断是一条sql执行的最佳策略。\n若是Mysql觉得执行索引查询还不如全表扫描速度快，那么Mysql就会使用全表扫描来查询，这是即使sql语句中使用了索引，最后还是执行为全表扫描，加的是表锁。\n","slug":"01_MySQL/控制并发","date":"2019-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"406c5d5fe6c6fd475c83074ee629ccea","title":"Redis缓存击穿","content":"什么是缓存击穿？\n其实跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是一个热点的Key，有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。\n分析：\n关键在于某个热点的key失效了，导致大并发集中打在数据库上。所以要从两个方面解决，第一是否可以考虑热点key不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量。\n解决方案：\n1、上面说过了，如果业务允许的话，对于热点的key可以设置永不过期的key。\n2、使用互斥锁。如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库打死。当然这样会导致系统的性能变差。\n","slug":"02_Redis/缓存击穿","date":"2019-03-20T07:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"9a6b411f07708c98a59d4123c2ccd32a","title":"穿透&雪崩&击穿","content":"\n\n\n\n雪崩\n穿透\n击穿\n\n\n\n概念\n当某一个时刻出现大规模的缓存失效的情况，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。\n访问redis中一个不存在的key的时候,会直接穿过缓存,去数据库中进行查询。\n\n\n\n场景\n就是每秒有5000个请求过来时候,redis缓存库崩了,然后这些请求瞬间落在了mysql数据库上,直接导致数据库死机.\n如果是黑客,进行恶意攻击的时候,每次都请求超过2000个&#x2F;秒的时候,这个时候mysql基本上就挂了.\n\n\n\n解决方案\n事前:提高缓存库的高可用, 使用主从结构加哨兵 cluster集群事中:使用ehcache+hystrix限流组件(当请求量非常巨大的时候,就调用自己开发好的一个降级饿组件,返回一些默认值,如友情提示,或者空白值)事后:做持久化,尽快恢复缓存集群,一旦恢复,自动从磁盘上读取数据,恢复内存中的数据.\n每次从数据库中查询到一个不存在的key的时候,就写一个空值到缓存库中,有恶意攻击的时候,直接从缓存中取到这个空值.\n永不过期\n\n\n分析\n造成缓存雪崩的关键在于在同一时间大规模的key失效\n\n\n\n\n\n这三个问题在使用Redis的时候是肯定会遇到的，而且是非常致命性的问题，所以在日常开发中一定要注意，每次使用Redis时，都要对其保持严谨的态度。还有一个需要注意的是要做好熔断，一旦出现缓存雪崩，击穿，穿透这种情况，至少还有熔断机制保护数据库不会被打死。\n","slug":"02_Redis/比较区别_穿透和雪崩","date":"2019-03-20T07:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"a0f45cd6c322a6e03b4044aafd033b7f","title":"Redis缓存穿透","content":"我们使用Redis大部分情况都是通过Key查询对应的值，假如发送的请求传进来的key是不存在Redis中的，那么就查不到缓存，查不到缓存就会去数据库查询。假如有大量这样的请求，这些请求像“穿透”了缓存一样直接打在数据库上，这种现象就叫做缓存穿透。\n分析：\n关键在于在Redis查不到key值，这和缓存击穿有根本的区别，区别在于缓存穿透的情况是传进来的key在Redis中是不存在的。假如有黑客传进大量的不存在的key，那么大量的请求打在数据库上是很致命的问题，所以在日常开发中要对参数做好校验，一些非法的参数，不可能存在的key就直接返回错误提示，要对调用方保持这种“不信任”的心态。\n\n解决方案：\n1、把无效的Key存进Redis中。如果Redis查不到数据，数据库也查不到，我们把这个Key值保存进Redis，设置value&#x3D;”null”，当下次再通过这个Key查询时就不需要再查询数据库。这种处理方式肯定是有问题的，假如传进来的这个不存在的Key值每次都是随机的，那存进Redis也没有意义。\n2、使用布隆过滤器。布隆过滤器的作用是某个 key 不存在，那么就一定不存在，它说某个 key 存在，那么很大可能是存在(存在一定的误判率)。于是我们可以在缓存之前再加一层布隆过滤器，在查询的时候先去布隆过滤器查询 key 是否存在，如果不存在就直接返回。\n\n","slug":"02_Redis/缓存穿透","date":"2019-03-20T07:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"8c8ef61b68dd77d38b57f5cea2b182a9","title":"Redis缓存雪崩","content":"当某一个时刻出现大规模的缓存失效的情况，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。\n\n分析：\n造成缓存雪崩的关键在于在同一时间大规模的key失效。为什么会出现这个问题呢，有几种可能，第一种可能是Redis宕机，第二种可能是采用了相同的过期时间。搞清楚原因之后，那么有什么解决方案呢？\n解决方案：\n1、在原有的失效时间上加上一个随机值，比如1-5分钟随机。这样就避免了因为采用相同的过期时间导致的缓存雪崩。\n如果真的发生了缓存雪崩，有没有什么兜底的措施？\n2、使用熔断机制。当流量到达一定的阈值时，就直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上。至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。\n3、提高数据库的容灾能力，可以使用分库分表，读写分离的策略。\n4、为了防止Redis宕机导致缓存雪崩的问题，可以搭建Redis集群，提高Redis的容灾性。\n","slug":"02_Redis/缓存雪崩","date":"2019-03-20T07:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"f89d86da12057f40e1f8accda509e042","title":"HTTP","content":"什么是HTTP?\n\n\n\n\n\n\n\n\n\n超文本传输协议，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP&#x2F;IP协议传输数据，互联网上应用最为广泛的一种网络协议,所有的WWW文件都必须遵守这个标准。设计HTTP的初衷是为了提供一种发布和接收HTML页面的方法。\nHTTP特点：\n\n无状态：协议对客户端没有状态存储，对事物处理没有“记忆”能力，比如访问一个网站需要反复进行登录操作。\n无连接：HTTP&#x2F;1.1之前，由于无状态特点，每次请求需要通过TCP三次握手四次挥手，和服务器重新建立连接。比如某个客户机在短时间多次请求同一个资源，服务器并不能区别是否已经响应过用户的请求，所以每次需要重新响应请求，需要耗费不必要的时间和流量。\n基于请求和响应：基本的特性，由客户端发起请求，服务端响应。\n简单快速、灵活。\n通信使用明文、请求和响应不会对通信方进行确认、无法保护数据的完整性。\n\nHTTP报文组成:\n\n请求行：包括请求方法、URL、协议&#x2F;版本\n请求头(Request Header)\n请求正文\n状态行\n响应头\n响应正文\n\n\nHTTP的缺点：\n\n通信使用明文（不加密），内容可能会被窃听。\n不验证通信方的身份，因此有可能遭遇伪装。\n无法证明报文的完整性，所以有可能已遭篡改。\n\n","slug":"03_HTTP/HTTP","date":"2019-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"HTTP","author_index":"Michael"},{"id":"f1176c7b24a04d98c4070e6d4bd0d70f","title":"Socket","content":"Socket是为了实现通信过程而建立成来的通信管道，其真实的代表是客户端和服务器端的一个通信进程，双方进程通过Socket进行通信，而通信的规则采用指定的协议。Socket只是一种连接模式，不是协议，TCP、UDP，简单的说（虽然不准确）是两个最基本的协议,很多其它协议都是基于这两个协议如，HTTP就是基于TCP的，.用Socket可以创建TCP连接，也可以创建UDP连接，这意味着，用Socket可以创建任何协议的连接，因为其它协议都是基于此的。 实际上，传输层的TCP是基于网络层的IP协议的，而应用层的HTTP协议又是基于传输层的TCP协议的，而Socket本身不算是协议，就像上面所说，它只是提供了一个针对TCP或者UDP编程的接口。\n","slug":"03_HTTP/Socket","date":"2019-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"Socket","author_index":"Michael"},{"id":"99ef2973aa94aa65ee3d2082ee3b960d","title":"HTTP状态码","content":"常见 HTTP 状态码，分别代表什么含义\n\n\n\n状态码\n含义\n\n\n\n1xx\n消息临时响应\n\n\n2xx\n成功\n\n\n3xx\n重定向\n\n\n4xx\n客户端错误\n\n\n5xx\n服务器错误\n\n\nHTTP状态码列表\n\n\n\n状态码\n状态码英文名称\n中文描述\n\n\n\n100\nContinue\n继续。客户端应继续其请求\n\n\n101\nSwitching Protocols\n切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议\n\n\n\n\n\n\n\n200\nOK\n请求成功。一般用于GET与POST请求\n\n\n201\nCreated\n已创建。成功请求并创建了新的资源\n\n\n202\nAccepted\n已接受。已经接受请求，但未处理完成\n\n\n203\nNon-Authoritative Information\n非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本\n\n\n204\nNo Content\n无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档\n\n\n205\nReset Content\n重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域\n\n\n206\nPartial Content\n部分内容。服务器成功处理了部分GET请求\n\n\n\n\n\n\n\n300\nMultiple Choices\n多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择\n\n\n301\nMoved Permanently\n永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替\n\n\n302\nFound\n临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI\n\n\n303\nSee Other\n查看其它地址。与301类似。使用GET和POST请求查看\n\n\n304\nNot Modified\n未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源\n\n\n305\nUse Proxy\n使用代理。所请求的资源必须通过代理访问\n\n\n306\nUnused\n已经被废弃的HTTP状态码\n\n\n307\nTemporary Redirect\n临时重定向。与302类似。使用GET请求重定向\n\n\n\n\n\n\n\n400\nBad Request\n客户端请求的语法错误，服务器无法理解\n\n\n401\nUnauthorized\n请求要求用户的身份认证\n\n\n402\nPayment Required\n保留，将来使用\n\n\n403\nForbidden\n服务器理解请求客户端的请求，但是拒绝执行此请求\n\n\n404\nNot Found\n服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面\n\n\n405\nMethod Not Allowed\n客户端请求中的方法被禁止\n\n\n406\nNot Acceptable\n服务器无法根据客户端请求的内容特性完成请求\n\n\n407\nProxy Authentication Required\n请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权\n\n\n408\nRequest Time-out\n服务器等待客户端发送的请求时间过长，超时\n\n\n409\nConflict\n服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突\n\n\n410\nGone\n客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置\n\n\n411\nLength Required\n服务器无法处理客户端发送的不带Content-Length的请求信息\n\n\n412\nPrecondition Failed\n客户端请求信息的先决条件错误\n\n\n413\nRequest Entity Too Large\n由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息\n\n\n414\nRequest-URI Too Large\n请求的URI过长（URI通常为网址），服务器无法处理\n\n\n415\nUnsupported Media Type\n服务器无法处理请求附带的媒体格式\n\n\n416\nRequested range not satisfiable\n客户端请求的范围无效\n\n\n417\nExpectation Failed\n服务器无法满足Expect的请求头信息\n\n\n\n\n\n\n\n500\nInternal Server Error\n服务器内部错误，无法完成请求\n\n\n501\nNot Implemented\n服务器不支持请求的功能，无法完成请求\n\n\n502\nBad Gateway\n充当网关或代理的服务器，从远端服务器接收到了一个无效的请求\n\n\n503\nService Unavailable\n由于超载或系统维护，服务器暂时的无法处理\n\n\n","slug":"03_HTTP/状态码","date":"2019-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"HTTP,CODE","author_index":"Michael"},{"id":"e1579ed1c931165c644c9ec68da7a87a","title":"Kafka","content":"使用kafka可以对系统\n​\t解耦、\n​\t流量削峰、\n​\t缓冲\n可以实现系统间的异步通信等。\n在活动追踪、消息传递、度量指标、日志记录和流式处理等场景中非常适合使用kafka。\n\n\n\n\n组件\n释义\n备注\n\n\n\nBroker\n服务代理节点\n其实就是一个kafka实例或服务节点，多个broker构成了kafka cluster\n\n\nProducer\n生产者\n也就是写入消息的一方，将消息写入broker中\n\n\nConsumer\n消费者\n也就是读取消息的一方，从broker中读取消息\n\n\nConsumer Group\n消费组\n一个或多个消费者构成一个消费组，不同的消费组可以订阅同一个主题的消息且互不影响\n\n\nZooKeeper\n\nkafka使用zookeeper来管理集群的元数据，以及控制器的选举等操作\n\n\nTopic\n主题\n每一个消息都属于某个主题，kafka通过主题来划分消息，是一个逻辑上的分类。\n\n\nPartition\n分区\n同一个主题下的消息还可以继续分成多个分区，一个分区只属于一个主题\n\n\nReplica\n副本\n一个分区可以有多个副本来提高容灾性。\n\n\nLeader and Follower\n主从\n分区有了多个副本，那么就需要有同步方式。kafka使用一主多从进行消息同步，主副本提供读写的能力，而从副本不提供读写，仅仅作为主副本的备份。\n\n\nOffset\n偏移\n分区中的每一条消息都有一个所在分区的偏移量，这个偏移量唯一标识了该消息在当前这个分区的位置，并保证了在这个分区的顺序性，不过不保证跨分区的顺序性。\n\n\n简单来说，作为消息系统的kafka本质上还是一个数据系统。既然是一个数据系统，那么就要解决两个根本问题：\n\n当我们把数据交给kafka的时候，kafka怎么存储；\n\n当我们向kafka要回数据的时候，kafka怎么返回。\n\n\n\n目前大多数数据系统将数据存储在磁盘的格式有追加日志型以及B+树型。而kafka采用了追加日志的格式将数据存储在磁盘上，整体的结构如下图：\n\n追加日志的格式可以带来写性能的提升（毕竟只需要往日志文件后面追加就可以了），但是同时对读的支持不是很友好。为了提升读性能，kafka需要额外的操作。\n关于kafka的数据是如何存储的是一个比较大的问题，这里先从逻辑层面开始。\nTopic+Partition的两层结构\nOffset\n\n\n\n\n\n\n\n\n\n发送方式\n消息的发送有三种方式：\n\n发后即忘（fire and forget）：只管发送不管结果，性能最高，可靠性也最差；\n\n同步（sync）：等集群确认消息写入成功再返回，可靠性最高，性能差很多；\n\n异步（async）：指定一个callback，kafka返回响应后调用来实现异步发送的确认。\n\n\n其中前两个是同步发送，后一个是异步发送。不过这里的异步发送没有提供callback的能力。\n那么生产者发送消息之后kafka怎么才算确认呢？这涉及到acks参数：\n\nacks &#x3D; 1, 默认值1，表示只要分区的leader副本成功写入就算成功；\n\nacks&#x3D;0，生产者不需要等待任何服务端的响应，可能会丢失数据；\n\nacks&#x3D;-1或acks&#x3D;all，需要全部处于同步状态的副本确认写入成功，可靠性最强，性能也差。\n\n\n参考\n","slug":"04_MQ/Kafka","date":"2019-03-20T07:05:07.000Z","categories_index":"MQ","tags_index":"Kafka","author_index":"Michael"},{"id":"c07280ed37e56a831a850ef11c3453d2","title":"MQ面试经","content":"为什么使用消息队列？消息队列的优点和缺点？kafka、activemq、rabbitmq、rocketmq都有什么优缺点？\n面试官角度分析：\n（1）你知不知道你们系统里为什么要用消息队列这个东西？\n（2）既然用了消息队列这个东西，你知不知道用了有什么好处？\n（3）既然你用了MQ，那么当时为什么选用这一款MQ？\n1. 为什么使用消息队列？面试官问这个问题的期望之一的回答是，你们公司有什么业务场景，这个业务场景有什么技术挑战，如果不用MQ可能会很麻烦，但是再用了之后带来了很多好处。\n消息队列的常见使用场景有很多但是核心的有三个：解耦、异步、削峰\n解耦场景描述：A系统发送个数据到BCD三个系统，接口调用发送，那如果E系统也要这个数据呢？那如果C系统现在不需要了呢？现在A系统又要发送第二种数据了呢？A系统负责人崩溃中…再来点崩溃的事儿，A系统要时时刻刻考虑BCDE四个系统如果挂了怎么办？那我要不要重发？我要不要把消息存起来？头发都白了啊…\n\n使用了MQ之后的解耦场景\n\n面试技巧：你需要考虑下，你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，相互之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果MQ给他异步化解耦也是可以的，你就需要去考虑在你的项目里是不是可以运用这个MQ去进行系统解耦 。\n异步场景描述：系统A接受一个请求，需要在自己本地写库，还需要在系统BCD三个系统写库，自己本地写库需要3ms。BCD分别需要300ms、450ms、200ms。最终总好时长：953ms，接近1s。给用户的体验感觉一点也不好。\n不用MQ的同步高延时请求场景\n\n使用MQ异步化之后的接口性能优化\n\n削峰场景描述：每天 0 点到 11 点，系统A风平浪静，每秒并发请求数量就 100 个。结果每一一到11点到1点，每秒并发请求数量就会暴增大1万条 。但是系统最大的处理能力就只能每秒钟处理1000个请求。\n没有用MQ的时候高峰期系统被打死的场景\n\n使用MQ来进行削峰的场景\n\n2. 消息队列的有点和缺点？优点：特殊场景下解耦、异步、削峰。\n缺点：\n系统可用性降低：系统引入的外部依赖越多，越容易挂掉，本来你就是A系统调用BCD三个系统的接口就好了，人ABCD四个系统好好的没什么问题，你偏加个MQ进来，万一MQ挂了怎么办，整套系统崩溃了，就完蛋了\n系统复杂性提高：硬生生加个MQ进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？\n一致性问题：系统A处理完了直接返回成功了，人家都认为你这个请求成功了；但问题是，要是BCD三个系统哪里BD系统成功了，结果C系统写库失败了，咋整？数据就不一致了，\n\n所以消息队列是一种非常复杂的架构，引入它有很多好处，但是也得针对他带来的坏处做各种额外的技术方案和架构来规避掉。做好之后你会发现系统复杂度提升了一个数量积，但是关键时刻，用，还是要用的。\n3. kafka、activemq、rabbitmq、rocketmq都有什么优缺点？\n\n\n特性\nActiveMQ\nRabbitMQ\nRocketMQ\nKafka\n\n\n\n单机吞吐量\n万级，吞吐量比RocketMQ和Kafka要低了一个数量级\n万级，吞吐量比RocketMQ和Kafka要低了一个数量级\n10万级，RocketMQ也是可以支撑高吞吐的一种MQ\n10万级别，这是kafka最大的优点，就是吞吐量高。 一般配合大数据类的系统来进行实时数据计算、日志采集等场景\n\n\ntopic数量对吞吐量的影响\n\n\ntopic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降 这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic\ntopic从几十个到几百个的时候，吞吐量会大幅度下降 所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源\n\n\n时效性\nms级\n微秒级，这是rabbitmq的一大特点，延迟是最低的\nms级\n延迟在ms级以内\n\n\n可用性\n高，基于主从架构实现高可用性\n高，基于主从架构实现高可用性\n非常高，分布式架构\n非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n\n\n消息可靠性\n有较低的概率丢失数据\n\n经过参数优化配置，可以做到0丢失\n经过参数优化配置，消息可以做到0丢失\n\n\n功能支持\nMQ领域的功能极其完备\n基于erlang开发，所以并发能力很强，性能极其好，延时很低\nMQ功能较为完善，还是分布式的，扩展性好\n功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准\n\n\n优劣势总结\n非常成熟，功能强大，在业内大量的公司以及项目中都有应用 偶尔会有较低概率丢失消息 而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本 而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用\nerlang语言开发，性能极其好，延时很低； 吞吐量到万级，MQ功能比较完备 而且开源提供的管理界面非常棒，用起来很好用 社区相对比较活跃，几乎每个月都发布几个版本分 在国内一些互联网公司近几年用rabbitmq也比较多一些 但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。 而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。\n接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障 日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景 而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码 还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的\nkafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 这个特性天然适合大数据实时计算以及日志收集\n\n\n1. 引入消息队列之后如何保证其高可用性?（1）RabbitMQ的高可用性RabbitMQ是比较有代表性的，因为是基于主从做高可用性的，我们就以他为例子讲解第一种MQ的高可用性怎么实现。\nrabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式\n（1.1） 单机模式\n就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式\n（1.2）普通集群模式\n意思就是在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据。完了你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。\n这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。\n而且如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。\n所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作。\n\n（1.3）镜像集群模式\n这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。\n这样的话，好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue\n那么怎么开启这个镜像集群模式呢？我这里简单说一下，避免面试人家问你你不知道，其实很简单rabbitmq有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。\n\n（2）kafka的高可用性kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。\n这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。\n实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已，因为无论怎么玩儿，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。\nkafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。\nkafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到吉他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。\n这么搞，就有所谓的高可用性了，因为如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。\n写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）\n消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。\n实际上这块机制，讲深了，是可以非常之深入的，但是我还是回到我们这个课程的主题和定位，聚焦面试，至少你听到这里大致明白了kafka是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要遇上面试官确实是kafka高手，深挖了问，那你只能说不好意思，太深入的你没研究过。\n但是大家一定要明白，这个事情是要权衡的，你现在是要快速突击常见面试题体系，而不是要深入学习kafka，要深入学习kafka，你是没那么多时间的。你只能确保，你之前也许压根儿不知道这块，但是现在你知道了，面试被问到，你大概可以说一说。然后很多其他的候选人，也许还不如你，没看过这个，被问到了压根儿答不出来，相比之下，你还能说点出来，大概就是这个意思了。\n\n2. 如何保证消息不被重复消费（如何保证消息消费时的幂等性）？其实这个很常见的一个问题，这俩问题基本可以连起来问。既然是消费消息，那肯定要考虑考虑会不会重复消费？能不能避免重复消费？或者重复消费了也别造成系统异常可以吗？这个是MQ领域的基本问题，其实本质上还是问你使用消息队列如何保证幂等性，这个是你架构里要考虑的一个问题。\n首先就是比如rabbitmq、rocketmq、kafka，都有可能会出现消费重复消费的问题，正常。因为这问题通常不是mq自己保证的，是给你保证的。然后我们挑一个kafka来举个例子，说说怎么重复消费吧。\nkafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。\n但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了。重启之后，少数消息会再次消费一次。\n其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。\n给你举个例子吧。假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下已经消费过了，直接扔了，不就保留了一条数据？\n一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性\n幂等性，我通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。\n那所以第二个问题来了，怎么保证消息队列消费的幂等性？\n其实还是得结合业务来思考，我这里给几个思路：\n（1）比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧\n（2）比如你是写redis，那没问题了，反正每次都是set，天然幂等性\n（3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。\n还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据\n如何保证MQ的消费是幂等性的，需要结合具体的业务来看\n\n如何保证消息的幂等性\n\n3. 如何保证消息的可靠传输（如何处理消息丢失的问题）？这个是肯定的，用mq有个基本原则，就是数据不能多一条，也不能少一条，不能多，就是刚才说的重复消费和幂等性问题。不能少，就是说这数据别搞丢了。那这个问题你必须得考虑一下。\n如果说你这个是用mq来传递非常核心的消息，比如说计费，扣费的一些消息，因为我以前设计和研发过一个公司非常核心的广告平台，计费系统，计费系统是很重的一个业务，操作是很耗时的。所以说广告系统整体的架构里面，实际上是将计费做成异步化的，然后中间就是加了一个MQ。\n我们当时为了确保说这个MQ传递过程中绝对不会把计费消息给弄丢，花了很多的精力。广告主投放了一个广告，明明说好了，用户点击一次扣费1块钱。结果要是用户动不动点击了一次，扣费的时候搞的消息丢了，我们公司就会不断的少几块钱，几块钱，积少成多，这个就对公司是一个很大的损失。\n面试题剖析\n这个丢数据，mq一般分为两种，要么是mq自己弄丢了，要么是我们消费的时候弄丢了。咱们从rabbitmq和kafka分别来分析一下\nrabbitmq这种mq，一般来说都是承载公司的核心业务的，数据是绝对不能弄丢的\nRabbitMQ可能存在的数据丢失问题。\n（1）rabbitmq1）生产者弄丢了数据\n生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。\n此时可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。\n所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。\n事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。\n所以一般在生产者这块避免数据丢失，都是用confirm机制的。\n2）rabbitmq弄丢了数据\n就是rabbitmq自己弄丢了数据，这个你必须开启rabbitmq的持久化，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。\n设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。\n而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。\n哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。\n3）消费端弄丢了数据\nrabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。\n这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。\n\n（2）kafka1）消费端弄丢了数据\n唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。\n这不是一样么，大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。\n生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。\n然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了\n2）kafka弄丢了数据\n这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。\n\n生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了\n所以此时一般是要求起码设置如下4个参数：\n\n给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本\n在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧\n在producer端设置acks&#x3D;all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了\n在producer端设置retries&#x3D;MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了\n\n我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失\n3）生产者会不会弄丢数据\n如果按照上述的思路设置了ack&#x3D;all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。\n1. 如何保证消息的顺序性？其实这个也是用MQ的时候必问的话题，第一看看你了解不了解顺序这个事儿？第二看看你有没有办法保证消息是有顺序的？这个生产系统中常见的问题。\n我举个例子，我们以前做过一个mysql binlog同步的系统，压力还是非常大的，日同步数据要达到上亿。mysql -&gt; mysql，常见的一点在于说大数据team，就需要同步一个mysql库过来，对公司的业务系统的数据做各种复杂的操作。\n你在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。\n本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。\n先看看顺序会错乱的俩场景\n（1）rabbitmq：一个queue，多个consumer，这不明显乱了\n\n（2）kafka：一个topic，一个partition，一个consumer，内部多线程，这不也明显乱了\n\n那如何保证消息的顺序性呢？简单简单（1）rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；\n\n或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理\n（2）kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可\n\n如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？\n你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了，或者消费的极其极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如rabbitmq设置了消息过期时间后就没了怎么办？\n所以就这事儿，其实线上挺常见的，一般不出，一出就是大case，一般常见于，举个例子，消费端每次消费之后要写mysql，结果mysql挂了，消费端hang那儿了，不动了。或者是消费端出了个什么叉子，导致消费速度极其慢。\n关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在mq里积压，现在事故了，慌了\n（1）大量消息在mq里积压了几个小时了还没解决几千万条数据在MQ里积压了七八个小时，从下午4点多，积压到了晚上很晚，10点多，11点多\n这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复consumer的问题，让他恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。\n一个消费者一秒是1000条，一秒3个消费者是3000条，一分钟是18万条，1000多万条\n所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来\n一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：\n1）先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉\n2）新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量\n3）然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue\n4）接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据\n5）这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据\n6）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息\n\n（2）这里我们假设再来第二个坑假设你用的是rabbitmq，rabbitmq是可以设置过期时间的，就是TTL，如果消息在queue中积压超过一定的时间就会被rabbitmq给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在mq里，而是大量的数据会直接搞丢。\n这个情况下，就不是说要增加consumer消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是批量重导，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。\n这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把白天丢的数据给他补回来。也只能是这样了。\n假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次\n（3）然后我们再来假设第三个坑如果走的方式是消息积压在mq里，那么如果你很长时间都没处理掉，此时导致mq都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。\n1. 如果让你写一个消息队列，该如何进行架构设计啊？说一下你的思路\n其实聊到这个问题，一般面试官要考察两块：\n（1）你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个mq的架构原理\n（2）看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来\n其实回答这类问题，说白了，起码不求你看过那技术的源码，起码你大概知道那个技术的基本原理，核心组成部分，基本架构构成，然后参照一些开源的技术把一个系统设计出来的思路说一下就好\n比如说这个消息队列系统，我们来从以下几个角度来考虑一下\n说实话，我一般面类似问题的时候，大部分人基本都会蒙，因为平时从来没有思考过类似的问题，大多数人就是平时埋头用，从来不去思考背后的一些东西。类似的问题，我经常问的还有，如果让你来设计一个spring框架你会怎么做？如果让你来设计一个dubbo框架你会怎么做？如果让你来设计一个mybatis框架你会怎么做？\n其实回答这类问题，说白了，起码不求你看过那技术的源码，起码你大概知道那个技术的基本原理，核心组成部分，基本架构构成，然后参照一些开源的技术把一个系统设计出来的思路说一下就好\n比如说这个消息队列系统，我们来从以下几个角度来考虑一下\n（1）首先这个mq得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下kafka的设计理念，broker -&gt; topic -&gt; partition，每个partition放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给topic增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？\n（2）其次你得考虑一下这个mq的数据要不要落地磁盘吧？那肯定要了，落磁盘，才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路。\n2.其次你考虑一下你的mq的可用性啊？\n这个事儿，具体参考我们之前可用性那个环节讲解的kafka的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker挂了重新选举leader即可对外服务。\n（4）能不能支持数据0丢失啊？可以的，参考我们之前说的那个kafka数据零丢失方案其实一个mq肯定是很复杂的，面试官问你这个问题，其实是个开放题，他就是看看你有没有从架构角度整体构思和设计的思维以及能力。确实这个问题可以刷掉一大批人，因为大部分人平时不思考这些东西。\n","slug":"04_MQ/MQ","date":"2019-03-20T07:05:07.000Z","categories_index":"MQ","tags_index":"MQ","author_index":"Michael"},{"id":"f8ef4e10e9f952ff4ed3590ecc45cea3","title":"MQ","content":"转自\n\n\n\n特性\nActiveMQ\nRabbitMQ\nRocketMQ\nKafka\n\n\n\n单机吞吐量\n万级，比 RocketMQ、Kafka 低一个数量级\n同 ActiveMQ\n10 万级，支撑高吞吐\n10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景\n\n\ntopic 数量对吞吐量的影响\n\n\ntopic 可以达到几百&#x2F;几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic\ntopic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源\n\n\n时效性\nms 级\n微秒级，这是 RabbitMQ 的一大特点，延迟最低\nms 级\n延迟在 ms 级以内\n\n\n可用性\n高，基于主从架构实现高可用\n同 ActiveMQ\n非常高，分布式架构\n非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用\n\n\n消息可靠性\n有较低的概率丢失数据\n基本不丢\n经过参数优化配置，可以做到 0 丢失\n同 RocketMQ\n\n\n功能支持\nMQ 领域的功能极其完备\n基于 erlang 开发，并发能力很强，性能极好，延时很低\nMQ 功能较为完善，还是分布式的，扩展性好\n功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用\n\n\n综上，各种对比之后，有如下建议：\n一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了。\n后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高。\n不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高），推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。\n所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。\n如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。\nMQ - message queue 消息队列\n核心：解耦、异步、削峰\n缺点：\n​\t\t\t系统可用性降低\n​\t\t\t系统复杂性提高\n​\t\t\t数据一致性问题\n","slug":"04_MQ/众多MQ区别","date":"2019-03-20T07:05:07.000Z","categories_index":"MQ","tags_index":"message,queue","author_index":"Michael"},{"id":"85c12a31d0c9184040aa4bab328e79c5","title":"Opcache","content":"Opcache - 扩展\n","slug":"05_PHP/Opcache","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP,扩展","author_index":"Michael"},{"id":"8ad7c02366ba3448c825d7359d268365","title":"PHP5与PHP7","content":"\n改进的性能 - 将 PHPNG 代码合并到 PHP7 中，速度是 PHP 5 的两倍。\n降低内存消耗 - 优化的 PHP 7 使用较少的资源。\n标量类型声明 - 现在可以强制执行参数和返回类型。\n一致的 64 位支持 - 对 64 位体系结构机器的一致支持。\n改进了异常层次 - 异常层次得到了改进\n许多致命的错误转换为例外 - 例外范围增加，涵盖许多致命的错误转换为例外。\n安全随机数发生器 - 增加新的安全随机数发生器 API。\n已弃用的 SAPI 和扩展已删除 - 各种旧的和不受支持的 SAPI 和扩展从最新版本中删除。\n空合并运算符（？） - 添加了新的空合并运算符。\n返回和标量类型声明 - 支持所添加的返回类型和参数类型。\n匿名类 - 支持匿名添加。\n零成本断言 - 支持零成本断言增加。\n\n","slug":"05_PHP/PHP5与PHP7","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"38f689e6465d7c7efe9e7da9f157dd4e","title":"后期静态变量绑定","content":"","slug":"05_PHP/后期静态绑定","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"6b6fc9dba74c7910bcbe51ca5306e95c","title":"GC - 垃圾回收机制","content":"GC 垃圾回收机制\n自动进行内存管理，清除不需要的对象，使用了引用计数GC机制。\n​\t每个对象都内含一个引用计数器，连接到对象，计数器+1；\n​\t当离开生存扣减或者设置为NULL时，计数器-1；\n当引用计数器为零时，PHP将释放其所占的内存空间。\n","slug":"05_PHP/垃圾回收机制","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"a362973c4b5c327fa654d2d9e8bdc0a8","title":"PHP安全","content":"永远不要相信用户传递的任何数据\n\n\n\n安全问题\n释义\n防范\n\n\n\nSQL注入\n\n\n\n\nXSS跨站脚本攻击\n\n\n\n\nXSRF跨站请求伪造攻击\n\n\n\n\n不充分的密码哈希\n\n\n\n\n生产中打印错误日志\n\n\n\n\n登录未限制\n\n\n\n\n中间人攻击\n\n\n\n\n命令注入\n\n\n\n\nLFI\n\n\n\n\nXXE\n\n\n\n\n","slug":"05_PHP/安全问题","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP,安全","author_index":"Michael"},{"id":"75fb5b6b2923996a93e804973515b8ea","title":"PHP的工作原理","content":"\n\n\n\n\n\n\n\n\n概述\nCGI，通用网关接口，\n用于WEB服务器和应用程序间的交互，定义输入输出规范，\n用户的请求通过WEB服务器转发给FastCGI进程，\nFastCGI进程再调用应用程序进行处理，如php解析器，应用程序的处理结果如html返回给FastCGI，FastCGI返回给Nginx 进行输出。\n假设这里WEB服务器是Nginx，应用程序是 PHP，而 php-fpm 是管理 FastCGI 的，这也就是 php-fpm，FastCGI，和 Nginx 之间的关系。\nFastCGI 用来提高 cgi 程序性能，启动一个master，再启动多个 worker，不需要每次解析 php.ini. \n而 php-fpm 实现了 FastCGI 协议，是 FastCGI 的进程管理器，支持平滑重启，可以启动的时候预先生成多个进程。\n\n\n\n\n\n\n\n\n\n协议模式\n\n\n\n协议模式\n定义\n用途\n备注\n\n\n\nCGI\n通用网关接口(Common Gateway Interface)\n用于WEB服务器和应用程序间的交互，定义输入输出规范\n用户的请求通过WEB服务器转发给Fast-CGI进程\n\n\nFast-CGI\nCGI模式的升级版\n用来提高 CGI 程序性能\n启动一个master，再启动多个 worker，不需要每次解析 php.ini\n\n\nPHP-Cli\n命令行模式\n-\n在控制台输入php xx.php 就能执行php代码\n\n\nPHP-FPM\n-\nFast-CGI 的进程管理器\n实现了 Fast-CGI 协议，支持平滑重启，可以启动的时候预先生成多个进程\n\n\nPHP\n-\n应用程序\n-\n\n\nNGINX\n-\nWEB服务器\n-\n\n\n\n\n\n\n\n\n\n\n\nFast-CGI的工作原理\nweb服务器fast-cgi进程管理器初始化-&gt;预先fork n个进程\n用户请求-&gt;web服务器接收请求-&gt;交给fast-cgi进程管理器-&gt;fast-cgi进程管理区接收,给其中一个空闲fast-cgi进程处理-&gt;处理完成，fast-cgi进程变为空闲状态，等待下次请求-&gt;web服务器接收内容-&gt;返回给用户。\n\n\n\n\n\n\n\n\n\nPHP-FPM的工作原理\nphp-fpm启动-&gt;生成n个fast-cgi协议处理进程-&gt;监听一个端口等待任务\n用户请求-&gt;web服务器接收请求-&gt;请求转发给php-fpm-&gt;php-fpm交给一个空闲进程处理-&gt;进程处理完成-&gt;php-fpm返回给web服务器-&gt;web服务器接收数据-&gt;返回给用户。\n","slug":"05_PHP/工作原理","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"工作原理","author_index":"Michael"},{"id":"ea77f838dd6d93ac5db4dfbbc8b08c5b","title":"GET 与 POST的区别","content":"\n\n\n比较\nGET\nPOST\n\n\n\n浏览器回退时\n无害\n会再次提交请求\n\n\nBookMark\nURL地址可以被BookMark\n不可以\n\n\n编码\n仅支持URL编码\n多种编码方式\n\n\n缓存\n会被浏览器主动缓存\n不会缓存，除非手动设置\n\n\n历史记录\n参数会被完整的保留在浏览器历史记录\n参数不会被保留\n\n\n限制\n根据各浏览器会被限制长度\n没有\n\n\n数据类型\n仅支持ASCII字符\n没有限制\n\n\n安全性\n低，暴露在URL上\n相对较高\n\n\n传递方式\n拼接在URL上\n放在Request Body中\n\n\nTCP数据包\n1个\n2个\n\n\n","slug":"05_PHP/比较区别_GET与POST","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"GET,POST","author_index":"Michael"},{"id":"081b1de5c3dce21d56d55b065140f305","title":"require与include的区别","content":"\n\n\n比较\nrequire\nrequire_once\ninclude\ninclude_once\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"05_PHP/比较区别_require与include","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"require,include","author_index":"Michael"},{"id":"6a4ee9e946a721c90eb7aa9e5d737354","title":"进程、线程和协程","content":"\n进程是资源分配的单位；\n线程是CPU调度的单位；\n协程是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）\n\n线程与进程的区别:\n\n地址空间:线程是进程内的一个执行单元，进程内至少有一个线程，它们共享进程的地址空间，而进程有自己独立的地址空间\n资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源\n线程是处理器调度的基本单位,但进程不是\n二者均可并发执行\n每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口，但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制\n\n协程与线程的区别:\n\n一个线程可以多个协程，一个进程也可以单独拥有多个协程。\n线程进程都是同步机制，而协程则是异步。\n协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态。\n线程是抢占式，而协程是非抢占式的，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。\n协程并不是取代线程, 而且抽象于线程之上, 线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行, 线程是协程的资源, 但协程不会直接使用线程, 协程直接利用的是执行器(Interceptor), 执行器可以关联任意线程或线程池, 可以使当前线程, UI线程, 或新建新程.。\n线程是协程的资源。协程通过Interceptor来间接使用线程这个资源。\n\n一个进程  可以  拥有多个协程\n一个线程  可以  拥有多个协程\n进程和线程 是同步机制、协程是异步机制；\n线程是抢占式\n进程\t\t\t\t\t\t一个人干一件事\t\t\t\t\t\t\t\t\t\t\t 管理者\n线程池\t\t\t\t  一个人带着一帮小弟   干多件事\t\t\t执行者\n协程上下文\t\t一个人带着一帮小弟   干一件事\t\t\t\n\n\n\n\n进程\n线程\n协程\n\n\n\n概念\n资源分配的单位\nCPU调度的单位\n一种比线程更加轻量级的存在，不被操作系统内核所管理，完全是由程序所控制（也就是在用户态执行）\n\n\n地址空间\n\n\n\n\n\n资源拥有\n\n\n\n\n\n机制\n同步\n同步\n异步\n\n\n\n\n\n\n\n\n","slug":"05_PHP/比较区别_协程与进程、线程","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"进程,线程,协程","author_index":"Michael"},{"id":"b760d8b0139b4afd182432843b5ddcf1","title":"PHP内置系统函数","content":"\n\n\n系统函数\n意义\n备注\n\n\n\nfunction_exists\n系统或自定义函数  是否存在\n\n\n\nclass_exists\n类是否存在\n\n\n\nmethod_exists\n类方法是否定义\n\n\n\nproperty_exists\n类属性是否定义\n\n\n\nempty\n类、变量、元素等是否为空\n\n\n\n","slug":"05_PHP/系统函数","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"e056c643723f9ba21fb813a935518ef7","title":"PHP自动加载类机制","content":"\n\n\n\n\n\n\n\n\n自动加载\n在 PHP 开发过程中，如果希望从外部引入一个 class，通常会使用 include 和 require 方法，去把定义这个 class 的文件包含进来；\nPHP5 提供了一个类的自动装载 (autoload) 机制。\nautoload 机制可以使得 PHP 程序有可能在使用类时才自动包含类文件，\n而不是一开始就将所有的类文件 include 进来，这种机制也称为 lazy loading。\nfunction __autoload($className) &#123;\n  echo &#39;__autload class:&#39;, $className, &#39;&lt;br &#x2F;&gt;&#39;;\n&#125;\n\n\n\n\n\nfunction __autoload($className) &#123;\n  require_once($className . &quot;class.php&quot;); \n&#125;\n\n\n\nautoload 至少要做三件事情：\n\n根据类名确定类文件名；\n\n确定类文件所在的磁盘路径\n 在我们的例子是最简单的情况，类与调用它们的 PHP 程序文件在同一个文件夹下；\n\n将类从磁盘文件中加载到系统中。\n\n\n优点：\n\n使用类之前无需 include 或者 require。\n使用类的时候才会 require&#x2F;include 文件，实现了 lazy loading，避免了 require&#x2F;include 多余文件。\n无需考虑引入类的实际磁盘地址，实现了逻辑和实体文件的分离。\n\nSPL Autoload 具体有几个函数：\nspl_autoload_register：注册 _autoload () 函数\nspl_autoload_unregister：注销已注册的函数\nspl_autoload_functions：返回所有已注册的函数\nspl_autoload_call：尝试所有已注册的函数来加载类\nspl_autoload ：_autoload () 的默认实现\nspl_autoload_extionsions： 注册并返回 spl_autoload 函数使用的默认文件扩展名。\n","slug":"05_PHP/自动加载","date":"2019-03-20T07:05:07.000Z","categories_index":"PHP","tags_index":"PHP","author_index":"Michael"},{"id":"e80867b83c958ad66c16e6a82d1e8c29","title":"查找重复字符","content":"给出一个字符串，返回里面连续字母的个数，比如：abbcddde,返回 1a2b1c3de;\nfunction str($str)\n&#123;\n  $res &#x3D; &#39;&#39;;\n  $arr &#x3D; str_split($str);&#x2F;&#x2F;把字符串变成数组\n  $len &#x3D; count($arr);\n  $key &#x3D; 0; &#x2F;&#x2F; key 用来记录下标，为了方便计算前面的数字\n  for ($i &#x3D; 0; $i &lt; $len; $i++) &#123;\n    $nk &#x3D; $i + 1;\n    $v  &#x3D; $arr[$i];\n    &#x2F;&#x2F; 俩值不相同时\n    if ($arr[$i] !&#x3D; $arr[$nk]) &#123;\n      &#x2F;&#x2F; 重复次数\n      $num &#x3D; $nk - $key;\n      $res .&#x3D; $num . $v; &#x2F;&#x2F; 不相等时计算出前面的数字\n      $key  &#x3D; $nk; &#x2F;&#x2F; 同时 key 下标重新赋值\n    &#125;\n  &#125;\n\n  return $res;\n&#125;\n\n\n\n","slug":"07_LeetCode/查重","date":"2019-03-20T07:05:07.000Z","categories_index":"LeetCode","tags_index":"查重","author_index":"Michael"},{"id":"144f0b4d9b9f80ea377106e9c6a54a45","title":"Linux基础","content":"参考\n\n\n\n命令\n释义\n\n\n\nshutdown -h now\n关机\n\n\nshutdown -r now\n重启\n\n\nuname -a\n查看系统内核信息\n\n\ncat &#x2F;proc&#x2F;version\n查看系统内核版本\n\n\nenv\n查看当前用户的环境变量\n\n\ncat &#x2F;proc&#x2F;cpuinfo\n查看系统内存信息\n\n\ncat &#x2F;proc&#x2F;cpuinfo | grep name | cut -f2 -d: | uniq -c\n查看有几个逻辑CPU及型号\n\n\ncat &#x2F;proc&#x2F;cpuinfo | grep physical | uniq -c\n查看有几颗CPU，每颗分别是几核\n\n\ngetconf LONG_BIT\n查看当前CPU运行在32bit\n\n\ncat &#x2F;proc&#x2F;cpuinfo | grep flags | grep ‘ lm ’ | wc -l\n结果大于0，说明支持64bit\n\n\nln -s &#x2F;usr&#x2F;local&#x2F;jdk1.8 jdk\n建立软连接\n\n\nrpm -qa | grep 软件名\n查看是否通过rpm安装了该软件\n\n\nssh-keygen -t rsa -C &#x79;&#x6f;&#x75;&#x72;&#95;&#x65;&#x6d;&#97;&#x69;&#108;&#x40;&#x65;&#120;&#x61;&#109;&#x70;&#x6c;&#101;&#46;&#99;&#x6f;&#109;\n创建sshkey\n\n\nalias ll&#x3D;’ls -alF’\n在各个用户的.bash_profile中添加重命名配置\n\n\nsudo ntpdate -u ntp.api.bz\n同步服务器时间\n\n\nnohup xxx &amp;\n后台运行,并且有nohup.out输出\n\n\nnohup xxx &gt; &#x2F;dev&#x2F;null &amp;\n后台运行, 不输出任何日志\n\n\nnohup xxx &gt;out.log 2&gt;&amp;1 &amp;\n后台运行, 并将错误信息做标准输出到日志中\n\n\npkill -kill -t [TTY]\n命令来完成强制活动用户退出.其中TTY表示终端名称\n\n\nwhich &lt;命令&gt;\n查看命令路径\n\n\nulimit -n\n查看进程所有打开最大fd数\n\n\nvim &#x2F;etc&#x2F;resolv.conf\n配置dns\n\n\nnslookup google.com\n查看域名路由表\n\n\nlast -n 5\n最近登录信息列表\n\n\nifconfig em1 192.168.5.177 netmask 255.255.255.0\n设置固定ip\n\n\nps eww -p XXXXX(进程号)\n查看进程内加载的环境变量\n\n\nps auwxf\n查看进程树找到服务器进程\n\n\ncd &#x2F;proc&#x2F;xxx(进程号)\n查看进程启动路径\n\n\nuseradd 用户名 &amp;&amp; passwd 用户名\n添加用户\n\n\nvim &#x2F;etc&#x2F;sudoers\n配置sudo权限\n\n\nps aux | grep xxx | grep -v grep | awk ‘{print $2}’ | xargs kill -9\n强制关闭进程名包含xxx的所有进程\n\n\n:%s&#x2F;x&#x2F;y&#x2F;g\nnormal模式下 g表示全局, x表示查找的内容, y表示替换后的内容\n\n\nmount\n查看磁盘挂载情况\n\n\ndf\n查看磁盘分区信息\n\n\ndu -H -h\n查看目录及子目录大小\n\n\ndu -sh *\n查看当前目录下各个文件, 文件夹占了多少空间, 不会递归\n\n\nwc -l filename\n查看文件里有多少行\n\n\nwc -w filename\n看文件里有多少个word\n\n\nwc -L filename\n文件里最长的那一行是多少个字\n\n\nwc -c\n统计字节数\n\n\ntar czvf xxx.tar\n压缩目录\n\n\nzip -r xxx.zip\n压缩目录\n\n\ntar zxvf xxx.tar\n\n\n\ntar zxvf xxx.tar -C &#x2F;xxx&#x2F;yyy&#x2F;\n解压到指定文件夹\n\n\nunzip xxx.zip\n\n\n\nchown eagleye.eagleye xxx.log\n变更文件所属用户, 用户组\n\n\ncp xxx.log\n复制\n\n\ncp -f xxx.log\n复制并强制覆盖同名文件\n\n\ncp -r xxx(源文件夹) yyy(目标文件夹)\n复制文件夹\n\n\nscp -P ssh端口 &#x75;&#115;&#101;&#114;&#x6e;&#97;&#x6d;&#x65;&#x40;&#x31;&#x30;&#46;&#x31;&#x30;&#46;&#x31;&#x30;&#x2e;&#x31;&#x30;&#x31;:&#x2F;home&#x2F;username&#x2F;xxx &#x2F;home&#x2F;xxx\n远程复制\n\n\nmkdir -p &#x2F;xxx&#x2F;yyy&#x2F;zzz\n级联创建目录\n\n\nmkdir -p src&#x2F;{test,main}&#x2F;{java,resources}\n批量创建文件夹, 会在test,main下都创建java, resources文件夹\n\n\ndiff -u 1.txt 2.txt\n比较两个文件\n\n\ntail -f xxx.log | pv -bt\n如果做性能测试, 可以每执行一次, 往日志里面输出 “.” , 这样日志中的字节数就是实际的性能测试运行的次数, 还可以看见实时速率.\n\n\ncat -v xxx.sh\n查看特殊字符\n\n\nsed -i ‘s&#x2F;^M&#x2F;&#x2F;g’ env.sh 去除文件的特殊字符, 比如^M: 需要这样输入: ctrl+v+enter\n去除特殊字符\n\n\ncat file.sh &gt; file.sh_bak\n可以转换为该系统下的文件格式\n\n\ncat &gt; file1.sh\n先将file.sh中文件内容复制下来然后运行, 然后粘贴内容, 最后ctrl + d 保存退出\n\n\n:set fileencodings&#x3D;utf-8 ，然后 w （存盘）一下即可转化为 utf8 格式，:set fileformat&#x3D;unix\n在vim中通过如下设置文件编码和文件格式\n\n\nfind . -name “*.sh” | xargs dos2unix\n在mac下使用dos2unix进行文件格式化\n\n\nawk ‘{print $0}’ xxx.log | tee test.log\n重定向的同时输出到屏幕\n\n\ngrep -v xxx\n反向匹配, 查找不包含xxx的内容\n\n\ngrep -v ‘^&#x2F;pre&gt;\n排除所有空行\n\n\ngrep -n “^$” 111.txt\n返回结果 2,则说明第二行是空行\n\n\nawk -F ‘:’ ‘{if ($5 ~ &#x2F;user&#x2F;) print $0}’ &#x2F;etc&#x2F;passwd\n以’:’ 为分隔符,如果第五域有user则输出该行\n\n\nawk -v RS&#x3D;’character’ ‘END {print –NR}’ xxx.txt\n统计单个文件中某个字符（串）(中文无效)出现的次数\n\n\nfind &#x2F;home&#x2F;eagleye -name ‘*.mysql’ -print\n在目录下找后缀是.mysql的文件\n\n\nfind &#x2F;doc -name ‘*bak’ -exec rm {} ;\n会从 &#x2F;doc 目录开始往下找，找到凡是文件名结尾为 bak的文件，把它删除掉。-exec 选项是执行的意思，rm 是删除命令，{ } 表示文件名，“;”是规定的命令结尾\n\n\nlsof -i:port\n查看什么进程使用了该端口\n\n\n&#x2F;sbin&#x2F;ifconfig -a | grep inet | grep -v 127.0.0.1 | grep -v inet6 | awk ‘{print $2}’ | tr -d “addr:”\n获取本机ip地址\n\n\nservice iptables status\n查看iptables状态\n\n\niptables -I INPUT -s ***.***.***.***  -j DROP\n要封停一个ip\n\n\niptables -D INPUT -s ***.***.***.***  -j DROP\n要解封一个IP\n\n\n&#x2F;etc&#x2F;init.d&#x2F;iptables status | start | stop | restart\n防火墙查看状态、开启、关闭、重启\n\n\nnc 192.168.0.11 8000 &lt; data.txt\n给某一个endpoint发送TCP请求,就将data的内容发送到对端\n\n\ntcpdump -i em1 tcp port 12301 -s 1500 -w abc.pcap\ndump出本机12301端口的tcp包\n\n\ntraceroute -I www.163.com\ntraceroute默认使用udp方式, 如果是-I则改成icmp方式\n\n\nnetstat -n | awk ‘&#x2F;^tcp&#x2F; {n&#x3D;split($(NF-1),array,”:”);if(n&lt;&#x3D;2)++S[array[(1)]];else++S[array[(4)]];++s[$NF];++N} END {for(a in S){printf(“%-20s %s\\n”, a, S[a]);++I}printf(“%-20s %s\\n”,”TOTAL_IP”,I);for(a in s) printf(“%-20s %s\\n”,a, s[a]);printf(“%-20s %s\\n”,”TOTAL_LINK”,N);}’\n输出每个ip的连接数，以及总的各个状态的连接数\n\n\ntop\n监控linux性能命令\n\n\ndmesg\n查看系统日志\n\n\niostat -xz 1\n磁盘IO情况监控\n\n\nfree -m\n内存使用情况\n\n\n\n\n\n\n\n\n\n\n\ntop\n\n\n\n列名\n含义\n\n\n\nPID\n进程id\n\n\nPPID\n父进程id\n\n\nRUSER\nReal user name\n\n\nUID\n进程所有者的用户id\n\n\nUSER\n进程所有者的用户名\n\n\nGROUP\n进程所有者的组名\n\n\nTTY\n启动进程的终端名。不是从终端启动的进程则显示为 ?\n\n\nPR\n优先级\n\n\nNI\nnice值。负值表示高优先级，正值表示低优先级\n\n\nP\n最后使用的CPU，仅在多CPU环境下有意义\n\n\n%CPU\n上次更新到现在的CPU时间占用百分比\n\n\nTIME\n进程使用的CPU时间总计，单位秒\n\n\nTIME+\n进程使用的CPU时间总计，单位1&#x2F;100秒\n\n\n%MEM\n进程使用的物理内存百分比\n\n\nVIRT\n进程使用的虚拟内存总量，单位kb。VIRT&#x3D;SWAP+RES\n\n\nSWAP\n进程使用的虚拟内存中，被换出的大小，单位kb。\n\n\nRES\n进程使用的、未被换出的物理内存大小，单位kb。RES&#x3D;CODE+DATA\n\n\nCODE\n可执行代码占用的物理内存大小，单位kb\n\n\nDATA\n可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb\n\n\nSHR\n共享内存大小，单位kb\n\n\nnFLT\n页面错误次数\n\n\nnDRT\n最后一次写入到现在，被修改过的页面数。\n\n\nS\n进程状态。D&#x3D;不可中断的睡眠状态,R&#x3D;运行,S&#x3D;睡眠,T&#x3D;跟踪&#x2F;停止,Z&#x3D;僵尸进程\n\n\nCOMMAND\n命令名&#x2F;命令行\n\n\nWCHAN\n若该进程在睡眠，则显示睡眠中的系统函数名\n\n\nFlags\n任务标志，参考 sched.h\n\n\n","slug":"Linux/常用命令","date":"2019-03-20T07:05:07.000Z","categories_index":"Linux","tags_index":"Linux","author_index":"Michael"},{"id":"fab493d9c5b4a3034c764bb5ca7924c1","title":"索引失效的原因","content":"使用not in、not exists、!=、&lt;&gt;、or、函数、运算符、模糊搜索以及类型不一致等情况会导致索引失效；\n\n不满足 最左前缀原则\n范围索引列 没有放最后\n使用了select *\n索引列上有计算、函数运算\n字符类型没加引号，隐式转换\n使用is (no) null 没注意字段是否允许为空\nlike查询左边有%\n使用or关键字时没有注意\n\n","slug":"01_MySQL/索引/失效原因","date":"2019-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"8168bc864d1b3d3139b7796e97f98317","title":"索引下推","content":"MySQL 5.6引入了索引下推优化。默认开启，使用SET optimizer_switch &#x3D; ‘index_condition_pushdown&#x3D;off’;可以将其关闭。\n\n有了索引下推优化，可以在减少回表次数\n在InnoDB中只针对二级索引有效\n\n官方文档中给的例子和解释如下：\n在 people_table中有一个二级索引(zipcode，lastname，firstname)，查询是SELECT * FROM people WHERE zipcode&#x3D;’95054′ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’;\n\n如果没有使用索引下推技术，则MySQL会通过zipcode&#x3D;’95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断数据是否符合条件\n如果使用了索引下推技术，则MYSQL首先会返回符合zipcode&#x3D;’95054’的索引，然后根据lastname LIKE ‘%etrunia%’ and address LIKE ‘%Main Street%’来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。\n\nMysql5.6之前是没有索引下推这个功能，后面为了提高性能，避免不必要的回表5.6之后就有了索引下推优化的功能。\n假如我们有一个用户表，并且使用用户的name，age两个字段建立联合索引，name在没有索引下推的功能，执行下面的sql，执行的流程如下图所示：\nselect * from tuser where name like &#39;张%&#39; and age&#x3D;10 and ismale&#x3D;1;\n\n\n当比较第一个索引字段name like ‘张%’ 就会筛选出四行数据，后面它不会再比较age值是否符合要求，直接获取到主键值，然后在回表查询，回表后再对比age、ismale是否符合条件。\n从上面的数据看来其实name，age两个字段建立的联合索引，两个字段的值会存储在联合索引树中，可以直接对比age字段是否符合查询的条件age&#x3D;10，那么索引下推就是做了这些事：\n\n索引下推会再次根据你的age进行比较，发现有两条记录不符合条件直接过滤掉，符合条件的才会进行回表查询，这样就减少了不必要的回表查询。\n","slug":"01_MySQL/索引/索引下推","date":"2019-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"d84a5be77f321e677b0e0b0840c629ed","title":"导入&导出优选CSV格式的理由","content":"CSV，comma-separated values 逗号分隔值，通常被用于在使用纯文本的系统之间，交换表格类型的数据。\nCSV是一种基于行的文件格式。也就是说，此类文件中的每一行都对应到数据表中的具体某一行。通常，CSV文件里包含有一个标题行，该标题行提供了数据的列名。如果没有标题行的话，该文件将被视为已部分完成了结构化工作。\n单个CSV文件往往无法显示层次化的结构、或数据关系。而具体的数据连接关系往往需要通常多个CSV文件进行组织。各种外键(Foreign key)一般被存储在一个或多个文件的多个列中。不过这些文件之间的链接并非由其格式本身来表示。此外，由于并未完全标准化，因此在CSV格式文件中，您可以使用逗号以外的界定符，例如：制表符(tabs)或空格。\nCSV文件的另一个特性是：只有处于未压缩的原始文件状态、或是运用诸如bzip2或lzo之类的解压缩工具时，CSV文件才能够被拆分(注意：lzo需要进行索引之后，方可执行拆分)。\n\n\n\n\n\n\n\n\n\n优点：\n\nCSV易于人工阅读，也易于手动编辑。\n\nCSV提供了一种简单明了的信息模式(schema)。\n\n几乎所有现有的应用程序都能够处理CSV文件。\n\nCSV文件比较易于实现和解析。\n\n对于XML而言，您需要在每一行的每一列中分别添加开始与结束标签;而CSV比较简约，您只需一次性写入列标题即可。\n\n\n\n\n\n\n\n\n\n\n\n缺点：\n\n由于处置的是平面数据，因此需要事先对复杂的数据结构进行格式上的转换。\n由于不支持列的类型，因此在文本列和数字列之间并无区别。\n并无表示二进制数据的标准方法。\n由于NULL和引号之间并无区别，因此导入CSV时可能会出现问题。\n对于特殊字符的支持性较差。\n缺乏通用的标准。\n\n尽管存在着一定的局限性，但CSV文件仍然是数据共享领域的上乘之选。它经常被广泛地用于各类业务应用、消费者行业、以及科学分析程序中。当前，大多数批处理和流数据处理模块(如Spark和Hadoop)，都能够支持CSV文件的序列化与反序列化。它们在读取时提供了添加schema的方法。\n\n\n\n\n\n\n\n\n\n导入功能优选CSV格式的理由：\n\n标准开放，即行业内标准，且支持市面上主流软件的各种操作、解析等；\n\n性能效率远胜于其他格式，消耗内存更小；\n\n支持流式处理，解析简单，消耗性能最小；\n\n读写效率最快。\n\n\n\n\n\n\n\n\n\n\n\n导出功能优选CSV格式的理由：\n\n文件结构简单，与txt文本格式相差无几，且功能比txt文本强大；\n\n存储方式简单，减少存储数据的容量；\n\n支持流式处理，写入速度最快，占用内存极低，生成效率更高；\n\n服务器、浏览器等各终端处理起来非常迅速；\n\n轻松处理几百万行数据，理论上是不限量；\n\n支持Excel等格式互相转换；\n\n\nPS: Excel格式处理上限65536行，不支持流失处理，性能消耗大，内存占用较大，很容易导致内存溢出等情况\n","slug":"Other/csv","date":"2018-04-08T02:27:28.000Z","categories_index":"","tags_index":"csv,import,export","author_index":"Michael"},{"id":"b6123b50bf2c6e96c11f8d6bbfaa6c5c","title":"MySQL的三种日志","content":"redo log日志也叫做WAL技术（Write- Ahead Logging），他是一种先写日志，并更新内存，最后再更新磁盘的技术，为了就是减少sql执行期间的数据库io操作，并且更新磁盘往往是在Mysql比较闲的时候，这样就大大减轻了Mysql的压力。\nredo log是固定大小，是物理日志，属于InnoDB引擎的，并且写redo log是环状写日志的形式：\n\n如上图所示：若是四组的redo log文件，一组为1G的大小，那么四组就是4G的大小，其中write pos是记录当前的位置，有数据写入当前位置，那么write pos就会边写入边往后移。\ncheck point记录擦除的位置，因为redo log是固定大小，所以当redo log满的时候，也就是write pos追上check point的时候，需要清除redo log的部分数据，清除的数据会被持久化到磁盘中，然后将check point向前移动。\nredo log日志实现了即使在数据库出现异常宕机的时候，重启后之前的记录也不会丢失，这就是crash-safe能力。\nbinlog称为归档日志，是逻辑上的日志，它属于Mysql的Server层面的日志，记录着sql的原始逻辑，主要有两种模式：一个是statement格式记录的是原始的sql，而row格式则是记录行内容。\nredo log和binlog记录的形式、内容不同，这两者日志都能通过自己记录的内容恢复数据。\n之所以这两个日志同时存在，是因为刚开始Mysql自带的引擎MyISAM就没有crash-safe功能的，并且在此之前Mysql还没有InnoDB引擎，Mysql自带的binlog日志只是用来归档日志的，所以InnoDB引擎也就通过自己redo log日志来实现crash-safe功能。\nredolog 是重做日志，提供前滚操作，\nundolog是回滚日志，提供回滚操作。\nbinlog   是归档日志\n","slug":"01_MySQL/redo log 和 binlog","date":"2018-03-20T07:05:07.000Z","categories_index":"SQL","tags_index":"MySQL","author_index":"Michael"},{"id":"b85a5ed5aa29024c7191b1325f9b4bb8","title":"网络编程","content":"1.说下计算机网络体系结构计算机网络体系结构，一般有三种：OSI 七层模型、TCP&#x2F;IP 四层模型、五层结构。\n三种网络体系结构\n简单说，OSI是一个理论上的网络通信模型，TCP&#x2F;IP是实际上的网络通信模型，五层结构就是为了介绍网络原理而折中的网络通信模型。\n\n\n\n\n\n\n\n\n\nOSI 七层模型\nOSI 七层模型是国际标准化组织（International Organization for Standardization）制定的一个用于计算机或通信系统间互联的标准体系。\n\n应用层：通过应用进程之间的交互来完成特定网络应用，应用层协议定义的是应用进程间通信和交互的规则，常见的协议有：HTTP FTP  SMTP SNMP DNS.\n表示层：数据的表示、安全、压缩。确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。\n会话层：建立、管理、终止会话，是用户应用程序和网络之间的接口。\n运输层：提供源端与目的端之间提供可靠的透明数据传输，传输层协议为不同主机上运行的进程提供逻辑通信。\n网络层：将网络地址翻译成对应的物理地址，实现不同网络之间的路径选择, 协议有 ICMP IGMP IP 等.\n数据链路层：在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路。\n物理层：建立、维护、断开物理连接。\n\n\n\n\n\n\n\n\n\n\nTCP&#x2F;IP 四层模型\n\n应用层：对应于 OSI 参考模型的（应用层、表示层、会话层）。\n传输层: 对应 OSI 的传输层，为应用层实体提供端到端的通信功能，保证了数据包的顺序传送及数据的完整性。\n网际层：对应于 OSI 参考模型的网络层，主要解决主机到主机的通信问题。\n网络接口层：与 OSI 参考模型的数据链路层、物理层对应。\n\n\n\n\n\n\n\n\n\n\n五层体系结构\n\n应用层：对应于 OSI 参考模型的（应用层、表示层、会话层）。\n传输层：对应 OSI 参考模型的的传输层\n网络层：对应 OSI 参考模型的的网络层\n数据链路层：对应 OSI 参考模型的的数据链路层\n物理层：对应 OSI 参考模型的的物理层。\n\n2.说一下每一层对应的网络协议有哪些？一张表格总结常见网络协议：\n各层网络对应的网络协议\n3.那么数据在各层之间是怎么传输的呢？对于发送方而言，从上层到下层层层包装，对于接收方而言，从下层到上层，层层解开包装。\n\n发送方的应用进程向接收方的应用进程传送数据\nAP先将数据交给本主机的应用层，应用层加上本层的控制信息H5就变成了下一层的数据单元\n传输层收到这个数据单元后，加上本层的控制信息H4，再交给网络层，成为网络层的数据单元\n到了数据链路层，控制信息被分成两部分，分别加到本层数据单元的首部（H2）和尾部（T2）\n最后的物理层，进行比特流的传输\n\n数据在各层之间的传输\n这个过程类似写信，写一封信，每到一层，就加一个信封，写一些地址的信息。到了目的地之后，又一层层解封，传向下一个目的地。\n网络综合4.从浏览器地址栏输入 url 到显示主页的过程？这道题，大概的过程比较简单，但是有很多点可以细挖：DNS解析、TCP三次握手、HTTP报文格式、TCP四次挥手等等。\n\nDNS 解析：将域名解析成对应的 IP 地址。\nTCP连接：与服务器通过三次握手，建立 TCP 连接\n向服务器发送 HTTP 请求\n服务器处理请求，返回HTTp响应\n浏览器解析并渲染页面\n断开连接：TCP 四次挥手，连接结束\n\n我们以输入www.baidu.com 为例：\nwww.baidu.comliu到显示主页\n\n\n\n\n\n\n\n\n\n各个过程都使用了哪些协议？\nwww.baidu.comliu到显示主页过程使用的协议\n5.说说 DNS 的解析过程？DNS，英文全称是 domain name system，域名解析系统，它的作用也很明确，就是域名和 IP 相互映射。\nDNS 的解析过程如下图：\nDNS解析流程\n假设你要查询 www.baidu.com 的 IP 地址:\n\n首先会查找浏览器的缓存,看看是否能找到www.baidu.com对应的IP地址，找到就直接返回；否则进行下一步。\n将请求发往给本地DNS服务器，如果查找到也直接返回，否则继续进行下一步；\n\n域名服务器层级\n\n本地DNS服务器向根域名服务器发送请求，根域名服务器返回负责com的顶级域名服务器的IP地址的列表。\n本地DNS服务器再向其中一个负责com的顶级域名服务器发送一个请求，返回负责baidu.com的权限域名服务器的IP地址列表。\n本地DNS服务器再向其中一个权限域名服务器发送一个请求，返回www.baidu.com所对应的IP地址。\n\n6.说说 WebSocket 与 Socket 的区别？\nSocket 其实就是等于 IP 地址 + 端口 + 协议。\n\n\n\n\n\n\n\n\n\n\n具体来说，Socket 是一套标准，它完成了对 TCP&#x2F;IP 的高度封装，屏蔽网络细节，以方便开发者更好地进行网络编程。\n\nWebSocket 是一个持久化的协议，它是伴随 H5 而出的协议，用来解决 http 不支持持久化连接的问题。\nSocket 一个是网编编程的标准接口，而 WebSocket 则是应用层通信协议。\n\n7.说一下你了解的端口及对应的服务？常见端口和服务\nHTTP8.说说 HTTP 常用的状态码及其含义？HTTP状态码首先应该知道个大概的分类：\n\n1XX：信息性状态码\n2XX：成功状态码\n3XX：重定向状态码\n4XX：客户端错误状态码\n5XX：服务端错误状态码\n\n几个常用的，面试之外，也应该记住：\n常见HTTP状态码\n之前写过一篇：程序员五一被拉去相亲，结果彻底搞懂了HTTP常用状态码，还比较有意思，可以看看。\n\n\n\n\n\n\n\n\n\n说一下301和302的区别？\n\n301：永久性移动，请求的资源已被永久移动到新位置。服务器返回此响应时，会返回新的资源地址。\n302：临时性性移动，服务器从另外的地址响应资源，但是客户端还应该使用这个地址。\n\n用一个比喻，301就是嫁人的新垣结衣，302就是有男朋友的长泽雅美。\n9.HTTP 有哪些请求方式？HTTP请求方式1\n其中，POST、DELETE、PUT、GET的含义分别对应我们最熟悉的增、删、改、查。\n10.说⼀下 GET 和 POST 的区别？可以从以下几个方面来说明GET和POST的区别：\nGet和Post区别\n\n从 HTTP 报文层面来看，GET 请求将信息放在 URL，POST 将请求信息放在请求体中。这一点使得 GET  请求携带的数据量有限，因为 URL 本身是有长度限制的，而 POST 请求的数据存放在报文体中，因此对大小没有限制。而且从形式上看，GET  请求把数据放 URL 上不太安全，而 POST 请求把数据放在请求体里想比较而言安全一些。\n从数据库层面来看，GET 符合幂等性和安全性，而 POST 请求不符合。这个其实和 GET&#x2F;POST 请求的作用有关。按照 HTTP 的约定，GET 请求用于查看信息，不会改变服务器上的信息；而 POST 请求用来改变服务器上的信息。正因为 GET  请求只查看信息，不改变信息，对数据库的一次或多次操作获得的结果是一致的，认为它符合幂等性。安全性是指对数据库操作没有改变数据库中的数据。\n从其他层面来看，GET 请求能够被缓存，GET 请求能够保存在浏览器的浏览记录里，GET 请求的 URL  能够保存为浏览器书签。这些都是 POST 请求所不具备的。缓存是 GET  请求被广泛应用的根本，他能够被缓存也是因为它的幂等性和安全性，除了返回结果没有其他多余的动作，因此绝大部分的 GET 请求都被 CDN  缓存起来了，大大减少了 Web 服务器的负担。\n\n11.GET 的长度限制是多少？HTTP中的GET方法是通过URL传递数据的，但是URL本身其实并没有对数据的长度进行限制，真正限制GET长度的是浏览器。\n例如IE浏览器对URL的最大限制是2000多个字符，大概2kb左右，像Chrome、Firefox等浏览器支持的URL字符数更多，其中FireFox中URL的最大长度限制是65536个字符，Chrome则是8182个字符。\n这个长度限制也不是针对数据部分，而是针对整个URL。\n12.HTTP 请求的过程与原理？HTTP协议定义了浏览器怎么向服务器请求文档，以及服务器怎么把文档传给浏览器。\nHTTP请求的过程和原理\n\n每个服务器都有一个进程，它不断监听TCP的端口80，以便发现是否有浏览器向它发出连接建立请求\n监听到连接请求，就会建立TCP连接\n浏览器向服务器发出浏览某个页面的请求，服务器接着就返回所请求的页面作为响应\n最后，释放TCP连接\n\n在浏览器和服务器之间的请求和响应的交互，必须按照规定的格式和遵循一定的规则，这些格式和规则就是超文本传输协议HTTP。\nPS:这道题和上面浏览器输入网址发生了什么那道题大差不差。\n13.说一下HTTP的报文结构？HTTP报文有两种，HTTP请求报文和HTTP响应报文：\nHTTP报文\nHTTP请求报文\nHTTP 请求报文的格式如下：\nGET &#x2F; HTTP&#x2F;1.1\nUser-Agent: Mozilla&#x2F;5.0 (Macintosh; Intel Mac OS X 10_10_5)\nAccept: *&#x2F;*\n\nHTTP 请求报文的第一行叫做请求行，后面的行叫做首部行，首部行后还可以跟一个实体主体。请求首部之后有一个空行，这个空行不能省略，它用来划分首部与实体。\n请求行包含三个字段：\n\n方法字段：包括POST、GET等请方法。\nURL 字段\nHTTP 版本字段。\n\nHTTP 响应报文\nHTTP 响应报文的格式如下：\nHTTP&#x2F;1.0 200 OK\nContent-Type: text&#x2F;plain\nContent-Length: 137582\nExpires: Thu, 05 Dec 1997 16:00:00 GMT\nLast-Modified: Wed, 5 August 1996 15:55:28 GMT\nServer: Apache 0.84\n&lt;html&gt;\n  &lt;body&gt;Hello World&lt;&#x2F;body&gt;\n&lt;&#x2F;html&gt;\n\nHTTP 响应报文的第一行叫做状态行，后面的行是首部行，最后是实体主体。\n\n状态行包含了三个字段：协议版本字段、状态码和相应的状态信息。\n\n实体部分是报文的主要部分，它包含了所请求的对象。\n\n首部行首部可以分为四种首部，请求首部、响应首部、通用首部和实体首部。通用首部和实体首部在请求报文和响应报文中都可以设置，区别在于请求首部和响应首部。\n\n\n常见的请求首部有 Accept 可接收媒体资源的类型、Accept-Charset 可接收的字符集、Host 请求的主机名。\n常见的响应首部有 ETag 资源的匹配信息，Location 客户端重定向的 URI。\n常见的通用首部有 Cache-Control 控制缓存策略、Connection 管理持久连接。\n常见的实体首部有 Content-Length 实体主体的大小、Expires 实体主体的过期时间、Last-Modified 资源的最后修改时间。\n\n\n\n14.URI 和 URL 有什么区别?URI和URL\n\nURI，统一资源标识符(Uniform Resource Identifier， URI)，标识的是Web上每一种可用的资源，如 HTML文档、图像、视频片段、程序等都是由一个URI进行标识的。\nURL，统一资源定位符（Uniform Resource Location)，它是URI的一种子集，主要作用是提供资源的路径。\n\n它们的主要区别在于，URL除了提供了资源的标识，还提供了资源访问的方式。这么比喻，URI 像是身份证，可以唯一标识一个人，而 URL 更像一个住址，可以通过 URL 找到这个人——人类住址协议:&#x2F;&#x2F;地球&#x2F;中国&#x2F;北京市&#x2F;海淀区&#x2F;xx职业技术学院&#x2F;14号宿舍楼&#x2F;525号寝&#x2F;张三.男。\n15.说下 HTTP&#x2F;1.0，1.1，2.0 的区别？关键需要记住 HTTP&#x2F;1.0 默认是短连接，可以强制开启，HTTP&#x2F;1.1 默认长连接，HTTP&#x2F;2.0 采用多路复用。\nHTTP&#x2F;1.0\n\n默认使用短连接，每次请求都需要建立一个 TCP 连接。它可以设置Connection: keep-alive 这个字段，强制开启长连接。\n\nHTTP&#x2F;1.1\n\n引入了持久连接，即 TCP 连接默认不关闭，可以被多个请求复用。\n分块传输编码，即服务端每产生一块数据，就发送一块，用” 流模式” 取代” 缓存模式”。\n管道机制，即在同一个 TCP 连接里面，客户端可以同时发送多个请求。\n\nHTTP&#x2F;2.0\n\n二进制协议，1.1 版本的头信息是文本（ASCII 编码），数据体可以是文本或者二进制；2.0 中，头信息和数据体都是二进制。\n完全多路复用，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应。\n报头压缩，HTTP 协议不带有状态，每次请求都必须附上所有信息。Http&#x2F;2.0 引入了头信息压缩机制，使用 gzip 或 compress 压缩后再发送。\n服务端推送，允许服务器未经请求，主动向客户端发送资源。\n\n16.HTTP&#x2F;3了解吗？HTTP&#x2F;3主要有两大变化，传输层基于UDP、使用QUIC保证UDP可靠性。\nHTTP&#x2F;2存在的一些问题，比如重传等等，都是由于TCP本身的特性导致的，所以HTTP&#x2F;3在QUIC的基础上进行发展而来，QUIC（Quick UDP Connections）直译为快速UDP网络连接，底层使用UDP进行数据传输。\nHTTP&#x2F;3主要有这些特点：\n\n使用UDP作为传输层进行通信\n在UDP的基础上QUIC协议保证了HTTP&#x2F;3的安全性，在传输的过程中就完成了TLS加密握手\nHTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS&#x2F;1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS&#x2F;1.3 的 6 次交互合并成了 3 次，减少了交互次数。\nQUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到影响。\n\n我们拿一张图看一下HTTP协议的变迁：\nHTTP协议变迁\n17.HTTP 如何实现长连接？在什么时候会超时？\n\n\n\n\n\n\n\n\n什么是 HTTP 的长连接？\n\nHTTP 分为长连接和短连接，本质上说的是 TCP 的长短连接。TCP 连接是一个双向的通道，它是可以保持一段时间不关闭的，因此 TCP 连接才具有真正的长连接和短连接这一说法。\nTCP 长连接可以复用一个 TCP 连接，来发起多次的 HTTP 请求，这样就可以减少资源消耗，比如一次请求 HTML，如果是短连接的话，可能还需要请求后续的 JS&#x2F;CSS。\n\n\n\n\n\n\n\n\n\n\n如何设置长连接？\n通过在头部（请求和响应头）设置 Connection 字段指定为keep-alive，HTTP&#x2F;1.0 协议支持，但是是默认关闭的，从 HTTP&#x2F;1.1 以后，连接默认都是长连接。\n\n\n\n\n\n\n\n\n\n在什么时候会超时呢？\n\nHTTP 一般会有 httpd 守护进程，里面可以设置 keep-alive timeout，当 tcp 连接闲置超过这个时间就会关闭，也可以在 HTTP 的 header 里面设置超时时间\nTCP 的 keep-alive 包含三个参数，支持在系统内核的 net.ipv4 里面设置；当 TCP 连接之后，闲置了 tcp_keepalive_time，则会发生侦测包，如果没有收到对方的 ACK，那么会每隔 tcp_keepalive_intvl 再发一次，直到发送了 tcp_keepalive_probes，就会丢弃该连接。\n\n1. tcp_keepalive_intvl &#x3D; 15\n2. tcp_keepalive_probes &#x3D; 5\n3. tcp_keepalive_time &#x3D; 1800\n\n18.说说HTTP 与 HTTPS 有哪些区别？\nHTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP ⽹络层之间加⼊了 SSL&#x2F;TLS 安全协议，使得报⽂能够加密传输。\nHTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL&#x2F;TLS 的握⼿过程，才可进⼊加密报⽂传输。\nHTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。\nHTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。\n\n19.为什么要用HTTPS？解决了哪些问题？因为HTTP 是明⽂传输，存在安全上的风险：\n窃听⻛险，⽐如通信链路上可以获取通信内容，用户账号被盗。\n篡改⻛险，⽐如强制植⼊垃圾⼴告，视觉污染。\n冒充⻛险，⽐如冒充淘宝⽹站，用户金钱损失。\nHTTP和HTTPS\n所以引入了HTTPS，HTTPS 在 HTTP 与 TCP 层之间加⼊了 SSL&#x2F;TLS 协议，可以很好的解决了这些风险：\n\n信息加密：交互信息⽆法被窃取。\n校验机制：⽆法篡改通信内容，篡改了就不能正常显示。\n身份证书：能证明淘宝是真淘宝。\n\n所以SSL&#x2F;TLS 协议是能保证通信是安全的。\n20.HTTPS工作流程是怎样的？这道题有几个要点：公私钥、数字证书、加密、对称加密、非对称加密。\nHTTPS 主要工作流程：\n\n客户端发起 HTTPS 请求，连接到服务端的 443 端口。\n服务端有一套数字证书（证书内容有公钥、证书颁发机构、失效日期等）。\n服务端将自己的数字证书发送给客户端（公钥在证书里面，私钥由服务器持有）。\n客户端收到数字证书之后，会验证证书的合法性。如果证书验证通过，就会生成一个随机的对称密钥，用证书的公钥加密。\n客户端将公钥加密后的密钥发送到服务器。\n服务器接收到客户端发来的密文密钥之后，用自己之前保留的私钥对其进行非对称解密，解密之后就得到客户端的密钥，然后用客户端密钥对返回数据进行对称加密，酱紫传输的数据都是密文啦。\n服务器将加密后的密文返回到客户端。\n客户端收到后，用自己的密钥对其进行对称解密，得到服务器返回的数据。\n\nhttps主要流程\n这里还画了一张更详尽的图：\nhttps工作流程详图\n21.客户端怎么去校验证书的合法性？首先，服务端的证书从哪来的呢？\n为了让服务端的公钥被⼤家信任，服务端的证书都是由 CA （Certificate Authority，证书认证机构）签名的，CA就是⽹络世界⾥的公安局、公证中⼼，具有极⾼的可信度，所以由它来给各个公钥签名，信任的⼀⽅签发的证书，那必然证书也是被信任的。\n证书签名和客户端校验-来源参考[2]\nCA 签发证书的过程，如上图左边部分：\n\n⾸先 CA 会把持有者的公钥、⽤途、颁发者、有效时间等信息打成⼀个包，然后对这些信息进⾏ Hash 计算，得到⼀个 Hash 值；\n然后 CA 会使⽤⾃⼰的私钥将该 Hash 值加密，⽣成 Certificate Signature，也就是 CA 对证书做了签名；\n最后将 Certificate Signature 添加在⽂件证书上，形成数字证书；\n\n客户端校验服务端的数字证书的过程，如上图右边部分：\n\n⾸先客户端会使⽤同样的 Hash 算法获取该证书的 Hash 值 H1；\n通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使⽤ CA 的公钥解密 Certificate\nSignature 内容，得到⼀个 Hash 值 H2 ；\n最后⽐较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。\n\n假如在HTTPS的通信过程中，中间人篡改了证书原文，由于他没有CA机构的私钥，所以CA公钥解密的内容就不一致。\n22.如何理解 HTTP 协议是无状态的？这个无状态的的状态值的是什么？是客户端的状态，所以字面意思，就是HTTP协议中服务端不会保存客户端的任何信息。\n比如当浏览器第一次发送请求给服务器时，服务器响应了；如果同个浏览器发起第二次请求给服务器时，它还是会响应，但是呢，服务器不知道你就是刚才的那个浏览器。\n\n\n\n\n\n\n\n\n\n那有什么办法记录状态呢？\n主要有两个办法，Session和Cookie。\n23.说说Session 和 Cookie 有什么联系和区别?先来看看什么是 Session 和 Cookie ：\n\nCookie 是保存在客户端的一小块文本串的数据。客户端向服务器发起请求时，服务端会向客户端发送一个 Cookie，客户端就把 Cookie 保存起来。在客户端下次向同一服务器再发起请求时，Cookie 被携带发送到服务器。服务端可以根据这个Cookie判断用户的身份和状态。\nSession 指的就是服务器和客户端一次会话的过程。它是另一种记录客户状态的机制。不同的是cookie保存在客户端浏览器中，而session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是session。客户端浏览器再次访问时只需要从该session中查找用户的状态。\n\nCookie和Session\n\n\n\n\n\n\n\n\n\nSession 和 Cookie 到底有什么不同呢？\n\n存储位置不一样，Cookie 保存在客户端，Session 保存在服务器端。\n存储数据类型不一样，Cookie 只能保存ASCII，Session可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等。\n有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般有效时间较短，客户端关闭或者 Session 超时都会失效。\n隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。\n存储大小不同， 单个Cookie保存的数据不能超过4K，Session可存储数据远高于 Cookie。\n\n\n\n\n\n\n\n\n\n\nSession 和 Cookie有什么关联呢？\n可以使用Cookie记录Session的标识。\nSession和Cookie的关联\n\n用户第一次请求服务器时，服务器根据用户提交的信息，创建对应的 Session，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入 Cookie 中，同时 Cookie 记录此 SessionID 是属于哪个域名。\n当用户第二次访问服务器时，请求会自动判断此域名下是否存在 Cookie 信息，如果存在，则自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到，说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。\n\n\n\n\n\n\n\n\n\n\n分布式环境下Session怎么处理呢？\n分布式环境下，客户端请求经过负载均衡，可能会分配到不同的服务器上，假如一个用户的请求两次没有落到同一台服务器上，那么在新的服务器上就没有记录用户状态的Session。\n这时候怎么办呢？\n可以使用Redis等分布式缓存来存储Session，在多台服务器之间共享。\nSession共享\n\n\n\n\n\n\n\n\n\n客户端无法使用Cookie怎么办？\n有可能客户端无法使用Cookie，比如浏览器禁用Cookie，或者客户端是安卓、IOS等等。\n这时候怎么办？SessionID怎么存？怎么传给服务端呢？\n首先是SessionID的存储，可以使用客户端的本地存储，比如浏览器的sessionStorage。\n接下来怎么传呢？\n\n拼接到URL里：直接把SessionID作为URL的请求参数\n放到请求头里：把SessionID放到请求的Header里，比较常用。\n\nTCP24.详细说一下 TCP 的三次握手机制PS:TCP三次握手是最重要的知识点，一定要熟悉到问到即送分。\nTCP提供面向连接的服务，在传送数据前必须建立连接，TCP连接是通过三次握手建立的。\nTCP三次握手示意图\n三次握手的过程：\n\n最开始，客户端和服务端都处于CLOSE状态，服务端监听客户端的请求，进入LISTEN状态\n\n客户端端发送连接请求，第一次握手 (SYN&#x3D;1, seq&#x3D;x)，发送完毕后，客户端就进入 SYN_SENT 状态\n\n服务端确认连接，第二次握手 (SYN&#x3D;1, ACK&#x3D;1, seq&#x3D;y, ACKnum&#x3D;x+1)， 发送完毕后，服务器端就进入 SYN_RCV 状态。\n\n客户端收到服务端的确认之后，再次向服务端确认，这就是**第三次握手 **(ACK&#x3D;1，ACKnum&#x3D;y+1)，发送完毕后，客户端进入 ESTABLISHED 状态，当服务器端接收到这个包时，也进入 ESTABLISHED 状态。\n\n\nTCP三次握手通俗比喻：\n在二十年前的农村，电话没有普及，手机就更不用说了，所以，通信基本靠吼。\n老张和老王是邻居，这天老张下地了，结果家里有事，热心的邻居老王赶紧跑到村口，开始叫唤老王。\n\n老王：老张唉！我是老王，你能听到吗？\n\n老张一听，是老王的声音：老王老王，我是老张，我能听到，你能听到吗？\n\n老王一听，嗯，没错，是老张：老张，我听到了，我有事要跟你说。\n“你老婆要生了，赶紧回家吧！”\n\n\n老张风风火火地赶回家，老婆顺利地生了个带把的大胖小子。握手的故事充满了幸福和美满。\n大白话三次握手\n25.TCP 握手为什么是三次，为什么不能是两次？不能是四次？\n\n\n\n\n\n\n\n\n为什么不能是两次？\n\n为了防止服务器端开启一些无用的连接增加服务器开销\n防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。\n\n由于网络传输是有延时的(要通过网络光纤和各种中间代理服务器)，在传输的过程中，比如客户端发起了 SYN&#x3D;1 的第一次握手。\n如果服务器端就直接创建了这个连接并返回包含 SYN、ACK 和 Seq  等内容的数据包给客户端，这个数据包因为网络传输的原因丢失了，丢失之后客户端就一直没有接收到服务器返回的数据包。\n如果没有第三次握手告诉服务器端客户端收的到服务器端传输的数据的话，服务器端是不知道客户端有没有接收到服务器端返回的信息的。\n服务端就认为这个连接是可用的，端口就一直开着，等到客户端因超时重新发出请求时，服务器就会重新开启一个端口连接。这样一来，就会有很多无效的连接端口白白地开着，导致资源的浪费。\n无三次握手导致端口占用\n还有一种情况是已经失效的客户端发出的请求信息，由于某种原因传输到了服务器端，服务器端以为是客户端发出的有效请求，接收后产生错误。\n响应生效请求\n所以我们需要“第三次握手”来确认这个过程：\n通过第三次握手的数据告诉服务端，客户端有没有收到服务器“第二次握手”时传过去的数据，以及这个连接的序号是不是有效的。若发送的这个数据是“收到且没有问题”的信息，接收后服务器就正常建立 TCP 连接，否则建立 TCP  连接失败，服务器关闭连接端口。由此减少服务器开销和接收到失效请求发生的错误。\n\n\n\n\n\n\n\n\n\n为什么不是四次？\n简单说，就是三次挥手已经足够创建可靠的连接，没有必要再多一次握手导致花费更多的时间建立连接。\n26.三次握手中每一次没收到报文会发生什么情况？\n第一次握手服务端未收到SYN报文\n服务端不会进行任何的动作，而客户端由于一段时间内没有收到服务端发来的确认报文，等待一段时间后会重新发送SYN报文，如果仍然没有回应，会重复这个过程，直到发送次数超过最大重传次数限制，就会返回连接建立失败。\n\n第二次握手客户端未收到服务端响应的ACK报文\n客户端会继续重传，直到次数限制；而服务端此时会阻塞在accept()处，等待客户端发送ACK报文\n\n第三次握手服务端为收到客户端发送过来的ACK报文\n服务端同样会采用类似客户端的超时重传机制，如果重试次数超过限制，则accept()调用返回-1，服务端建立连接失败；而此时客户端认为自己已经建立连接成功，因此开始向服务端发送数据，但是服务端的accept()系统调用已经返回，此时不在监听状态，因此服务端接收到客户端发送来的数据时会发送RST报文给客户端，消除客户端单方面建立连接的状态。\n\n\n27.第二次握手传回了 ACK，为什么还要传回 SYN？ACK是为了告诉客户端传来的数据已经接收无误。\n而传回SYN是为了告诉客户端，服务端响应的确实是客户端发送的报文。\n28.第3次握手可以携带数据吗？第3次握手是可以携带数据的。\n此时客户端已经处于ESTABLISHED状态。对于客户端来说，它已经建立连接成功，并且确认服务端的接收和发送能力是正常的。\n第一次握手不能携带数据是出于安全的考虑，因为如果允许携带数据，攻击者每次在SYN报文中携带大量数据，就会导致服务端消耗更多的时间和空间去处理这些报文，会造成CPU和内存的消耗。\n29.说说半连接队列和 SYN Flood 攻击的关系？\n\n\n\n\n\n\n\n\n什么是半连接队列？\nTCP 进入三次握手前，服务端会从 CLOSED 状态变为 LISTEN 状态, 同时在内部创建了两个队列：半连接队列（SYN 队列）和全连接队列（ACCEPT 队列）。\n三次握手中创建的队列\n顾名思义，半连接队列存放的是三次握手未完成的连接，全连接队列存放的是完成三次握手的连接。\n\nTCP 三次握手时，客户端发送 SYN 到服务端，服务端收到之后，便回复 ACK 和 SYN，状态由 LISTEN 变为 SYN_RCVD，此时这个连接就被推入了 SYN 队列，即半连接队列。\n当客户端回复 ACK, 服务端接收后，三次握手就完成了。这时连接会等待被具体的应用取走，在被取走之前，它被推入 ACCEPT 队列，即全连接队列。\n\n\n\n\n\n\n\n\n\n\n什么是SYN Flood ？\nSYN Flood 是一种典型的 DDos 攻击，它在短时间内，伪造不存在的 IP 地址, 向服务器发送大量SYN 报文。当服务器回复 SYN+ACK 报文后，不会收到 ACK 回应报文，那么SYN队列里的连接旧不会出对队，久⽽久之就会占满服务端的 SYN 接收队列（半连接队列），使得服务器不能为正常⽤户服务。\nSYN攻击\n\n\n\n\n\n\n\n\n\n那有什么应对方案呢？\n主要有 syn cookie 和 SYN Proxy 防火墙等。\n\nsyn cookie：在收到 SYN 包后，服务器根据一定的方法，以数据包的源地址、端口等信息为参数计算出一个 cookie 值作为自己的 SYNACK 包的序列号，回复 SYN+ACK 后，服务器并不立即分配资源进行处理，等收到发送方的 ACK 包后，重新根据数据包的源地址、端口计算该包中的确认序列号是否正确，如果正确则建立连接，否则丢弃该包。\nSYN Proxy 防火墙：服务器防火墙会对收到的每一个 SYN 报文进行代理和回应，并保持半连接。等发送方将 ACK 包返回后，再重新构造 SYN 包发到服务器，建立真正的 TCP 连接。\n\n30.说说 TCP 四次挥手的过程？PS：问完三次握手，常常也会顺道问问四次挥手，所以也是必须掌握知识点。\nTCP四次挥手\nTCP 四次挥手过程：\n\n数据传输结束之后，通信双方都可以主动发起断开连接请求，这里假定客户端发起\n客户端发送释放连接报文，第一次挥手 (FIN&#x3D;1，seq&#x3D;u)，发送完毕后，客户端进入 FIN_WAIT_1 状态。\n服务端发送确认报文，第二次挥手 (ACK&#x3D;1，ack&#x3D;u+1,seq &#x3D;v)，发送完毕后，服务器端进入 CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入 FIN_WAIT_2 状态。\n服务端发送释放连接报文，第三次挥手 (FIN&#x3D;1，ACK1,seq&#x3D;w,ack&#x3D;u+1)，发送完毕后，服务器端进入 LAST_ACK 状态，等待来自客户端的最后一个 ACK。\n客户端发送确认报文，第四次挥手 (ACK&#x3D;1，seq&#x3D;u+1,ack&#x3D;w+1)，客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入 TIME_WAIT 状态，等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的 ACK ，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入 CLOSED 状态。服务器端接收到这个确认包之后，关闭连接，进入 CLOSED 状态。\n\n大白话说四次挥手：\n假如单身狗博主有一个女朋友—由于博主上班九九六，下班肝博客，导致没有时间陪女朋友，女朋友忍无可忍。\n\n女朋友：狗男人，最近你都不理我，你是不是不爱我了？你是不是外面有别的狗子了？我要和你分手？\n沙雕博主一愣，怒火攻心：分手就分手，不陪你闹了，等我把东西收拾收拾。\n\n沙雕博主小心翼翼地装起了自己的青轴机械键盘。\n\n哼，蠢女人，我已经收拾完了，我先滚为敬，再见！\n女朋友：滚，滚的远远的，越远越好，我一辈子都不想再见到你。\n\n挥手的故事总充满了悲伤和遗憾！\n大白话四次挥手\n31.TCP 挥手为什么需要四次呢？再来回顾下四次挥手双方发 FIN 包的过程，就能理解为什么需要四次了。\n\n关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。\n服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。\n\n从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。\n32.TCP 四次挥手过程中，为什么需要等待 2MSL, 才进入 CLOSED 关闭状态？\n\n\n\n\n\n\n\n\n为什么需要等待？\n1. 为了保证客户端发送的最后一个 ACK 报文段能够到达服务端。 这个 ACK 报文段有可能丢失，因而使处在 LAST-ACK 状态的服务端就收不到对已发送的 FIN + ACK 报文段的确认。服务端会超时重传这个 FIN+ACK 报文段，而客户端就能在 2MSL 时间内（超时 + 1MSL 传输）收到这个重传的 FIN+ACK 报文段。接着客户端重传一次确认，重新启动 2MSL 计时器。最后，客户端和服务器都正常进入到 CLOSED 状态。\n2. 防止已失效的连接请求报文段出现在本连接中。客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。\n\n\n\n\n\n\n\n\n\n为什么等待的时间是2MSL？\nMSL 是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这个时间报⽂将被丢弃。\nTIME_WAIT 等待 2 倍的 MSL，⽐较合理的解释是：⽹络中可能存在来⾃发送⽅的数据包，当这些发送⽅的数据包被接收⽅处理后⼜会向对⽅发送响应，所以⼀来⼀回需要等待 2 倍的时间。\n2MSL恰好一个来回\n⽐如如果被动关闭⽅没有收到断开连接的最后的 ACK 报⽂，就会触发超时重发 Fin 报⽂，另⼀⽅接收到 FIN 后，会重发 ACK 给被动关闭⽅， ⼀来⼀去正好 2 个 MSL。\n33.保活计时器有什么用？除时间等待计时器外，TCP 还有一个保活计时器（keepalive timer）。\n设想这样的场景：客户已主动与服务器建立了 TCP 连接。但后来客户端的主机突然发生故障。显然，服务器以后就不能再收到客户端发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就需要使用保活计时器了。\n服务器每收到一次客户端的数据，就重新设置保活计时器，时间的设置通常是两个小时。若两个小时都没有收到客户端的数据，服务端就发送一个探测报文段，以后则每隔 75 秒钟发送一次。若连续发送 10 个探测报文段后仍然无客户端的响应，服务端就认为客户端出了故障，接着就关闭这个连接。\n34.CLOSE-WAIT 和 TIME-WAIT 的状态和意义？\n\n\n\n\n\n\n\n\nCLOSE-WAIT状态有什么意义？\n服务端收到客户端关闭连接的请求并确认之后，就会进入CLOSE-WAIT状态。此时服务端可能还有一些数据没有传输完成，因此不能立即关闭连接，而CLOSE-WAIT状态就是为了保证服务端在关闭连接之前将待发送的数据处理完。\n\n\n\n\n\n\n\n\n\nTIME-WAIT有什么意义？\nTIME-WAIT状态发生在第四次挥手，当客户端向服务端发送ACK确认报文后进入TIME-WAIT状态。\n它存在的意义主要是两个：\nTIME_WAIT状态的作用\n\n防⽌旧连接的数据包\n如果客户端收到服务端的FIN报文之后立即关闭连接，但是此时服务端对应的端口并没有关闭，如果客户端在相同端口建立新的连接，可能会导致新连接收到旧连接残留的数据包，导致不可预料的异常发生。\n\n保证连接正确关闭\n假设客户端最后一次发送的ACK包在传输的时候丢失了，由于TCP协议的超时重传机制，服务端将重发FIN报文，如果客户端没有维持TIME-WAIT状态而直接关闭的话，当收到服务端重新发送的FIN包时，客户端就会使用RST包来响应服务端，导致服务端以为有错误发生，然而实际关闭连接过程是正常的。\n\n\n35.TIME_WAIT 状态过多会导致什么问题？怎么解决？\n\n\n\n\n\n\n\n\nTIME_WAIT 状态过多会导致什么问题?\n如果服务器有处于 TIME-WAIT 状态的 TCP，则说明是由服务器⽅主动发起的断开请求。\n过多的 TIME-WAIT 状态主要的危害有两种：\n第⼀是内存资源占⽤；\n第⼆是对端⼝资源的占⽤，⼀个 TCP 连接⾄少消耗⼀个本地端⼝；\n\n\n\n\n\n\n\n\n\n怎么解决TIME_WAIT 状态过多？\n\n服务器可以设置SO_REUSEADDR套接字来通知内核，如果端口被占用，但是TCP连接位于TIME_WAIT 状态时可以重用端口。\n还可以使用长连接的方式来减少TCP的连接和断开，在长连接的业务里往往不需要考虑TIME_WAIT状态。\n\n36.说说 TCP 报文首部的格式？看一下TCP报文首部的格式：\nTCP报文首部的格式\n\n16 位端口号：源端口号，主机该报文段是来自哪里；目标端口号，要传给哪个上层协议或应用程序\n32 位序号：一次 TCP 通信（从 TCP 连接建立到断开）过程中某一个传输方向上的字节流的每个字节的编号。\n32 位确认号：用作对另一方发送的 tcp 报文段的响应。其值是收到的 TCP 报文段的序号值加 1。\n4 位首部长度：表示 tcp 头部有多少个 32bit 字（4 字节）。因为 4 位最大能标识 15，所以 TCP 头部最长是 60 字节。\n6 位标志位：URG(紧急指针是否有效)，ACk（表示确认号是否有效），PST（缓冲区尚未填满），RST（表示要求对方重新建立连接），SYN（建立连接消息标志接），FIN（表示告知对方本端要关闭连接了）\n16 位窗口大小：是 TCP 流量控制的一个手段。这里说的窗口，指的是接收通告窗口。它告诉对方本端的 TCP 接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。\n16 位校验和：由发送端填充，接收端对 TCP 报文段执行 CRC 算法以检验 TCP 报文段在传输过程中是否损坏。注意，这个校验不仅包括 TCP 头部，也包括数据部分。这也是 TCP 可靠传输的一个重要保障。\n16 位紧急指针：一个正的偏移量。它和序号字段的值相加表示最后一个紧急数据的下一字节的序号。因此，确切地说，这个字段是紧急指针相对当前序号的偏移，不妨称之为紧急偏移。TCP 的紧急指针是发送端向接收端发送紧急数据的方法。\n\n37.TCP 是如何保证可靠性的？TCP主要提供了检验和、序列号&#x2F;确认应答、超时重传、最大消息长度、滑动窗口控制等方法实现了可靠性传输。\nTCP保证可靠性的方法\n\n连接管理：TCP使用三次握手和四次挥手保证可靠地建立连接和释放连接，这里就不用多说了。\n校验和：TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果接收端的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。\n\nTCP校验和\n\n序列号&#x2F;确认应答：TCP 给发送的每一个包进行编号，接收方会对收到的包进行应答，发送方就会知道接收方是否收到对应的包，如果发现没有收到，就会重发，这样就能保证数据的完整性。就像老师上课，会问一句，这一章听懂了吗？没听懂再讲一遍。\n\n序列号&#x2F;确认应答\n\n流量控制：TCP  连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。（TCP 利用滑动窗口实现流量控制）\n\n滑动窗口简图\n\n最大消息长度：在建立TCP连接的时候，双方约定一个最大的长度（MSS）作为发送的单位，重传的时候也是以这个单位来进行重传。理想的情况下是该长度的数据刚好不被网络层分块。\n\n最大消息长度\n\n超时重传：超时重传是指发送出去的数据包到接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。\n\n超时重传\n\n拥塞控制：如果网络非常拥堵，此时再发送数据就会加重网络负担，那么发送的数据段很可能超过了最大生存时间也没有到达接收方，就会产生丢包问题。为此TCP引入慢启动机制，先发出少量数据，就像探路一样，先摸清当前的网络拥堵状态后，再决定按照多大的速度传送数据。\n\n拥塞控制简略示意图\n38.说说 TCP 的流量控制？TCP 提供了一种机制，可以让发送端根据接收端的实际接收能力控制发送的数据量，这就是流量控制。\nTCP 通过滑动窗口来控制流量，我们看下简要流程：\n\n首先双方三次握手，初始化各自的窗口大小，均为 400 个字节。\n\nTCP流量控制\n\n假如当前发送方给接收方发送了 200 个字节，那么，发送方的SND.NXT会右移 200 个字节，也就是说当前的可用窗口减少了 200 个字节。\n接受方收到后，放到缓冲队列里面，REV.WND &#x3D;400-200&#x3D;200 字节，所以 win&#x3D;200 字节返回给发送方。接收方会在 ACK 的报文首部带上缩小后的滑动窗口 200 字节\n发送方又发送 200 字节过来，200 字节到达，继续放到缓冲队列。不过这时候，由于大量负载的原因，接受方处理不了这么多字节，只能处理 100 字节，剩余的 100 字节继续放到缓冲队列。这时候，REV.WND &#x3D; 400-200-100&#x3D;100 字节，即 win&#x3D;100 返回发送方。\n发送方继续发送 100 字节过来，这时候，接收窗口 win 变为 0。\n发送方停止发送，开启一个定时任务，每隔一段时间，就去询问接受方，直到 win 大于 0，才继续开始发送。\n\n39.详细说说 TCP 的滑动窗口？TCP 发送一个数据，如果需要收到确认应答，才会发送下一个数据。这样的话就会有个缺点：效率会比较低。\n“用一个比喻，我们在微信上聊天，你打完一句话，我回复一句之后，你才能打下一句。假如我没有及时回复呢？你是把话憋着不说吗？然后傻傻等到我回复之后再接着发下一句？”\n为了解决这个问题，TCP 引入了窗口，它是操作系统开辟的一个缓存空间。窗口大小值表示无需等待确认应答，而可以继续发送数据的最大值。\nTCP 头部有个字段叫 win，也即那个 16 位的窗口大小，它告诉对方本端的 TCP 接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度，从而达到流量控制的目的。\n“通俗点讲，就是接受方每次收到数据包，在发送确认报文的时候，同时告诉发送方，自己的缓存区还有多少空余空间，缓冲区的空余空间，我们就称之为接受窗口大小。这就是 win。”\nTCP 滑动窗口分为两种: 发送窗口和接收窗口。发送端的滑动窗口包含四大部分，如下：\n\n已发送且已收到 ACK 确认\n已发送但未收到 ACK 确认\n未发送但可以发送\n未发送也不可以发送\n\n发送端滑动窗口\n\n深蓝色框里就是发送窗口。\nSND.WND: 表示发送窗口的大小, 上图虚线框的格子数是 10个，即发送窗口大小是 10。\nSND.NXT：下一个发送的位置，它指向未发送但可以发送的第一个字节的序列号。\nSND.UNA: 一个绝对指针，它指向的是已发送但未确认的第一个字节的序列号。\n\n接收方的滑动窗口包含三大部分，如下：\n\n已成功接收并确认\n未收到数据但可以接收\n未收到数据并不可以接收的数据\n\n接收方滑动窗口\n\n蓝色框内，就是接收窗口。\nREV.WND: 表示接收窗口的大小, 上图虚线框的格子就是 9 个。\nREV.NXT: 下一个接收的位置，它指向未收到但可以接收的第一个字节的序列号。\n\n40.了解Nagle 算法和延迟确认吗？\n\n\n\n\n\n\n\n\nNagle 算法和延迟确认是干什么的？\n当我们 TCP 报⽂的承载的数据⾮常⼩的时候，例如⼏个字节，那么整个⽹络的效率是很低的，因为每个 TCP 报⽂中都会有 20 个字节的 TCP 头部，也会有 20 个字节的 IP 头部，⽽数据只有⼏个字节，所以在整个报⽂中有效数据占有的比例就会⾮常低。\n小数据情况\n这就好像快递员开着⼤货⻋送⼀个⼩包裹⼀样浪费。\n那么就出现了常⻅的两种策略，来减少⼩报⽂的传输，分别是：\n\nNagle 算法\n延迟确认\n\n\n\n\n\n\n\n\n\n\nNagle 算法\nNagle 算法：任意时刻，最多只能有一个未被确认的小段。所谓 “小段”，指的是小于 MSS 尺寸的数据块，所谓 “未被确认”，是指一个数据块发送出去后，没有收到对方发送的 ACK 确认该数据已收到。\nNagle 算法的策略：\n\n没有已发送未确认报⽂时，⽴刻发送数据。\n存在未确认报⽂时，直到「没有已发送未确认报⽂」或「数据⻓度达到 MSS ⼤⼩」时，再发送数据。\n\n只要没满⾜上⾯条件中的⼀条，发送⽅⼀直在囤积数据，直到满⾜上⾯的发送条件。\n\n\n\n\n\n\n\n\n\n延迟确认\n事实上当没有携带数据的 ACK，它的⽹络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报⽂。\n为了解决 ACK 传输效率低问题，所以就衍⽣出了 TCP 延迟确认。\nTCP 延迟确认的策略：\n\n当有响应数据要发送时，ACK 会随着响应数据⼀起⽴刻发送给对⽅\n当没有响应数据要发送时，ACK 将会延迟⼀段时间，以等待是否有响应数据可以⼀起发送\n如果在延迟等待发送 ACK 期间，对⽅的第⼆个数据报⽂⼜到达了，这时就会⽴刻发送 ACK\n\n一般情况下，Nagle 算法和延迟确认不能一起使用，Nagle 算法意味着延迟发，延迟确认意味着延迟接收，两个凑在一起就会造成更大的延迟，会产生性能问题。\n41.说说TCP 的拥塞控制？\n\n\n\n\n\n\n\n\n什么是拥塞控制？不是有了流量控制吗？\n前⾯的流量控制是避免发送⽅的数据填满接收⽅的缓存，但是并不知道整个⽹络之中发⽣了什么。\n⼀般来说，计算机⽹络都处在⼀个共享的环境。因此也有可能会因为其他主机之间的通信使得⽹络拥堵。\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤….\n所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。\n于是，就有了拥塞控制，控制的⽬的就是避免发送⽅的数据填满整个⽹络。\n就像是一个水管，不能让太多的水（数据流）流入水管，如果超过水管的承受能力，水管会被撑爆（丢包）。\n破解的水管-图片来源网络\n发送方维护一个拥塞窗口 cwnd（congestion window） 的变量，调节所要发送数据的量。\n\n\n\n\n\n\n\n\n\n什么是拥塞窗⼝？和发送窗⼝有什么关系呢？\n拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。\n发送窗⼝ swnd 和接收窗⼝ rwnd 是约等于的关系，那么由于加⼊了拥塞窗⼝的概念后，此时发送窗⼝的值是swnd &#x3D; min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。\n拥塞窗⼝ cwnd 变化的规则：\n\n只要⽹络中没有出现拥塞， cwnd 就会增⼤；\n但⽹络中出现了拥塞， cwnd 就减少；\n\n\n\n\n\n\n\n\n\n\n拥塞控制有哪些常用算法？\n拥塞控制主要有这几种常用算法：\n拥塞控制常用算法\n\n慢启动\n拥塞避免\n拥塞发生\n快速恢复\n\n慢启动算法慢启动算法，慢慢启动。\n它表示 TCP 建立连接完成后，一开始不要发送大量的数据，而是先探测一下网络的拥塞程度。由小到大逐渐增加拥塞窗口的大小，如果没有出现丢包，每收到一个 ACK，就将拥塞窗口 cwnd 大小就加 1（单位是 MSS）。每轮次发送窗口增加一倍，呈指数增长，如果出现丢包，拥塞窗口就减半，进入拥塞避免阶段。\n举个例子：\n\n连接建⽴完成后，⼀开始初始化 cwnd &#x3D; 1 ，表示可以传⼀个 MSS ⼤⼩的数据。\n当收到⼀个 ACK 确认应答后，cwnd 增加 1，于是⼀次能够发送 2 个\n当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以⽐之前多发2 个，所以这⼀次能够发送 4 个\n当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以⽐之前多发4 个，所以这⼀次能够发送 8 个。\n\n慢启动算法\n发包的个数是指数性的增⻓。\n慢启动呈指数型增长\n为了防止 cwnd 增长过大引起网络拥塞，还需设置一个慢启动阀值 ssthresh（slow start threshold）状态变量。当cwnd到达该阀值后，就好像水管被关小了水龙头一样，减少拥塞状态。即当 cwnd &gt;ssthresh 时，进入了拥塞避免算法。\n拥塞避免算法一般来说，慢启动阀值 ssthresh 是 65535 字节，cwnd到达慢启动阀值后\n\n每收到一个 ACK 时，cwnd &#x3D; cwnd + 1&#x2F;cwnd\n当每过一个 RTT 时，cwnd &#x3D; cwnd + 1\n\n显然这是一个线性上升的算法，避免过快导致网络拥塞问题。\n接着上面慢启动的例子，假定 ssthresh 为 8 ：：\n\n当 8 个 ACK 应答确认到来时，每个确认增加 1&#x2F;8，8 个 ACK 确认 cwnd ⼀共增加 1，于是这⼀次能够发送 9个 MSS ⼤⼩的数据，变成了线性增⻓。\n\n拥塞避免算法\n拥塞发生当网络拥塞发生丢包时，会有两种情况：\n\nRTO 超时重传\n快速重传\n\n如果是发生了 RTO 超时重传，就会使用拥塞发生算法\n\n慢启动阀值 sshthresh &#x3D;  cwnd &#x2F;2\ncwnd 重置为 1\n进入新的慢启动过程\n\n拥塞发生算法\n这种方式就像是飙车的时候急刹车，还飞速倒车，这。。。\n其实还有更好的处理方式，就是快速重传。发送方收到 3 个连续重复的 ACK 时，就会快速地重传，不必等待 RTO 超时再重传。\n发⽣快速重传的拥塞发⽣算法：\n\n拥塞窗口大小 cwnd &#x3D; cwnd&#x2F;2\n慢启动阀值 ssthresh &#x3D; cwnd\n进入快速恢复算法\n\n快速恢复快速重传和快速恢复算法一般同时使用。快速恢复算法认为，还有 3 个重复 ACK 收到，说明网络也没那么糟糕，所以没有必要像 RTO 超时那么强烈。\n正如前面所说，进入快速恢复之前，cwnd 和 sshthresh 已被更新：\n\ncwnd &#x3D; cwnd &#x2F;2\n\n- sshthresh &#x3D; cwnd\n然后，进⼊快速恢复算法如下：\n\ncwnd &#x3D; sshthresh  + 3\n重传重复的那几个 ACK（即丢失的那几个数据包）\n如果再收到重复的 ACK，那么 cwnd &#x3D; cwnd +1\n如果收到新数据的 ACK 后, cwnd &#x3D; sshthresh。因为收到新数据的 ACK，表明恢复过程已经结束，可以再次进入了拥塞避免的算法了。\n\n快速恢复算法\n42.说说 TCP 的重传机制？重传包括超时重传、快速重传、带选择确认的重传（SACK）、重复 SACK 四种。\nTCP重传分类\n超时重传超时重传，是 TCP 协议保证数据可靠性的另一个重要机制，其原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。\n\n\n\n\n\n\n\n\n\n超时时间应该设置为多少呢？\n先来看下什么叫 RTT（Round-Trip Time，往返时间）。\nRTT\nRTT 就是数据完全发送完，到收到确认信号的时间，即数据包的一次往返时间。\n超时重传时间，就是 RTO（Retransmission Timeout)。那么，RTO 到底设置多大呢？\n\n如果 RTO 设置很大，等了很久都没重发，这样肯定就不行。\n如果 RTO 设置很小，那很可能数据都没有丢失，就开始重发了，这会导致网络阻塞，从而恶性循环，导致更多的超时出现。\n\n一般来说，RTO 略微大于 RTT，效果是最佳的。\n其实，RTO 有个标准方法的计算公式，也叫 Jacobson &#x2F; Karels 算法。\n\n首先计算 SRTT（即计算平滑的 RTT）\n\nSRTT &#x3D; (1 - α) * SRTT + α * RTT  &#x2F;&#x2F;求 SRTT 的加权平均\n\n\n其次，计算 RTTVAR (round-trip time variation)\n\nRTTVAR &#x3D; (1 - β) * RTTVAR + β * (|RTT - SRTT|) &#x2F;&#x2F;计算 SRTT 与真实值的差距\n\n\n最后，得出最终的 RTO\n\nRTO &#x3D; µ * SRTT + ∂ * RTTVAR  &#x3D;  SRTT + 4·RTTVAR  \n\n在 Linux 下，α &#x3D; 0.125，β &#x3D; 0.25， μ &#x3D; 1，∂ &#x3D; 4。别问这些参数是怎么来的，它们是大量实践，调出的最优参数。\n超时重传不是十分完美的重传方案，它有这些缺点：\n\n当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。\n当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。\n\n并且，对于 TCP，如果发生一次超时重传，时间间隔下次就会加倍。\n快速重传TCP 还有另外⼀种快速重传（Fast Retransmit）机制，它不以时间为驱动，⽽是以数据驱动重传。\n它不以时间驱动，而是以数据驱动。它是基于接收端的反馈信息来引发重传的。\n可以用它来解决超时重发的时间等待问题，快速重传流程如下：\n快速重传流程\n在上图，发送⽅发出了 1，2，3，4，5 份数据：\n\n第⼀份 Seq1 先送到了，于是就 Ack 回 2；\n结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；\n后⾯的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；\n发送端收到了三个 Ack &#x3D; 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。\n最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。\n\n快速重传机制只解决了⼀个问题，就是超时时间的问题，但是它依然⾯临着另外⼀个问题。就是重传的时候，是重传之前的⼀个，还是重传所有的问题。\n⽐如对于上⾯的例⼦，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。\n根据 TCP 不同的实现，以上两种情况都是有可能的。可⻅，这是⼀把双刃剑。\n为了解决不知道该重传哪些 TCP 报⽂，于是就有 SACK ⽅法。\n带选择确认的重传（SACK）为了解决应该重传多少个包的问题? TCP 提供了带选择确认的重传（即 SACK，Selective Acknowledgment）。\nSACK 机制就是，在快速重传的基础上，接收方返回最近收到报文段的序列号范围，这样发送方就知道接收方哪些数据包是没收到的。这样就很清楚应该重传哪些数据包。\nSACK机制-来源参考[3]\n如上图中，发送⽅收到了三次同样的 ACK 确认报⽂，于是就会触发快速重发机制，通过 SACK 信息发现只有200~299 这段数据丢失，则重发时，就只选择了这个 TCP 段进⾏重发。\n重复 SACK（D-SACK）D-SACK，英文是 Duplicate SACK，是在 SACK 的基础上做了一些扩展，主要用来告诉发送方，有哪些数据包，自己重复接受了。\nDSACK 的目的是帮助发送方判断，是否发生了包失序、ACK 丢失、包重复或伪重传。让 TCP 可以更好的做网络流控。\n例如ACK丢包导致的数据包重复：\nACK丢包-来源参考[3]\n\n接收⽅发给发送⽅的两个 ACK 确认应答都丢失了，所以发送⽅超时后，重传第⼀个数据包（3000 ~\n\n3499）\n\n于是接收⽅发现数据是重复收到的，于是回了⼀个 SACK &#x3D; 3000~3500，告诉「发送⽅」 3000~3500的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个SACK 就代表着 D-SACK 。这样发送⽅就知道了，数据没有丢，是接收⽅的 ACK 确认报⽂丢了。\n\n43.说说TCP 的粘包和拆包？TCP 的粘包和拆包更多的是业务上的概念！\n\n\n\n\n\n\n\n\n\n什么是TCP粘包和拆包？\nTCP 是面向流，没有界限的一串数据。TCP 底层并不了解上层业务数据的具体含义，它会根据 TCP 缓冲区的实际情况进行包的划分，所以在业务上认为，一个完整的包可能会被 TCP 拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的 TCP 粘包和拆包问题。\n![图片](&#x2F;Users&#x2F;michael&#x2F;Project&#x2F;MichaelBlog&#x2F;images&#x2F;网络TCP 的粘包和拆包.png)TCP 的粘包和拆包\n\n\n\n\n\n\n\n\n\n为什么会产生粘包和拆包呢?\n\n要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；\n接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；\n要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；\n待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 &gt; MSS。\n\n\n\n\n\n\n\n\n\n\n那怎么解决呢？\n\n发送端将每个数据包封装为固定长度\n在数据尾部增加特殊字符进行分割\n将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小固定，且有一个字段声明内容体的大小。\n\nUDPUDP问的不多，基本上是被拿来和TCP比较。\n44.说说 TCP 和 UDP 的区别？最根本区别：TCP 是面向连接，而 UDP 是无连接。\nTCP和UDP区别\n可以这么形容：TCP是打电话，UDP是大喇叭。\nTCP和UDP比喻\n\n\n\n\n\n\n\n\n\n说说TCP和UDP的应用场景？\n\nTCP应用场景： 效率要求相对低，但对准确性要求相对高的场景。因为传输中需要对数据确认、重发、排序等操作，相比之下效率没有UDP高。例如：文件传输（准确高要求高、但是速度可以相对慢）、收发邮件、远程登录。\nUDP应用场景： 效率要求相对高，对准确性要求相对低的场景。例如：QQ聊天、在线视频、网络语音电话（即时通讯，速度要求高，但是出现偶尔断续不是太大问题，并且此处完全不可以使用重发机制）、广播通信（广播、多播）。\n\n45.为什么QQ采用UDP协议？PS：这是多年前的老题了，拉出来怀怀旧。\nQQ使用UDP\n\n首先，QQ并不是完全基于UDP实现。比如在使用QQ进行文件传输等活动的时候，就会使用TCP作为可靠传输的保证。\n使用UDP进行交互通信的好处在于，延迟较短，对数据丢失的处理比较简单。同时，TCP是一个全双工协议，需要建立连接，所以网络开销也会相对大。\n如果使用QQ语音和QQ视频的话，UDP的优势就更为突出了，首先延迟较小。最重要的一点是不可靠传输，这意味着如果数据丢失的话，不会有重传。因为用户一般来说可以接受图像稍微模糊一点，声音稍微不清晰一点，但是如果在几秒钟以后再出现之前丢失的画面和声音，这恐怕是很难接受的。\n由于QQ的服务器设计容量是海量级的应用，一台服务器要同时容纳十几万的并发连接，因此服务器端只有采用UDP协议与客户端进行通讯才能保证这种超大规模的服务\n\n简单总结一下：UDP协议是无连接方式的协议，它的效率高，速度快，占资源少，对服务器的压力比较小。但是其传输机制为不可靠传送，必须依靠辅助的算法来完成传输控制。QQ采用的通信协议以UDP为主，辅以TCP协议。\n46.UDP协议为什么不可靠？UDP在传输数据之前不需要先建立连接，远地主机的运输层在接收到UDP报文后，不需要确认，提供不可靠交付。总结就以下四点：\n\n不保证消息交付：不确认，不重传，无超时\n不保证交付顺序：不设置包序号，不重排，不会发生队首阻塞\n不跟踪连接状态：不必建立连接或重启状态机\n不进行拥塞控制：不内置客户端或网络反馈机制\n\n47.DNS为什么要用UDP?更准确地说，DNS既使用TCP又使用UDP。\n当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用TCP，因为数据同步传送的数据量比一个请求和应答的数据量要多，而TCP允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的TCP。\n当客户端想DNS服务器查询域名（域名解析）的时候，一般返回的内容不会超过UDP报文的最大长度，即512字节，用UDP传输时，不需要创建连接，从而大大提高了响应速度，但这要求域名解析服务器和域名服务器都必须自己处理超时和重传从而保证可靠性。\nIP48.IP 协议的定义和作用？\n\n\n\n\n\n\n\n\nIP协议是什么？\nIP协议（Internet Protocol）又被称为互联网协议，是支持网间互联的数据包协议，工作在网际层，主要目的就是为了提高网络的可扩展性。\n通过网际协议IP，可以把参与互联的，性能各异的网络看作一个统一的网络。\n虚拟IP网\n和传输层TCP相比，IP协议是一种无连接&#x2F;不可靠、尽力而为的数据包传输服务，和TCP协议一起构成了TCP&#x2F;IP协议的核心。\n\n\n\n\n\n\n\n\n\nIP协议有哪些作用？\nIP协议主要有以下几个作用：\n\n寻址和路由：在IP数据报中携带源IP地址和目的IP地址来表示该数据包的源主机和目标主机。IP数据报在传输过程中，每个中间节点（IP网关、路由器）只根据网络地址来进行转发，如果中间节点是路由器，则路由器会根据路由表选择合适的路径。IP协议根据路由选择协议提供的路由信息对IP数据报进行转发，直至目标主机。\n分段和重组：IP数据报在传输过程中可能会经过不同的网络，在不同的网络中数据报的最大长度限制是不同的，IP协议通过给每个IP数据报分配一个标识符以及分段与组装的相关信息，使得数据报在不同的网络中能够被传输，被分段后的IP数据报可以独立地在网络中进行转发，在达到目标主机后由目标主机完成重组工作，恢复出原来的IP数据报。\n\n\n\n\n\n\n\n\n\n\n传输层协议和网络层协议有什么区别？\n网络层协议负责提供主机间的逻辑通信；传输层协议负责提供进程间的逻辑通信。\n49.IP 地址有哪些分类？一个IP地址在这鞥个互联网范围内是惟一的，一般可以这么认为，IP 地址 &#x3D; {&lt;网络号&gt;，&lt;主机号&gt;}。\n\n网络号：它标志主机所连接的网络地址表示属于互联网的哪一个网络。\n主机号：它标志主机地址表示其属于该网络中的哪一台主机。\n\nIP 地址分为 A，B，C，D，E 五大类：\n\nA 类地址 (1~126)：以 0 开头，网络号占前 8 位，主机号占后面 24 位。\nB 类地址 (128~191)：以 10 开头，网络号占前 16 位，主机号占后面 16 位。\nC 类地址 (192~223)：以 110 开头，网络号占前 24 位，主机号占后面 8 位。\nD 类地址 (224~239)：以 1110 开头，保留为多播地址。\nE 类地址 (240~255)：以 1111开头，保留位为将来使用\n\nIP地址分类\n50.域名和 IP 的关系？一个 IP 可以对应多个域名吗？\nIP地址在同一个网络中是惟一的，用来标识每一个网络上的设备，其相当于一个人的身份证号\n域名在同一个网络中也是惟一的，就像是一个人的名字、绰号\n\n假如你有多个不用的绰号，你的朋友可以用其中任何一个绰号叫你，但你的身份证号码却是惟一的。但同时你的绰号也可能和别人重复，假如你不在，有人叫你的绰号，其它人可能就答应了。\n一个域名可以对应多个IP，但这种情况DNS做负载均衡的，在用户访问过程中，一个域名只能对应一个IP。\n而一个IP却可以对应多个域名，是一对多的关系。\n51.IPV4 地址不够如何解决？我们知道，IP地址有32位，可以标记2的32次方个地址，听起来很多，但是全球的网络设备数量已经远远超过这个数字，所以IPV4地址已经不够用了，那怎么解决呢？\nIPV4不够解决办法\n\nDHCP：动态主机配置协议，动态分配IP地址，只给接入网络的设备分配IP地址，因此同一个MAC地址的设备，每次接入互联网时，得到的IP地址不一定是相同的，该协议使得空闲的IP地址可以得到充分利用。\nCIDR：无类别域间路由。CIDR消除了传统的A类、B类、C类地址以及划分子网的概念，因而更加有效地分配IPv4的地址空间，但无法从根本上解决地址耗尽的问题。\nNAT：网络地址转换协议，我们知道属于不同局域网的主机可以使用相同的IP地址，从而一定程度上缓解了IP资源枯竭的问题，然而主机在局域网中使用的IP地址是不能在公网中使用的，当局域网主机想要与公网主机进行通信时，NAT方法可以将该主机IP地址转换为全球IP地址。该协议能够有效解决IP地址不足的问题。\nIPv6：作为接替IPv4的下一代互联网协议，其可以实现2的128次方个地址，而这个数量级，即使给地球上每一粒沙子都分配一个IP地址也够用，该协议能够从根本上解决IPv4地址不够用的问题。\n\n52.说下 ARP 协议的工作过程？ARP 协议，Address Resolution Protocol，地址解析协议，它是用于实现 IP 地址到 MAC 地址的映射。\nARP 协议作用\n\n首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。\n当源主机需要将一个数据包要发送到目的主机时，会首先检查自己的 ARP 列表，是否存在该 IP 地址对应的 MAC 地址；如果有﹐就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。此 ARP 请求的数据包里，包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。\n网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同，就会忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址。\n源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。\n\n53.为什么既有IP地址，又有MAC 地址？\n\n\n\n\n\n\n\n\nMAC地址和IP地址都有什么作用？\n\nMAC地址是数据链路层和物理层使用的地址，是写在网卡上的物理地址，用来定义网络设备的位置，不可变更。\nIP地址是网络层和以上各层使用的地址，是一种逻辑地址。IP地址用来区别网络上的计算机。\n\n\n\n\n\n\n\n\n\n\n为什么有了MAC地址还需要IP地址？\n如果我们只使用MAC地址进行寻址的话，我们需要路由器记住每个MAC地址属于哪个子网，不然一次路由器收到数据包都要满世界寻找目的MAC地址。而我们知道MAC地址的长度为48位，也就是最多共有2的48次方个MAC地址，这就意味着每个路由器需要256T的内存，显然是不现实的。\n和MAC地址不同，IP地址是和地域相关的，在一个子网中的设备，我们给其分配的IP地址前缀都是一样的，这样路由器就能根据IP地址的前缀知道这个设备属于哪个子网，剩下的寻址就交给子网内部实现，从而大大减少了路由器所需要的内存。\n\n\n\n\n\n\n\n\n\n为什么有了IP地址还需要MAC地址？\nIP地址和MAC地址\n\n只有当设备连入网络时，才能根据他进入了哪个子网来为其分配IP地址，在设备还没有IP地址的时候，或者在分配IP的过程中。我们需要MAC地址来区分不同的设备。\nIP 地址可以比作为地址，MAC 地址为收件人，在一次通信过程中，两者是缺一不可的。\n\n54.ICMP 协议的功能？ICMP（Internet Control Message Protocol） ，网际控制报文协议。\n\nICMP 协议是一种面向无连接的协议，用于传输出错报告控制信息。\n它是一个非常重要的协议，它对于网络安全具有极其重要的意义。它属于网络层协议，主要用于在主机与路由器之间传递控制信息，包括报告错误、交换受限控制和状态信息等。\n当遇到 IP 数据无法访问目标、IP 路由器无法按当前的传输速率转发数据包等情况时，会自动发送 ICMP 消息。\n\n比如我们日常使用得比较多的 ping，就是基于 ICMP 的。\n55.说下 ping 的原理？ping，Packet Internet Groper，是一种因特网包探索器，用于测试网络连接量的程序。Ping 是工作在 TCP&#x2F;IP 网络体系结构中应用层的一个服务命令， 主要是向特定的目的主机发送 ICMP（Internet Control Message Protocol 因特网报文控制协议） 请求报文，测试目的站是否可达及了解其有关状态。\nping百度\n一般来说，ping 可以用来检测网络通不通。它是基于ICMP协议工作的。假设机器 A ping 机器 B，工作过程如下：\n\nping 通知系统，新建一个固定格式的 ICMP 请求数据包\nICMP 协议，将该数据包和目标机器 B 的 IP 地址打包，一起转交给 IP 协议层\nIP 层协议将本机 IP 地址为源地址，机器 B 的 IP 地址为目标地址，加上一些其他的控制信息，构建一个 IP 数据包\n先获取目标机器 B 的 MAC 地址。\n数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址是本机的 MAC 地址\n机器 B 收到后，对比目标地址，和自己本机的 MAC 地址是否一致，符合就处理返回，不符合就丢弃。\n根据目的主机返回的 ICMP 回送回答报文中的时间戳，从而计算出往返时间\n最终显示结果有这几项：发送到目的主机的 IP 地址、发送 &amp; 收到 &amp; 丢失的分组数、往返时间的最小、最大 &amp; 平均值\n\n网络安全56.说说有哪些安全攻击？网络安全攻击主要分为两种类型，被动攻击和主动攻击：\n主动攻击和被动攻击\n\n被动攻击：是指攻击者从网络上窃听他人的通信内容，通常把这类攻击称为截获，被动攻击主要有两种形式：消息内容泄露攻击和流量分析攻击。由于攻击者没有修改数据，使得这种攻击很难被检测到。\n\n主动攻击：直接对现有的数据和服务造成影响，常见的主动攻击类型有：\n\n\n篡改：攻击者故意篡改网络上送的报文，甚至把完全伪造的报文传送给接收方。\n恶意程序：恶意程序种类繁多，包括计算机病毒、计算机蠕虫、特洛伊木马、后门入侵、流氓软件等等。\n拒绝服务Dos：攻击者向服务器不停地发送分组，使服务器无法提供正常服务。\n\n\n\n57.DNS劫持了解吗？DNS劫持即域名劫持，是通过将原域名对应的IP地址进行替换，从而使用户访问到错误的网站，或者使用户无法正常访问网站的一种攻击方式。\nDNS劫持示意图\n域名劫持往往只能在特定的网络范围内进行，范围外的DNS服务器能够返回正常的IP地址。攻击者可以冒充原域名所属机构，通过电子邮件的方式修改组织机构的域名注册信息，或者将域名转让给其它主持，并将新的域名信息保存在所指定的DNS服务器中，从而使用户无法对原域名来进行解析以访问目标地址。\n\n\n\n\n\n\n\n\n\nDNS劫持的步骤是什么样的？\n\n获取要劫持的域名信息：攻击者会首先访问域名查询要劫持的站点的域名信息。\n控制域名响应的E-Mail账号：在获取到域名信息后，攻击者通过暴力破解或者专门的方法破解公司注册域名时使用的E-mail账号所对应的密码，更高级的攻击者甚至能够直接对E-Mail进行信息窃取。\n修改注册信息：当攻击者破解了E-Mail后，会利用相关的更改功能修改该域名的注册信息，包括域名拥有者信息，DNS服务器信息等。\n使用E-Mail收发确认函：在修改完注册信息后，攻击者E-Mail在真正拥有者之前收到修改域名注册信息的相关确认信息，并回复确认修改文件，待网络公司恢复已成功修改信件后，攻击者便成功完成DNS劫持。\n\n\n\n\n\n\n\n\n\n\n怎么应对DNS劫持？\n\n直接通过IP地址访问网站，避开DNS劫持\n由于域名劫持往往只能在特定的网络范围内进行，因此一些高级用户可以通过网络设置让DNS指向正常的域名服务器以实现对目标网址的正常访问，例如计算机首选DNS服务器的地址固定为8.8.8.8。\n\n58.什么是 CSRF 攻击？如何避免？\n\n\n\n\n\n\n\n\n什么是 CSRF 攻击？\nCSRF，跨站请求伪造（英文全称是 Cross-site request forgery），是一种挟持用户在当前已登录的 Web 应用程序上执行非本意的操作的攻击方法。\n\n\n\n\n\n\n\n\n\nCSRF 是如何攻击的呢？\n来看一个例子：\nCSRF典型例子\n\n用户登陆银行，没有退出，浏览器包含了 用户 在银行的身份认证信息。\n攻击者将伪造的转账请求，包含在在帖子\n用户在银行网站保持登陆的情况下，浏览帖子\n将伪造的转账请求连同身份认证信息，发送到银行网站\n银行网站看到身份认证信息，以为就是 用户的合法操作，最后造成用户资金损失。\n\n\n\n\n\n\n\n\n\n\n怎么应对 CSRF 攻击呢？\n\n检查 Referer 字段\nHTTP头中的Referer字段记录了该 HTTP 请求的来源地址。在通常情况下，访问一个安全受限页面的请求来自于同一个网站，而如果黑客要对其实施 CSRF攻击，他一般只能在他自己的网站构造请求。因此，可以通过验证Referer值来防御CSRF 攻击。\n\n添加校验 token\n以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有token或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。\n\n敏感操作多重校验\n对一些敏感的操作，除了需要校验用户的认证信息，还可以通过邮箱确认、验证码确认这样的方式多重校验。\n\n\n59.什么是 DoS、DDoS、DRDoS 攻击？\n请求太多服务器着不住\n\nDOS: (Denial of Service), 翻译过来就是拒绝服务, 一切能引起拒绝 行为的攻击都被称为 DOS 攻击。最常见的 DoS 攻击就有计算机网络宽带攻击、连通性攻击。\n\nDDoS: (Distributed Denial of Service)，翻译过来是分布式拒绝服务。是指处于不同位置的多个攻击者同时向一个或几个目标发动攻击，或者一个攻击者控制了位于不同位置的多台机器，并利用这些机器对受害者同时实施攻击。\n主要形式有流量攻击和资源耗尽攻击，常见的 DDoS攻击有：SYN Flood、Ping of Death、ACK Flood、UDP Flood 等。\n\nDRDoS: (Distributed Reflection Denial of Service)，中文是分布式反射拒绝服务，该方式靠的是发送大量带有被害者 IP 地址的数据包给攻击主机，然后攻击主机对 IP 地址源做出大量回应，从而形成拒绝服务攻击。\n\n\n\n\n\n\n\n\n\n\n\n如何防范DDoS?\n针对DDoS中的流量攻击，最直接的方法是增加带宽，理论上只要带宽大于攻击流量就可以了，但是这种方法成本非常高。在有充足带宽的前提下，我们应该尽量提升路由器、网卡、交换机等硬件设施的配置。\n针对资源耗尽攻击，我们可以升级主机服务器硬件，在网络带宽得到保证的前提下，使得服务器能够有效对抗海量的SYN攻击包。我们也可以安装专业的抗DDoS防火墙，从而对抗SYN Flood等流量型攻击。瓷碗，负载均衡，CDN等技术都能有效对抗DDos攻击。\n60.什么是 XSS 攻击，如何避免?XSS 攻击也是比较常见，XSS，叫跨站脚本攻击（Cross-Site Scripting），因为会与层叠样式表 (Cascading Style Sheets, CSS) 的缩写混淆，因此有人将跨站脚本攻击缩写为 XSS。它指的是恶意攻击者往 Web 页面里插入恶意 html 代码，当用户浏览网页的时候，嵌入其中 Web 里面的 html 代码会被执行，从而达到恶意攻击用户的特殊目的。\nXSS 攻击一般分三种类型：存储型 、反射型 、DOM 型 XSS\n\n\n\n\n\n\n\n\n\nXSS 是如何攻击的呢？\n简单说，XSS的攻击方式就是想办法“教唆”用户的浏览器去执行一些这个网页中原本不存在的前端代码。\n拿反射型举个例子吧，流程图如下：\n\n攻击者构造出特殊的 URL，其中包含恶意代码。\n用户打开带有恶意代码的 URL 时，访问正常网站服务器\n网站服务端将恶意代码从 URL 中取出，拼接在 HTML 中返回给浏览器。\n用户浏览器接收到响应后解析执行，混在其中的恶意代码也被执行，请求恶意服务器，发送用户数据\n攻击者就可以窃取用户的数据，以此冒充用户的行为，调用目标网站接口执行攻击者指定的操作。\n\n一个典型的XSS\n\n\n\n\n\n\n\n\n\n如何应对 XSS 攻击？\n\n对输入进行过滤，过滤标签等，只允许合法值。\nHTML 转义\n对于链接跳转，如&lt;a href=&quot;xxx&quot; 等，要校验内容，禁止以 script 开头的非法链接。\n限制输入长度\n\n61.对称加密与非对称加密有什么区别？对称加密：指加密和解密使用同一密钥，优点是运算速度较快，缺点是如何安全将密钥传输给另一方。常见的对称加密算法有：DES、AES 等。\n对称加密\n非对称加密：指的是加密和解密使用不同的密钥（即公钥和私钥）。公钥与私钥是成对存在的，如果用公钥对数据进行加密，只有对应的私钥才能解密。常见的非对称加密算法有 RSA。\n\n&#123;% asset_path slug %&#125;\n\n\n\n非对称加密\n62.RSA和AES算法有什么区别？\nRSA\n采用非对称加密的方式，采用公钥进行加密，私钥解密的形式。其私钥长度一般较长，由于需要大数的乘幂求模等运算，其运算速度较慢，不合适大量数据文件加密。\n\nAES\n采用对称加密的方式，其秘钥长度最长只有256个比特，加密和解密速度较快，易于硬件实现。由于是对称加密，通信双方在进行数据传输前需要获知加密密钥。\n\n\n参考\n","slug":"03_HTTP/网络编程","date":"2018-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"HTTP","author_index":"Michael"},{"id":"dee473956ecc4136db4ec27893bc59f9","title":"索引的优缺点","content":"\n\n\n\n\n\n\n\n\n索引的优点\n\n可以大大加快数据的检索速度，这也是创建索引的最主要的原因。\n通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。\n\n\n\n\n\n\n\n\n\n\n索引的缺点\n\n时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，会降低增&#x2F;改&#x2F;删的执行效率；\n空间方面：索引需要占物理空间。\n\n","slug":"01_MySQL/索引/优缺点","date":"2018-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"c959ca1c966c1689958d6f39785ba7f9","title":"索引创建的原则","content":"\n\n\n\n\n\n\n\n\n建索引的原则\n1、最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a &#x3D; 1 and b &#x3D; 2 and c &gt; 3 and d &#x3D; 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。\n2、&#x3D;和in可以乱序，比如a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。\n3、尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)&#x2F;count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。\n4、索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) &#x3D; ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time &#x3D; unix_timestamp(’2014-05-29’)。\n5、尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。\n\n\n\n\n\n\n\n\n\n使用索引查询一定能提高查询的性能吗\n通常通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。\n索引需要空间来存储，也需要定期维护， 每当有记录在表中增减或索引列被修改时，索引本身也会被修改。这意味着每条记录的I* NSERT，DELETE，UPDATE将为此多付出4，5 次的磁盘I&#x2F;O。因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:\n\n基于一个范围的检索，一般查询返回结果集小于表中记录数的30%。\n基于非唯一性索引的检索。\n\n","slug":"01_MySQL/索引/建立原则","date":"2018-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"dc39dd35ae294923e1738eec2083266a","title":"Redis 队列消费","content":"\n\n\n\n\n\n\n\n\n数据结构\nlist - 先进先出  - 左进右出\n\n\n\n\n\n\n\n\n\n归纳\n\n\n\n实现方式\n操作\n效果\n\n\n\n单list\n左进右出 lpush rpop\n最简单，实际应用比较局限\n\n\n多list\nbrpop list1 list2 0\n推荐用法，实际应用最为合适\n\n\n特定单list\nlist1 - 高优list2 - 普通\n实现复杂优先级，但实现比较复杂，不利于维护\n\n\n\n\n\n\n\n\n\n\n\n优先级实现方式\n通常使用一个list来实现队列操作，\n这样有一个小限制，所以的任务统一都是先进先出，\n如果想优先处理某个任务就不太好处理了，这就需要让队列有优先级的概念，我们就可以优先处理高级别的任务，实现方式有以下几种方式：\n\n单一列表实现：\n队列正常的操作是 左进右出（lpush,rpop）为了先处理高优先级任务，在遇到高级别任务时，可以直接插队，直接放入队列头部（rpush），这样，从队列头部（右侧）获取任务时，取到的就是高优先级的任务（rpop）\n\n使用两个队列\n一个普通队列，一个高级队列，针对任务的级别放入不同的队列，获取任务时也很简单，redis的BRPOP命令可以按顺序从多个队列中取值，BRPOP会按照给出的 key 顺序查看，并在找到的第一个非空 list 的尾部弹出一个元素\nredis&gt; BRPOP list1 list2 0\n\n\n\nlist1 做为高优先级任务队列\nlist2 做为普通任务队列\n\n\n这样就实现了先处理高优先级任务，当没有高优先级任务时，就去获取普通任务。\n方式1 最简单，但实际应用比较局限；\n方式2 推荐用法，实际应用最为合适；\n方式3 可以实现复杂优先级，但实现比较复杂，不利于维护。\n","slug":"02_Redis/Redis消息队列","date":"2017-03-20T07:05:07.000Z","categories_index":"Redis","tags_index":"redis","author_index":"Michael"},{"id":"972e329cd1da7ac5452b9664a39b21b1","title":"HTTPS","content":"HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。\n\nHTTPS 并非是应用层的一种新协议。只是 HTTP 通信接口部分用SSL（Secure Socket Layer）和 TLS（Transport Layer Security）协议代替而已。通常，HTTP 直接和 TCP 通信。当使用 SSL时，则演变成先和 SSL通信，再由 SSL和 TCP 通信了。简言之，所谓 HTTPS，其实就是身披SSL协议这层外壳的 HTTP。\nHTTPS通讯方式：\n\n客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。\nWeb服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。\n客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。\n客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。\nWeb服务器利用自己的私钥解密出会话密钥。\nWeb服务器利用会话密钥加密与客户端之间的通信。\n\n\n为什么HTTPS安全\nSSL不仅提供加密处理，加密方式为混合加密。\nSSL而且还使用了一种被称为证书的手段，可用于确定方。证书由值得信任的第三方机构颁发，用以证明服务器和客户端是实际存在的。另外，伪造证书从技术角度来说是异常困难的一件事。所以只要能够确认通信方（服务器或客户端）持有的证书。\n\n\n加密方法\n\n\n\n\n\n\n\n\n\n对称加密：加密和解密同用一个密钥的方式称为共享密钥加密（Common keycrypto system），也被叫做对称密钥加密.\n对成加密的方式效率比较低，加密速度慢。另外对称加密存在安全隐患的问题，堆成加密的密钥必须要传到对方对方才能解密，要是对方在密钥传输的过程获取到密钥，那不是密钥失去了加密的意义，所以完全使用对称加密也是不安全的。\n\n\n\n\n\n\n\n\n\n非对称加密：公开密钥加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得。公钥加密，私钥解密使用公开密钥加密方式，发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密。\n那么非对称个加密就一定安全吗？非对称加密也不安全，为什么呢？因为存在中间伪造公钥和私钥，假如在公钥传给对方的时候，有人获取到公钥，虽然她不能用你的公钥做什么，但是它截获公钥后，把自己伪造的公钥发送给对方，这样对方获取的就不是真正的公钥，当对方用公钥进行加密文件，再将文件发送给对方，这样即使截获人没有获取到真正的私钥，但是加密时的公钥是截获人的，他获取到加密文件，只需要用自己的私钥进行解密就成功获取到文件了。\n\n\n\n\n\n\n\n\n\n混合加密机制（对称加密与非对称加密结合的方式）顾名思义也就是对称加密和非对称加密的方式相结合。\n\n如何证明公开没要本身的真实性。因为在公开秘钥传输的过程中，可能真正的公开秘钥已经被攻击者替换掉了。\n为了解决上述问题，于是除了CA认证证书。服务器将CA证书发送给客户端，以进行公开密钥加密方式通信。接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可明确两件事：\n\n一：认证服务器的公开密钥的是真实有效的数字证书认证机构；\n二：服务器的公开密钥是值得信赖的。\n\n那么公开密钥如何交接给客户端是一件非常重要的事，因此多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥，这样就确保公钥是使用认证机构的公钥避免了公钥伪造的过程，进而确保了安全。\n\n","slug":"03_HTTP/HTTPS","date":"2017-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"HTTPS","author_index":"Michael"},{"id":"07ce52ba0deb3c9ebe285ff3996a2db7","title":"HTTP 三次握手","content":"\n第一次握手：Client将标志位SYN置为1，随机产生一个值seq&#x3D;J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。\n第二次握手：Server收到数据包后由标志位SYN&#x3D;1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack&#x3D;J+1，随机产生一个值seq&#x3D;K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。\n第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack&#x3D;K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。\n\n\n为什么要进行三次握手呢? \n第三次握手是为了防止失效的连接请求到达服器，让服务器错误打开连接。\n客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。\n客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。\n如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。\n​\t如果此时变成两次握手行不行？\n举个打电话的例子，比如：\n第一次握手：A给B打电话说，你可以听到我说话吗？\n第二次握手：B收到了A的信息，然后对A说：我可以听得到你说话啊，你能听得到我说话吗？\n第三次握手：A收到了B的信息，然后说可以的，我要给你发信息啦！\n结论：在三次握手之后，A和B都能确定这么一件事：我能听到你，你也能听到我。\n这样，就可以开始正常通信了。如果是两次，那将无法确定。\n","slug":"03_HTTP/三次握手","date":"2017-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"HTTP","author_index":"Michael"},{"id":"31e25675b77f47e927b5d00900537180","title":"HTTP四次挥手","content":"\n第一次挥手，客户端设置seq和 ACK ,向服务器发送一个 FIN(终结)报文段。此时，客户端进入 FIN_WAIT_1状态，表示客户端没有数据要发送给服务端了。\n第二次挥手，服务端收到了客户端发送的 FIN 报文段，向客户端回了一个 ACK 报文段。\n第三次挥手，服务端向客户端发送FIN 报文段，请求关闭连接，同时服务端进入 LAST_ACK 状态。\n第四次挥手，客户端收到服务端发送的 FIN 报文段后，向服务端发送 ACK 报文段,然后客户端进入 TIME_WAIT状态。服务端收到客户端的 ACK 报文段以后，就关闭连接。此时，客户端等待2MSL（指一个片段在网络中最大的存活时间）后依然没有收到回复，则说明服务端已经正常关闭，这样客户端就可以关闭连接了。四次挥手\n\n\n为什么要四次挥手？客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。\nHTTP持久连接如果有大量的连接，每次在连接，关闭都要经历三次握手，四次挥手，这显然会造成性能低下。因此。\nHttp 有一种叫做 长连接（keepalive connections） 的机制。\n它可以在传输数据后仍保持连接，当客户端需要再次获取数据时，直接使用刚刚空闲下来的连接而无需再次握手。\n","slug":"03_HTTP/四次挥手","date":"2017-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"HTTP","author_index":"Michael"},{"id":"c9bae4d52c21a8c716e9cbe93724780d","title":"索引回表","content":"\n\n\n\n\n\n\n\n\n回表\n查询时一些字段值拿不到，需要到主键索引B+树再查一次。\n根据索引进行条件查询，回到主键索引树进行搜索的过程\n\n因为查询还要回表一次，再次查询主键索引树，所以实际中应该尽量避免回表的产生。\n解决回表问题可以建立联合索引进行索引覆盖，如图所示根据name字段查询用户的name和sex属性出现了回表问题：\n\n那么我们可以建立下面这个联合索引来解决：\ncreate table user (\n id int primary key,\n name varchar(20),\n sex varchar(5),\n index(name, sex)\n) engine &#x3D; innodb;\n\n建立了如上所示的index(name,sex)联合索引，在二级索引的叶子结点的位置就会同时也出现sex字段的值，因为能够获取到要查询的所有字段，因为就不用再回表查询一次。\n\n\n\n\n\n\n\n\n\n强制索引\nforce index\n","slug":"01_MySQL/索引/回表","date":"2017-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"c96d4fc8e3f918b924dc7332b382cdc6","title":"索引的概念","content":"索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，\n它们包含着对数据表里所有记录的引用指针。\n索引是一种数据结构。\n数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。\n索引的实现通常使用B树及其变种B+树。\n更通俗的说，索引就相当于目录。\n为了方便查找书中的内容，通过对内容建立索引形成目录。\n而且索引是一个文件，它是要占据物理空间的。\nMySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。\n比如我们在查字典的时候，前面都有检索的拼音和偏旁、笔画等，\n然后找到对应字典页码，\n这样然后就打开字典的页数就可以知道我们要搜索的某一个key的全部值的信息了。\n","slug":"01_MySQL/索引/概念","date":"2017-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"dcac90a749529234346e1f26c6954e6d","title":"创建索引","content":"\n在执行CREATE TABLE时创建索引\n\nCREATE TABLE user_index2 (\n id INT auto_increment PRIMARY KEY,\n first_name VARCHAR (16),\n last_name VARCHAR (16),\n id_card VARCHAR (18),\n information text,\n KEY name (first_name, last_name),\n FULLTEXT KEY (information),\n UNIQUE KEY (id_card)\n);\n\n\n使用ALTER TABLE命令去增加索引。\n\nALTER TABLE table_name ADD INDEX index_name (column_list);\n\nALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。\n其中table_name是要增加索引的表名，column_list指出对哪些列进行索引，多列时各列之间用逗号分隔。\n索引名index_name可自己命名，缺省时，MySQL将根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可以在同时创建多个索引。\n\n使用CREATE INDEX命令创建。\n\nCREATE INDEX index_name ON table_name (column_list);\n\n\n\n\n\n\n\n\n\n\n\n\n注意点\n\n非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；\n取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；\n索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。\n\n","slug":"01_MySQL/索引/创建","date":"2016-10-03T12:15:24.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"663da5c433b044584e25ee70419ef2e6","title":"TCP/IP","content":"TCP&#x2F;IP（Transmission Control Protocol&#x2F;Internet Protocol，传输控制协议&#x2F;网际协议）\n是指能够在多个不同网络间实现信息传输的协议簇。\nTCP&#x2F;IP协议不仅仅指的是TCP 和IP两个协议，\n而是指一个由FTP、SMTP、TCP、UDP、IP等协议构成的协议簇，\n同时是Internet最基本的协议、Internet国际互联网络的基础，\n由网络层的IP协议和传输层的TCP协议组成。\nTCP&#x2F;IP 定义了电子设备如何连入因特网，以及数据如何在它们之间传输的标准。\n 互联网中的设备要相互通信，必须基于相同的方式，\n比如由哪一方发起通讯，使用什么语言进行通讯，怎么结束通讯这些都要事先确定，\n不同设备之间的通讯都需要一种规则，我们将这种规则成为协议。\nTCP&#x2F;IP协议中最重要的特点就是分层。\n由上往下分别为 \n​\t【应用层】、【传输层】、【网络层】、【数据链路层】、【物理层】。\n当然也有按不同的模型分为4层或者7层的。\n\n应用层TCP&#x2F;IP模型将OSI参考模型中的会话层和表示层的功能合并到应用层实现。这一层主要的代表有DNS域名解析&#x2F;http协议\n传输层在TCP&#x2F;IP模型中，传输层的功能是使源端主机和目标端主机上的对等实体可以进行会话。在传输层定义了两种服务质量不同的协议。即：传输控制协议TCP和用户数据报协议UDP.\n网络层网络层是整个TCP&#x2F;IP协议栈的核心。它的功能是把分组发往目标网络或主机。同时，为了尽快地发送分组，可能需要沿不同的路径同时进行分组传递。因此，分组到达的顺序和发送的顺序可能不同，这就需要上层必须对分组进行排序。网络层定义了分组格式和协议，即IP协议（Internet Protocol ）。\n物理层该层负责 比特流在节点之间的传输，即负责物理传输，这一层的协议既与链路有关，也与传输的介质有关。通俗来说就是把计算机连接起来的物理手段。\n数据链路层控制网络层与物理层之间的通信，主要功能是保证物理线路上进行可靠的数据传递。为了保证传输，从网络层接收到的数据被分割成特定的可被物理层传输的帧。帧是用来移动数据结构的结构包，他不仅包含原始数据，还包含发送方和接收方的物理地址以及纠错和控制信息。其中的地址确定了帧将发送到何处，而纠错和控制信息则确保帧无差错到达。如果在传达数据时，接收点检测到所传数据中有差错，就要通知发送方重发这一帧。\n","slug":"03_HTTP/TCP&IP","date":"2016-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"TCP/IP","author_index":"Michael"},{"id":"6d487588c7e406811559edfe45923441","title":"UDP","content":"\n用户数据报协议 UDP（User Datagram Protocol）:无连接；尽最大努力的交付；面向报文；无拥塞控制；支持一对一、一对多、多对一、多对多的交互通信；首部开销小(只有四个字段：源端口、目的端口、长度、检验和)。UDP是面向报文的传输方式是应用层交给UDP多长的报文，UDP发送多长的报文，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。\n传输控制协议 TCP（Transmission Control Protocol）:面向连接；每一个TCP连接只能是点对点的(一对一)；提供可靠交付服务；提供全双工通信；面向字节流。应用程序和TCP的交互是一次一个数据块(大小不等)，但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应该程序传送的数据块太长，TCP就可以把它划分短一些再传送。\n\nUDP的首部格式:\n\n用户数据报有两个字段：数据字段和首部字段，数据字段很简单，只有8个字节，由四个字段组成，每个字段的长度都是两个字节。各字段意义如下：\n\n源端口： 源端口号，在需要给对方回信时使用。不需要是可全用0.\n目的端口号： 这在终点交付报文时必须使用。\n长度： 用户数据报UDP的长度，最小为8（仅首部）。\n校验和： 用于校验用户数据报在传输过程是否出错，出错则丢弃该报文。\n\nTCP报文首部格式:\n源端口和目的端口: 各占两个字节，分别写入源端口号和目的端口号。序号 ： \n占4个字节；用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。确认号 ： \n占4个字节；期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。数据偏移 ： \n占4位；指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。确认 ACK ： \n当 ACK&#x3D;1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。同步 SYN ：\n在连接建立时用来同步序号。当 SYN&#x3D;1，ACK&#x3D;0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN&#x3D;1，ACK&#x3D;1。终止 FIN ： \n用来释放一个连接，当 FIN&#x3D;1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。窗口 ： \n占2字节；窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。检验和： \n占2个字节；检验和字段检验的范围包括首部和数据这两个部分。在计算检验和时，在TCP报文段的前面加上12字节的伪首部。套接字：\n TCP连接的端点叫做套接字或插口。端口号拼接到IP地址即构成了套接字。\n","slug":"03_HTTP/UDP","date":"2016-03-20T07:05:07.000Z","categories_index":"网络编程","tags_index":"UDP","author_index":"Michael"},{"id":"14259dca92b4f8c7a0ce08ea8747bdb9","title":"覆盖索引","content":"覆盖索引，指的是在一次查询中，一个索引包含所有需要查询的字段的值，可能是返回值或where条件\nselect buyer_id from order where money &gt; 100\n\n假如我们创建了一个(money，buyer_id)的联合索引，索引的叶子节点包含了buyer_id的信息，则不会再回表查询。\n","slug":"01_MySQL/索引/覆盖索引","date":"2016-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"cc82895a993ed8e5fa47b14980296312","title":"索引的类型","content":"\n从存储结构上来划分：\nBTree索引（B-Tree或B+Tree索引）；\nHash索引；\nfull-index全文索引；\nR-Tree索引\n这里所描述的是索引存储时保存的形式\n\n从应用层次来分：\n主键索引；\n普通索引；\n唯一索引；\n复合索引(联合索引)；\n空间索引；\n\n根据中数据的物理顺序与键值的逻辑（索引）顺序关系：\n聚集索引(聚族索引)；\n非聚集索引(非聚族索引)；\n\n\n\n\n\n\n\n\n\n\n\n总结\n\n\n\n索引类型\n概念\n\n\n\n普通索引\n一个索引只包含一个列，一个表可以有多个单列索引\n\n\n唯一索引\n索引列的值必须唯一，但允许有空值\n\n\n复合索引\n多列值组成一个索引，专门用于组合搜索，其效率大于索引合并\n\n\n聚簇索引\n也称为主键索引，是一种数据存储方式。B+Tree结构，非叶子节点包含健值和指针，叶子节点包含索引列和行数据。一张表只能有一个聚簇索引。\n\n\n非聚簇索引\n不是聚簇索引，就是非聚簇索引。叶子节点只是存索引列和主键id。如果sql还要返回除了索引列的其他字段信息，需要回表，第一次索引一般是顺序IO，回表的操作属于随机IO。回表的次数越多，性能越差\n\n\n","slug":"01_MySQL/索引/类型","date":"2016-03-13T06:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"82ad704264f844d11231e75cf8c5d2e6","title":"聚簇索引与非聚簇索引","content":"在 InnoDB 里，索引B+ Tree的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引，即将数据存储与索引放到了一块，找到索引也就找到了数据。\n而索引B+ Tree的叶子节点存储了主键的值的是非主键索引，也被称之为非聚簇索引、二级索引。\n聚簇索引与非聚簇索引的区别：\n\n非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键（行号）\n对于InnoDB来说，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为回表。第一次索引一般是顺序IO，回表的操作属于随机IO。需要回表的次数越多，即随机IO次数越多，我们就越倾向于使用全表扫描 。\n通常情况下， 主键索引（聚簇索引）查询只会查一次，而非主键索引（非聚簇索引）需要回表查询多次。当然，如果是覆盖索引的话，查一次即可\n注意：MyISAM无论主键索引还是二级索引都是非聚簇索引，而InnoDB的主键索引是聚簇索引，二级索引是非聚簇索引。我们自己建的索引基本都是非聚簇索引。\n\n非聚簇索引一定会回表查询吗？不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询。一个索引包含（覆盖）所有需要查询字段的值，被称之为”覆盖索引”。\n举个简单的例子，假设我们在学生表的成绩上建立了索引，那么当进行select score from student where score &gt; 90的查询时，在索引的叶子节点上，已经包含了score 信息，不会再次进行回表查询。\n联合索引是什么？为什么需要注意联合索引中的顺序？MySQL可以使用多个字段同时建立一个索引，叫做联合索引。在联合索引中，如果想要命中索引，需要按照建立索引时的字段顺序挨个使用，否则无法命中索引。\n具体原因为:\nMySQL使用索引时需要索引有序，假设现在建立了”name，age，school”的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。\n当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推。因此在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。\n","slug":"01_MySQL/索引/(非)聚簇索引","date":"2015-10-03T12:14:56.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"9e33d627513d69088c1f528c1caaca12","title":"前缀索引","content":"因为可能我们索引的字段非常长，这既占内存空间，也不利于维护。所以我们就想，如果只把很长字段的前面的公共部分作为一个索引，就会产生超级加倍的效果。但是，我们需要注意，order by不支持前缀索引 。\n流程是：\n先计算完整列的选择性 :select count(distinct col_1)/count(1) from table_1\n再计算不同前缀长度的选择性 :select count(distinct left(col_1,4))/count(1) from table_1\n找到最优长度之后，创建前缀索引 :create index idx_front on table_1 (col_1(4))\n","slug":"01_MySQL/索引/前缀索引","date":"2015-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"},{"id":"71464c5902369f580d83a42e959c47ea","title":"索引底层实现","content":"Hash索引\n基于哈希表实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。\n\nB-Tree索引（MySQL使用B+Tree）\nB-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。\n\nB+Tree索引\n是B-Tree的改进版本，同时也是数据库索引索引所采用的存储结构。数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址。相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。\nB+tree性质：\n\nn棵子tree的节点包含n个关键字，不用来保存数据而是保存数据的索引。\n所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。\n所有的非终端结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。\nB+ 树中，数据对象的插入和删除仅在叶节点上进行。\nB+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。\n\n\n\n\n","slug":"01_MySQL/索引/底层实现","date":"2015-03-20T07:05:07.000Z","categories_index":"索引","tags_index":"索引","author_index":"Michael"}]